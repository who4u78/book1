[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "통알못을 위한 기초통계 1",
    "section": "",
    "text": "서문\nSaientia a Dei입니다. 2019년 1월부터 YouTube 통알못을 위한 기초통계 강의를 시작하게 되어 2021년부터는 이를 책으로 만드는 작업을 시작했습니다. 개인사정으로 인해 몇 년간 지지부진 하던 상황에서 마음을 다잡고 책을 썼습니다. 여러가지 옵션을 고민하던 중에 micro-web-book을 결정하였습니다. micro-web-book이란 개념도 제가 혼자 만든 것인데, 소책자 크기로 하여 주제별로 쪼개어 제공하는 것을 의미 합니다. 여기에는 나름 여러가지의 고민이 있었습니다. 이미 꽤 많은 양의 통계강의를 YouTube로 만들은데 반해 이 모든 내용을 한 번에 책으로 쓰기는 것이 제 개인적인 역량을 봐서는 단 기간에 어렵다고 판단한 것도 한가지 이유입니다. 그러나, 이보다 더 중요한 이유는 제 서재의 수많은 통계책을 보면서 고민한 것이 있습니다. 저도 미국에서부터 꽤 많은 통계책을 사서 읽었지만 수 백 페이지 정도의 두꺼운 통계책 중에 처음부터 끝까지 모두 다 읽은 경우는 정말 한 두 권 정도에 불과 했습니다. 저의 경우는 특정 부분이 필요 해서 구매한 통계책이 대부분이었습니다. 그래서 저도 통알못을 위한 책을 쓰는 마당에 보다 미래 지향적이고 실용적인 방법을 찾아야겠다는 마음을 먹었습니다. 운 좋게도 어느 출판사에서 책을 출판하자는 제안이 있기는 했지만, 돈 보다는 지식의 공유가 더 중요하다는 생각에 오픈 소스 북으로 책을 내기로 했고 이를 주제별로 쪼개서 시리즈물로 책을 쓰는 것이 좋겠다고 생각했습니다. 그러니 독자분들께서도 필요한 주제별로 micro-web-book을 읽으실 것을 권해드립니다. 두껍고 무겁기만한 종이책이 읽혀지지도 않은 채로 서재 어딘가에 몇 년간 방치되는 것 보다는 이 편이 낫다고 생각됩니다. 필요에 따라서 스마트폰이나 패드를 이용하셔서 출퇴근 시간 혹은 자투리 시간에 읽으실 수 있을 것입니다.\n1장 통계기초편은 통계공부를 시작하기로 마음먹은 통알못을 위한 일종의 마인드셋팅을 목적으로 합니다. 어려운 통계 용어들을 나열하여 시작부터 통계를 포기하게 만드는 수 많은 교재들에서 벗어나, 통계를 보다 일반 교양적인 측면에서 접근하고자 했습니다. 사실 통계를 일반 교양으로 공부하실 분들은 여기까지만 보시면 됩니다. 2장부터는 교양을 벗어나서 진정한 통계의 길로 들어서는 것이기 때문입니다. 이 책 정도만 보셔도 기본적인 통계적 마인드와 생각하는 방법은 충분히 마스터하실 수 있다고 생각합니다. 2장은 t-test로 그리고 3장은 ANOVA로 진행했습니다. 아마도 대부분의 일반인들은 이정도 통계만 보아도 충분할 수 있다고 생각됩니다. 향후 계속해서 주제별로 책을 쓰도록 하겠습니다.\n무엇보다 통계 전공자도 아닌 사람이 강의를 하고 책을 쓰는 것이 여전히 부담스럽고 조심스럽습니다. 이 책을 보시는 통계학과 교수님들과 전공자 분들에게는 너그러운 양해를 부탁드립니다. 정통 통계학적인 측면에서 보자면 너무 초라하고 부족하며 때로는 오류가 있을 수 있는 책입니다. 이 책의 내용에 대한 비판은 제가 감당할 부분이나 부드럽고 건설적인 평가는 언제나 반기겠습니다.\n이 책은 YouTube의 통통튜브 (통알못을 위한 통계튜브)의 온라인 비디오 강의를 보다 자세하게 풀어 말로 적은 것입니다. 처음 보시는 분들은 이 책을 한번 가볍게 보시고 난 후 각 절의 마지막에 있는 YouTube 바로가기 링크를 통해 비디오로 한 번 보시고 다시 본문을 읽어 보실 것을 권해드립니다. 한 번에 모든 것을 이해할 수 있다면 좋겠으나 반복 학습이 보다 효과적이라고 생각합니다. 유튜브 주소는 아래와 같습니다. 네이버 블로그에도 링크가 되어 있으니 편하신 플랫폼으로 비디오를 보시면 될 것 같습니다. 더불어 실습에 사용될 모든 샘플파일은 GitHub에 저장되어 있으니 자유롭게 다운로드 받아 사용하시기 바랍니다.\n마지막으로 제가 유투브를 통해 공개한 통통튜브의 내용이나 이 책의 내용을 무단으로 사용하지 마시길 부탁드립니다. 무료로 공개한 내용이지만 저의 노력과 오랜 기간의 아이디어가 담긴 것들입니다. 가끔 이런 무료공개 정보는 저작권이 없다고 생각하시고 심지어 제 강의 내용을 상업적 용도로 사용하시는 분들이 있는데 이는 분명한 저작물권의 침해입니다. 혼자 공부하기 위해 자료를 만들어 혼자서 보는 것은 누가 뭐라 할 수 없으나 정리된 내용을 인터넷으로 공개하거나 상업적인 목적으로 사용하시는 것은 분명 문제의 소지가 있음을 알려드립니다.\nYoutube 채널\n네이버 블로그\n샘플파일 다운로드\n부족한 제 강의와 책에 관심을 가져주시는 모든 분들께 감사의 말씀 올립니다."
  },
  {
    "objectID": "chapter1.html#문과-출신의-평생-난제-통계",
    "href": "chapter1.html#문과-출신의-평생-난제-통계",
    "title": "1  통계는 왜 어려울까?",
    "section": "1.1 문과 출신의 평생 난제: 통계",
    "text": "1.1 문과 출신의 평생 난제: 통계\n\n1.1.1 통계는 왜 어려운 것일까?\n대부분의 사람들은 통계를 어려워합니다. 특히, 인문계열 출신들은 더욱 그렇습니다. 이 글을 쓰고있는 저도 통계가 어렵습니다. 물론, 통계가 어려운 이유는다양 합니다. 그러나, 기초 통계수준에서 많은 사람들이 어려움을 겪는 주된 이유는 사실이 책을 읽고있는 여러분들에게 있지않다는 것이제 생각입니다. 제가 처음 통계를 마주한 것이고등학교 시절정석이라는 수학참고서였습니다. 아마 대부분비슷할 것이라는 생각이 듭니다. 고등학교 당시에 배운 통계는 무조건 문제를 풀어서 정답을 맞춰야만 하는 것일 뿐이었고 수능에 나오지않았으면 하는 그런 대상이었습니다. 대학에 가서도 경영 통계나 일반통계강의를 들으면 도통 알 수없는 말들로 가득했고 여전히 시험기간이 되면 문제를 풀고정답을 찾기에 그저 바쁘기만 했습니다.\n\n\n1.1.2 통계가 어려운 첫 번째 이유\n여태 우리에게 통계란 그저 정답을 찾아야만 하는 문제였고, 그래서 어렵기만 했습니다. 정답을 찾아야 한다는 압박감이 여전히 우리의 뇌리에 자리 잡고 있으니 통계가 어렵게 느껴지는 것이 이상한 일은 아닙니다. 저도 가르치는 직업을 가진 사람으로서 과거의 통계 강의가 너무 어렵기만 했던 것은 아니었나 생각해봅니다. 물론 과거의 제 선생님들은 모두 훌륭하신 분들이었지만 저도 가르치면서 보니 아는 것과 가르치는 것은 많은 차이가 난다는 것을 깨닫게 되었습니다. 저도 선생으로서 첫 몇 년 동안 많은 고민과 어려움을 마주하면서 어떻게 통계를 가르쳐야 하나 고민이 많았습니다. 나름 쉽게 설명하고 있다고 생각했지만, 학생들은 여전히 어려워했고 다만 필기하고 암기하기에 바빴습니다. 문제는 통계가 암기과목이 아니라는 점이 함정이었습니다. 그래서 숫자와 기호 그리고 수식, 공식 등은 가급적 자제하고 말과 논리로서 통계를 가르치려 노력하다 보니 여기까지 오게 되었습니다.\n저는 통계 전문가가 아닙니다. 더구나 저는 통계 전공자도 아닙니다. 학부, 석사와 박사도 통계 전공을 한 사람이 아닙니다. 그러나 저는 오히려 비전공자로서 통알못(통계를 알지 못하는 분들)에게 어떻게 해야 더 쉽게 설명할 수 있을지 잘 알고 있다고 생각합니다. 인문사회계열의 전공자이면서 문과돌이로 살아온 사람들은 수학에도 약하지만 수학 공식을 보는 것 자체가 스트레스입니다. 제 생각에 통계가 어려웠던 이유는 통계 교육이 잘못 되어 있었기 때문이라고 봅니다. 절대 여러분들이 부족하거나 이해를 못하는 것이 아니라는 것을 저는 먼저 이야기하고 싶습니다. 통계를 정답을 찾아 풀어야만 하는 수학문제로 배워온 우리는 이제 다른 접근을 해야 합니다.\n\n\n1.1.3 통계가 어려운 두 번째 이유\n우리가 처음 외국어를 공부할 때를 떠올려 봅시다. 대부분의 경우 그 언어의 문자와 발음부터 시작해서 단어와 어순 그리고 문법을 공부하면서 차근차근 알아가게 됩니다. 외국어는 어렵긴 하지만 아무리 들어도 이해가 안 되는 통계와는 느낌이 많이 다릅니다. 그런데 저는 통계도 일종의 외국어라고 생각합니다. 문제는 외국어인 통계를 외국어처럼 가르치지 않는다는 것이 문제라고 생각합니다. 통계에서 사용되는 단어와 정의 그리고 의미 등은 애초에 우리의 일상생활과는 동떨어진 남의 나라 혹은 남의 행성 이야기입니다. 어쩌면 통계는 외국어 보다 외계어에 더 가까울 수도 있습니다. 왜냐하면 통계에서 이야기하는 논리의 흐름은 우리의 일상적인 생각의 흐름과는 완전히 다르기 때문입니다. 이제 한 에피소드를 살펴보겠습니다.\n\n\n1.1.4 안유의 주임의 보고서\n세컨마트에 다니는 회사원 3년차 안유의 주임은 금년 12월 매출이 지난 10년간의 12월 평균매출 보다 1,000만원이나 증가했다는 사실을 월간 매출 보고서 작성 중 발견했습니다. 이번 12월은 안주임이 새로 계획한 판매 전략을 시험했던 첫 달 이었고, 이에 안유의 주임은 본인의 새로운 판매 전략이 12월 매출을 1000만원 증가시켰다고 확신하고 보고서를 작성하였습니다. 안주임은 보고서를 서둘러 출력하여 정통해 부장에게 보고하였습니다.\n\n안주임: 부장님! 신규 판매 전략이 성공입니다! 12월 매출이 1000만원이나 올랐습니다!\n정부장: (곁눈질로 보고서를 잠시 보더니) 이보게!! 박경우과장!!\n박과장: 네, 부장님.\n정부장: 자네가 이 친구 기본적인 통계부터 좀 가르쳐야겠는데.\n안주임: 네??? 제 보고서에 무슨 문제가 있나요?\n\n저도 대형 유통회사에서 일 해본 경험이 있습니다만, 글쎄요. 우리나라에서는 절대 일어날 가능성이 없는 이야기이긴 합니다. 어떤 의미에서 불가능할까요? 제 경험상 얼마간이라도 매출이 증가하면 보통은 호들갑 떨며 보고하기에 바쁩니다. 이 일화의 정부장처럼 통계를 이해하고 대답해주는 경우는 거의 없을 것 같습니다. 하지만, 이제 여러분들은 달라질 것입니다. 그렇다면 안주임의 보고서는 무엇이 잘못일까요? 분명 매출이 1,000만원 오른 사건(event)은 사실(fact)입니다. 그렇다면 통계에서는 이 사건을 어떻게 생각하고 접근하는 것일까요?\n\n\n1.1.5 일상적 의사결정 vs. 통계적 의사결정\n지금부터 설명 하는 일상적 의사결정이나 통계적 의사결정이라는 용어는 제가 만들어낸 개념입니다. 그러니 어떤 통계 책에도 없을 것이므로 너무 용어의 정확성에 집착하지 마시길 부탁드립니다. 우리가 일상생활 속에서 무의식적으로 생각하는 생각의 흐름을 잘 따져봅시다. 인간은 일상생활에서 마주하는 세상의 수많은 신호(signal)를 받아들여 이를 모두 처리하는 것이 불가능합니다. 어떤 신호는 정보로서의 가치를 인정받지 못하고 우리의 뇌리 속에서 그냥 잊히기도 하고, 어떤 정보는 우리의 두뇌에 저장되고 판단되기도 합니다. 문제는 이러한 신호를 정보로서 해석하는 방법이 일상생활에서 매우 결정론적 이라는 것입니다. 여기서 결정론적이라는 의미는 원인과 결과 사이의 인과관계를 매우 직관적으로 판단하고 연결하여 이를 결정짓는 사고방식을 의미합니다. 예를 들어보겠습니다.\n\n새로운 판매 전략으로 월간 매출이 1,000만원이나 올랐으니 이번 전략은 대성공이야!!\n지난달에 수학학원을 다녔더니 중간고사 수학점수가 10점이나 올랐어!! 역시 학원을 가야 해!!\n지난주에 2년간 사귄 여자 친구와 헤어졌더니 체중이 3kg이나 늘었어. 이별의 아픔이 남긴 건 살뿐이로구나!\n\n어떤가요? 우리가 일상적으로 생각하는 의식의 흐름이 위와 같지 않나요? 매출이 1,000만원 증가한 것의 원인을 안주임은 자연스럽게 본인의 새로운 판매 전략 때문이라고 생각합니다. 어느 중학생은 학원을 다녀서 수학점수가 10점 올랐다고 믿습니다. 어떤 대학생은 여자 친구와 헤어지고 슬픔을 잊기 위해 폭식을 했더니 체중이 3kg이나 늘었다고 생각합니다. 이런 일들은 매일 매일의 우리의 삶 속에서 너무나 흔하게 일어납니다. 저의 삶에서도 그렇고 여러분들도 비슷할 것입니다. 너무나 일상적이고 너무나 직관적이기 때문에 저는 이를 결정론적인 의사결정이라고 부릅니다. 이것은 우리의 잘못이 아닙니다. 어쩌면 인간이 진화 과정에서 생존을 위한 빠른 판단을 반복적으로 하는 과정에서 누적된 자연스런 결과물일 것입니다. 위의 일상적인 의사결정 방법은 사실 통계적인 의사결정 방법과 많이 다릅니다. 쉽게 말해 아예 생각하는 방법 자체가 다른 것이지요. 그렇다면 과연 통계적인 의사결정이란 무엇일까요? 위의 세 가지 예를 통계적 의사결정의 방법으로 바꾸어 보았습니다.\n\n판매 전략의 변화로 월간 매출이 우연히 1,000만원 오를 가능성은 얼마나 될까?\n지난달에 수학학원을 다녀서 중간고사 수학점수가 우연히 10점 오를 가능성은 얼마나 될까?\n지난주에 2년간 사귄 여자 친구와 헤어져서 체중이 우연히 3kg 늘어날 가능성은 얼마나 될까?\n\n통계적 의사결정의 방법으로 바꾼 위의 세 가지 문장이 친숙하신가요? 만약 위의 세 개의 문장이 매우 익숙하다면 여러분은 이미 통계를 공부할 할 준비된 것입니다. 그러나 대부분의 사람들에게는 위의 문장은 매우 어색하고 이상해 보입니다. 그렇습니다. 그래서 통계란 외국어인 것입니다. 통계적 의사결정, 즉 통계적으로 생각한다는 것은 어떤 사건(event)이 우연히 발생할 확률을 묻는 것으로 시작합니다. 여기서 가장 중요한 단어는 바로 우연히 입니다. 일상생활에서 대부분의 사람은 이런 질문을 스스로에게 하지 않습니다. 그게 정상이라고 저는 생각합니다. 그러나 우리가 통계를 배우기 위해서는 이제 새로운 외국어를 배운다는 생각으로 우리의 생각의 방식을 바꿔야 합니다. 모든 문제를 어떤 사건(event)이 우연히 발생할 확률을 묻는 것으로 시작해야 합니다. 여기서 말하는 사건이란 위의 예에서 보자면, 매출이 1,000만원 오른 사건, 중간고사 수학점수가 10점 오른 사건, 그리고 체중이 3kg 늘어난 사건을 말합니다. 이 모든 것이 바로 사건(event)입니다. 반드시 기억합시다!!\n여태 통계가 어려웠던 이유는 우리 자신의 부족함 때문이 아닙니다. 애초에 통계는 외국어와 같은 것이라서 우리의 일상적인 생각의 흐름을 완전히 바꾸어 새롭게 시작해야 하는 것이기 때문입니다. 사실 통계수업의 첫 시간 그리고 통계 책의 첫 머리에서 우리의 일상적인 의사결정과 통계적 의사결정 사이의 차이점을 배웠어야합니다. 우리는 통계적 의사결정방식으로 생각을 바꿔야 통계적인 질문을 이해하고 통계가 찾고자 하는 길이 무엇인지 이해할 수 있습니다. 그러니, 여러분들이 통계를 어려워하는 것은 기존의 교육이 잘못된 것입니다. 통계란 정답을 찾아내는 수학문제가 아닙니다. 통계란 외국어와 같고 통계를 이해하려면 통계적인 의사결정 방법으로 생각할 수 있어야 합니다. 이렇게 생각의 전환이 이루어지지 않으면, 우리는 그저 여전히 통계문제의 정답만을 찾게 될 것입니다. 제가 강의를 하면서 느끼는 가장 안타까운 것이 바로 이 지점입니다. 학생들이 하는 대부분의 질문을 한 마디로 정리해 본다면, “그래서 정답이 뭔가요?” 라는 것입니다. 이러한 한계에서 벗어나야 합니다. 정답 찾기에서 벗어나 통계적 의사결정 방법으로 생각할 수 있어야 합니다. 그러니 이것만큼은 꼭 기억합시다. “어떤 사건이 우연히 발생할 확률이 얼마일까?”\n이제부터 통계로의 여행을 떠나봅시다!\nWelcome aboard!!\nYouTbue 바로 가기"
  },
  {
    "objectID": "chapter1.html#모든-통계책-첫-페이지에-평균과-표준편차가-나오는-이유",
    "href": "chapter1.html#모든-통계책-첫-페이지에-평균과-표준편차가-나오는-이유",
    "title": "1  통계는 왜 어려울까?",
    "section": "1.2 모든 통계책 첫 페이지에 평균과 표준편차가 나오는 이유",
    "text": "1.2 모든 통계책 첫 페이지에 평균과 표준편차가 나오는 이유\n\n1.2.1 평균과 표준편차\n통계에 관심을 가지고 통계를 공부해 보려고 노력해 보신 분이라면, 어떤 기초 통계학 책을 펴도 제일 앞장에 평균과 표준편차가 나온다는 것쯤은 다 알고 있을 것입니다. 그런데, 왜 모든 통계책의 시작은 평균과 표준편차일까요? 통계 공부하려고 책을 폈는데, 어처구니없는 질문을 하고 있다고 생각하시나요? 네. 어쩌면 그럴지도 모릅니다. 하지만 모름지기 모든 공부의 시작은 아는 것부터 그리고 당연한 것부터 질문하면서 시작해야 한다고 생각합니다.\n미국에서 공부하면서 알게 된 재미있는 것이 있습니다. 미국 학생들은 교수가 질문을 하면 정말이지 대답을 참 잘 합니다. 장점이지요. 단점이 있다면 한국 학생 입장에서 보자면 저걸 지금 말이라고 하나 싶은 수준의 대답들이 많습니다. 어처구니없는 질문을 하는 학생부터 말도 안 되는 대답을 하는 학생까지 참 많습니다. 그런데, 이런 미국 학생들의 특징은 모르는 것은 확실하게 질문하고 넘어간다는 사실입니다. 반면에, 한국 학생들은 정반대입니다. 한국 학생들은 보통 질문을 안 합니다. 미국 교수들이 그래서 처음엔 한국 학생들이 다들 너무 뛰어나다고 칭찬 일색이죠. 문제는 시험을 보고 나면 달라집니다. 한국 학생들 보다 미국 학생들의 학업 성취도가 높은 경우가 많기 때문이지요. 심지어 미국 학생들은 정말 실력이 그저 그랬는데, 학기가 마무리되어 갈 때 즈음이면 꽤 쟁쟁한 실력자가 되어 있습니다. 반면, 한국 학생들은 학기 초에는 뛰어나다고 평가 받다가, 학기 말이 되면 의외로 별 볼일 없게 마무리되는 경우를 종종 봅니다. 왜 일까요? 한국 학생들의 특징은 알면 질문하고 모르면 입을 닫기 때문입니다. 무엇을 알면 이를 뽐내고 싶어서 질문을 하고, 모르면 남들에게 부끄러워 입을 닫습니다. 교수에게 질문하지 않고 집에 가서 필기와 강의 자료를 열심히 암기합니다. 이렇게 되면, 투자하는 시간 대비 효율이 많이 떨어집니다. 비싼 돈 내고 유학까지 와서 교수에게 물어보면 될 간단한 문제를 혼자서 몇 시간이고 끙끙거리면서 고민하는 경우가 많지요.\n\n\n1.2.2 당연해보이는 것부터 질문합시다\n세상에 당연한 것은 없습니다. 그러니 당연한 것부터 질문해야 합니다. 도대체, 왜 통계책의 첫 페이지에는 언제나 평균과 표준편차가 등장할까요? 사실, 수많은 책들이 평균과 표준편차는 무엇이고 어떻게 계산하는지 설명하고 언뜻 보기에 복잡해 보이는 공식과 수식 그리고 그리스 문자까지 우리의 머릿속을 카오스로 만들어 버립니다. 여기에 더해 학생들은 책에 설명된 정의와 특징을 암기하고 열심히 문제를 풀어 시험에 대비합니다. 놀라운 것은 시험이 끝나고 시험장의 문을 열고 나오는 순간 머릿속엔 바로 지우개가 깔끔히 모든 암기 내용을 지워버립니다. 혹시 지금 바로 표준편차 공식을 종이에 써 볼 수 있는 분이 있을까요? 많은 분들이 아마도 헷갈리실 것입니다. 한 번 살펴볼까요?\n\\[\\sigma=\\sqrt{\\frac{\\sum(x_i-\\mu)^2}{N}}\\]\n기억이 나시나요? 기억을 못 하셨다 해도 아무 문제없습니다. 중요한 것은 이 수식을 보고 내용을 이해했느냐 아니냐가 가장 큰 과제일 뿐입니다. 저와 같은 문과돌이들은 위의 공식을 봐도 아무런 감흥이 없습니다. 왜냐하면, 이해가 안 되기 때문이지요. 선생님들은 이 공식이 무슨 뜻인지 자세하게 설명해 주셔야 맞지만 이걸 또 선생님 탓으로만 돌리기에는 좀 안타까운 면도 있습니다. 제가 미국에서 공부하던 시절, 어떤 통계학 수업을 들었는데 수업도중 등장한 공식 하나가 도저히 이해가 안되어 수업을 마치고 질문을 했습니다. 저의 질문에 교수님은 많이 당황하시면서 다시 그 공식을 친절하게 칠판에 쓰면서 이렇게 말씀하셨습니다. “What a beautiful equation it is!” 그러면서 저에게 왜 이게 이해가 안 되냐며 저를 이해하지 못하셨습니다. 이공계 출신은 공식만 보여줘도 그 의미를 이해한다지만 문과돌이는 그렇지 않습니다. 일단 우리는 이런 공식이 왜 필요한지부터 설득이 되어야 그 다음에 이해를 할 수 있는 사람들이기 때문입니다. 이제 우리는 왜 통계학 첫 페이지부터 평균과 표준편차가 등장하는지 설득 당하길 원합니다. 자, 이제 설득의 단계로 한 걸음 나아가 봅시다.\n\n\n1.2.3 스피드 퀴즈\n여러분들은 저와 함께 한 팀이 되어 게임을 할 것입니다. 우리가 할 게임은 스피드 게임입니다. 문제는 인물 문제이며 저는 문제를 맞히고 여러분은 저에게 그 인물에 대해 설명을 할 것입니다. 출제자가 어느 연예인이나 유명인사의 이름을 여러분들에게 보여줄 것입니다. 그럼 그 이름을 보고 그 사람의 생김새에 대해서 여러분은 저에게 설명을 해주셔야 합니다. 제가 빨리 맞힐수록 우리 팀이 승리하는 것입니다. 그러니 저에게 잘 설명해 주시길 부탁드립니다. 그럼 이제 게임을 시작해 봅시다!\n\n도널드 트럼프\n\n저에게 설명해 보세요. 어떻게 설명하실 건가요? 아마도 여러분은 트럼트라는 사람을 머릿속에 떠올리고 그의 대표적인 외형적 특징을 먼저 이야기 할 것입니다. 예를 들자면, 머리 스타일이 이렇고, 키가 어떻고, 눈이 어떻게 생겼으며, 코가 이렇고, 입술이 저렇게 생긴 목소리가 어떤 사람이다. 아마 이런 식으로 설명할 것입니다. 왜 그럴까요? 우리가 사람의 생김새를 설명할 때에는 그 사람의 가장 대표적인 특징을 특정하여 설명합니다. 눈썹이 진하다거나 입이 크다거나 코가 뾰족하다거나 하는 등의 것들이지요. 그럼, 다시 통계로 넘어와서 생각해 봅시다. 우리가 통계를 배우는 이유는 사실 우리가 가진 데이터(data)를 잘 분석하고 싶어서 입니다. 우리에게 데이터가 없다면 우린 통계를 공부할 이유가 없습니다. 통계의 시작은 사실 어떤 어려워 보이는 분석을 배우는 것부터 하는 것이 아닙니다. 우리가 가진 데이터를 설명하는 것으로부터 시작합니다. 즉, 우리가 가진 데이터가 어떻게 생겼는지를 다른 사람들에게 설명하는 것이 바로 통계의 시작입니다. 이것은 마치 여러분이 저에게 트럼프를 설명하는 것과 동일합니다. 그렇다면 우리는 우리가 가진 데이터의 생김새를 다른 사람에게 설명할 때 어떻게 해야 할까요? 정답은 간단합니다. 우리가 방금 게임에서 했던 것과 같은 방법으로 하면 됩니다. 즉, 우리가 가진 데이터의 대표적인 특징을 특정하여 설명하면 되는 것입니다.\n그렇다면 데이터의 대표적인 특징이란 무엇일까요? 그것은 바로 대푯값입니다. 대푯값이란 우리가 가진 데이터가 가진 값 중 가장 대표되는 그러면서 데이터를 가장 잘 설명하는 값을 대푯값이라고 합니다. 통계에서 주로 이야기하는 대푯값은 이렇습니다.\n\n평균 (average; mean)\n중앙값 (median)\n최빈값 (mode)\n표준편차 (standard deviation)\n분산 (variance)\n구간 (range)\n최솟값 (min; minimum)\n최댓값 (Max; Maximum)\n\n위에서 나타나 있듯이, 평균과 표준편차가 바로 여기서 등장합니다. 일단 우리는 여기서 평균과 표준편차의 역할이 우리가 가진 데이터의 특징을 설명하는 대표적인 대푯값 중 하나라는 사실을 알았습니다. 우리가 통계책 첫 페이지를 펴면 등장하는 평균과 표준편차가 왜 가장 앞에 나오는지 이해가 되시나요? 지금 우리는 통계의 첫 발을 떼고 있는 것이고, 그 첫 단계로서 우리는 복잡한 통계 방법론이 아니라 가장 단순하게 어떻게 우리가 가진 데이터를 다른 사람들에게 잘 설명할 수 있을지 배우는 것입니다. 이게 가장 쉬운 것이면서도 시작이고 또한 매우 중요한 부분이기 때문이지요. 여러분들이 가진 데이터가 있다면 그 데이터를 다른 사람에게 설명해 보실 것을 권해 드립니다. 물론 위에 등장하는 대푯값을 이용해서 해 보시길 바랍니다.\n\n\n1.2.4 누구나 다 아는 평균과 표준편차\n과연 그럴까요? 여러분들은 평균과 표준편차를 확실하게 이해하고 있습니까? 그 의미를 설명해볼 수 있나요? 참으로 애매할 것입니다. 분명히 내가 모르는 것은 아닌데, 알기는 아는데 이렇게 훅 치고 들어오면 당황하기 마련입니다. 그럼, 평균부터 알아봅시다. 아마도 평균이 무엇인지 모르는 분은 거의 없을 것입니다. 평균의 계산방법은 아래와 같습니다.\n\\[Mean=\\mu=\\frac{\\sum_{i=1}^{n}{x_i}}{N}=\\frac{Sum}{N}\\]\n위에서 mean은 영어로 평균이란 뜻이고 \\(\\mu\\) 는 그리스어로 “뮤”라고 읽습니다. 평균이란 의미로 통계학에서 사용되는 기호입니다. 왜 이런 어려운 글자를 썼을 까요? 글쎄요. 저도 이런 그리스 문자를 좋아하지 않습니다. 그냥 영어의 알파벳을 써도 될 거 같은데, 오래전부터 이렇게 써 왔다고 합니다. 예나 지금이나 똑똑한 사람들은 어려운 말을 쓰는 걸 즐겨했던 것 같습니다. 그 다음에 등장하는 분수의 분자에 있는 \\(\\sum\\) 는 시그마라고 읽기도 하고 영어로 sum 이라고 읽기도 합니다. 이 역시 그리스 문자이고 그 기능은 모든 숫자를 합하라는 의미 입니다. 그러니 위의 수식은 모든 \\(x\\) 를 더하라는 의미가 됩니다. 아래 분모의 \\(N\\)은 데이터의 개수입니다. 여기서 개수란 위의 분자에서 몇 개의 숫자가 더해졌는지를 의미합니다. 통계에서는 이를 사이즈라고 부르기도 합니다. 데이터가 몇 개나 되느냐라는 의미입니다. 가장 우측에는 좀 쉬운 말로 써 봤습니다. 물론 통계학에서 사용되는 표기법은 아닙니다. 여기서는 여러분들의 이해를 돕기 위해 사용된 것입니다. 그럼 예를 들어보겠습니다. 우리가 가진 데이터가 \\({1, 2, 3, 4, 5}\\)라고 합시다. 정말 작은 데이터이지만 예제로 보기엔 좋습니다. 이 데이터의 평균을 구해 봅시다. 얼마인가요?\n\\[(1+2+3+4+5)\\div5=3\\]\n너무 쉬운가요? 그렇다면 평균이 가진 특징은 무엇일까요? 그리고 어떤 의미가 있을까요? 데이터의 어떤 특징을 나타내는 것일까요? 평균이란 데이터의 중심값으로서 데이터의 특성을 대표하는 값입니다. 여기서 중심값이라는 개념은 쉽게 말해 대표선수라는 것입니다. 우리가 위에서처럼 5개가 아닌 5억 개의 데이터를 가지고 있을 때, 그중 대표가 되는 단 하나의 숫자를 말하라면 그게 바로 평균입니다. 왜냐하면 이 값은 데이터의 중심이기 때문입니다. 그러나 이 대푯값은 약간의 약점이 있습니다. 단 한 개라도 어떤 값이 너무 치우치게 크거나 작으면 그 값에 의해 평균값은 심하게 요동칩니다. 우리는 이렇게 비정상적으로 크거나 작은 값을 아웃라이어(outlier)라고 합니다. 이상치 혹은 이상값이라고도 합니다. 물론 이 값이 이상한 것인지 아닌지는 두고 봐야 할 일이지만 어쨌든 이런 값이 하나라도 존재하면 평균은 그 값이 있는 방향으로 심하게 움직입니다. 위의 예를 조금 바꿔 보겠습니다. 만약, 우리가 가진 데이터가 \\({1, 2, 3, 4, 5, 99}\\) 라고 하면 우리는 앞에서 본 데이터에 비해 99란 단 한 개의 값을 더 가지고 있습니다. 그러면 이때, 평균은 어떻게 될까요?\n\\[(1+2+3+4+5+99)\\div5=19\\]\n단 한 개의 값이 추가될 뿐이지만 평균은 3에서 19로 움직였고 99가 있는 방향으로 평균이 이동한 것 입니다. 사실 평균은 무게중심과 같습니다. 어느 값 하나가 우측으로 멀리 떨어져 있으면 무게중심이 우측으로 이동하는 것과 같습니다. 하지만, 평균의 역할은 여기서 끝나지 않습니다. 평균은 대푯값으로서 혼자 빛이 나는 그런 존재가 아닙니다. 오히려 평균은 주연과 조연을 오가면서 통계의 대푯값으로서 굉장히 중요한 역할을 합니다. 혼자서는 주연이지만 평균은 표준편차와 만날 때, 조연의 역할을 합니다. 사실 표준편차를 알고자 하면 먼저 평균을 계산해야 합니다. 그럼 이제 표준편차에 대해 알아보겠습니다. 표준편차는 분산에 제곱근을 씌운 것입니다. 그러니 분산에서부터 시작하는 것이 쉽겠습니다. 분산은 영어로 variance라고 합니다. 여기서 vari-는 변화한다는 의미인 vary라는 동사에서 온 것이라고 보시면 됩니다. 즉 분산은 기본적으로 변화하는 어떤 값을 의미하는 것입니다. 분산(variance)의 계산은 다음과 같습니다.\n\\[Variance=\\sigma^2=\\frac{\\sum_{i=1}^{n}(x_i-\\mu)^2}{N}\\]\n가끔 어떤 경우에는 분산의 식을 이처럼 쓰는 경우도 있습니다.\n\\[Variance=s^2=\\frac{\\sum_{i=1}^{n}(x_i-\\bar{x})^2}{n-1}\\]\n비슷해 보이는데 뭔가 좀 다르죠? 사실 위의 것은 모집단에 대한 것이고 아래의 것은 표본에 대한 것입니다. 아직 모집단이 뭐고 표본이 뭔지 모르니 일단 여기서는 그런가보다 하고 넘어갑시다. 그럼 앞에서 보았던 예를 가지고 다시 분산을 계산해 봅시다. 앞에서 우리가 가진 첫 번째 데이터는 \\({1, 2, 3, 4, 5}\\) 였습니다. 여기서 평균은 당연히 3이었습니다. 이제 이 평균 3을 이용하여 분산을 계산해 봅시다. 단 여기서 우리는 위의 두 공식 중 두번째 분산의 공식을 이용할 것입니다.\n\\[\\frac{(1-3)^2+(2-3)^2+(3-3)^2+(4-3)^2+(5-3)^2}{4}=2.5\\]\n계산은 모두 끝났습니다. 분산은 2.5입니다. 그렇다면 도대체 분산은 무엇이고 왜 이따위로 생겨 먹었을까요? 분산이란 우리가 가진 데이터가 평균을 중심으로 얼만큼 퍼져 있는가를 말해 주는 대푯값입니다. 다시 말해, 우리가 가진 데이터가 평균값인 3을 중심으로 평균적으로 약 2.5만큼 떨어져 있다는 의미 입니다. 평균값으로부터 데이터가 퍼져 있는 평균적인 거리(distance)라고 이해하면 됩니다. 그럼 다시 생각해 봅시다. 우리의 데이터는 \\({1, 2, 3, 4, 5}\\)였습니다. 평균은 3이고 분산은 2.5입니다. 3으로부터 2.5 떨어져 있다면 \\(3\\pm2.5\\) 를 계산해 보면 됩니다. 값은 0.5와 5.5 입니다. 뭔가 좀 이상하지요? 이유는 간단합니다. 우리가 제곱을 하여 값을 합산했기 때문입니다. 그러므로 여기에 다시 제곱근을 붙여 분산을 표준편차로 바꾸면 평균값과 단위가 일치하게 됩니다. 2.5에 제곱근을 씌우면 약 1.58정도 됩니다. 따라서 우리의 데이터는 3을 중심으로 1.58정도 퍼져 있는 것이고 그 범위는 대략 1.42부터 4.58정도 입니다. 우리의 데이터가 \\({1, 2, 3, 4, 5}\\)이므로 이 두 대푯값은 훌륭하게 우리의 데이터를 표현해 줍니다.\n\\[\\frac{(1-3)^2+(2-3)^2+(3-3)^2+(4-3)^2+(5-3)^2}{4}=2.5\\]\n분산의 계산내용을 다시 살펴봅시다. 분산의 의미는 우리의 데이터가 평균을 중심으로 얼마나 평균적으로 멀어져 있는지 보고자 하는 것이라고 했습니다. 그래서 위의 식을 들여다보면 우리가 가진 데이터의 개별 값인 \\({1, 2, 3, 4, 5}\\)에서 각각 평균인 3을 빼고 있습니다. 즉 \\((1-3)=2\\) 라는 값은 1이라는 첫 번째 데이터 값에서 평균까지의 거리 2를 의미합니다. 이런 식으로 보면 값들이 어떤 것은 양수 이고 어떤 것은 음수가 됩니다. 만약, 우리가 이 양수와 음수를 섞어서 모두 합산을 하게 되면 우리가 알고자하는 평균적으로 퍼져있는 거리의 거리 개념이 뭉개지게 됩니다. 이러한 문제를 해결하고자 분산을 계산할 때, 모든 값을 제곱을 하여 강제로 양수로 만들고 이를 더하는 것입니다. 그러고 나서 평균적인 거리를 알고 싶으므로 데이터의 개수로 나누어 줍니다. 다만, 여기서는 데이터의 개수가 5개인데 나눌 때는 4로 나누었습니다. 이는 우리가 처음에 두 개의 분산의 식 중 두 번째 것을 쓰기로 약속했기 때문입니다.\n그런데, 이상하지요? 왜 5가 아닌 하나를 뺀 4로 나눌까요? 위의 분산의 공식에 등장하는 \\(n-1\\)은 쉽게 설명하기 어려운 존재입니다. 특히 기초 수준에서는 이해할 수 없는 상황이 됩니다. 일단 이 부분에 대한 가장 직관적인 간단한 설명은 이것입니다. 분산의 계산식을 들여다보면 우리는 5개의 값에서 5번을 계속해서 평균으로 빼는 작업을 반복했습니다. 우리의 데이터에서 보면 평균이 3이기도 하지만 우리가 가진 데이터에도 3이란 값이 있었습니다. 따라서 우리는 평균값을 뺀 것이긴 하지만 우리가 가진 데이터 중 3이라는 값을 잃은 것과 비슷합니다. 계속해서 평균값을 빼는 작업을 반복한 탓입니다. 그래서 이렇게 평균값을 감안해서 데이터의 개수가 아닌 데이터의 개수에서 하나 작은 숫자로 나누어주는 것입니다. 다르게 말하면, 평균을 한 번씩 계속 빼 주었으니, 우리의 데이터의 개수는 \\(n-1\\) 개라고 보는 것이지요. 사실 이 \\(n-1\\) 이라는 값은 뒤에 등장할 자유도 (degree of freedom)이라는 개념과도 일맥상통합니다. 보통은 통계를 처음 공부하다가 이 문제를 만나면 통계를 포기하기도 합니다. 여러분 절대 그러지 마세요. 제가 여러분과 함께 가겠습니다. 자유도에 대해서는 뒤에서 따로 설명하겠습니다. 일단 이런 개념이 있다는 정도만 알고 계속 분산에 대한 이야기를 합시다.\n다시 강조 하자면, 분산이란 내가 가진 데이터가 평균값을 중심으로 퍼져 있는 평균적인 거리를 의미 합니다. 왜냐하면 계산에서 보았듯이, 분자부분은 자료의 값이 평균값으로부터 얼마나 먼 거리에 있는지의 합입니다. 이 거리의 합을 자료의 개수로 나누어 자료의 값들이 평균값으로부터 평균적으로 얼마나 멀어져 있는지 알아보는 것입니다. 이 계산의 분자부분을 제곱 합이라고 표현하고, 분모부분은 자유도라고 표현합니다. 제곱 합이란 제곱한 것들의 합이라는 의미입니다. 자유도는 뒤에서 좀 더 자세히 알아보겠습니다. 결국, 분산이란 제곱 합을 자유도로 나눈 값입니다. 이 분산에 제곱근을 씌우면 우리는 표준편차를 얻을 수 있고 이 표준편차와 평균값은 단위가 같아지게 됩니다. 값이 다소 다르긴 하나 결국 분산과 표준편차 모두 같은 의미인 것입니다. 분산에 대해 이렇게 강조하는 이유가 뭘까요? 이장의 마지막에 이야기 하겠습니다.\n\n\n1.2.5 왜 굳이 평균과 표준편차일까?\n그렇습니다. 앞서 우리는 여러 가지의 대푯값이 있다는 것을 배웠습니다. 즉, 대표선수들이 꽤 많다는 것입니다. 올림픽이나 월드컵경기를 보면 가끔 그런 경우들이 있습니다. 꽤 훌륭한 선수인데 국가대표에 선발되지 못해 국제대회에 나가지 못하는 경우를요. 많이 아쉽지요. 하지만 국가별 대항의 의미와 그 나라에서 가장 뛰어난 선수를 출전시킨다는 점을 생각해 보면 어쩔 수 없습니다. 즉, 훌륭한 선수이지만 우리는 최선의 결과가 아닌 최고의 결과를 원하기 때문입니다. 통계의 경우에도 평균 대신 이를 대신할만한 대푯값이 분명히 존재합니다. 예를 들면 중앙값(median)과 같은 것이 있습니다. 의미상 중앙값 역시 데이터의 중심을 표현하는 값이 맞습니다. 다만 중앙값(median)은 수리적 계산으로 값을 구할 수 없다는 단점이 존재합니다. 하지만 평균과는 다르게 아웃라이어(outlier)에 영향을 거의 받지 않습니다. 또 다른 중심값으로서 최빈값(mode)이 있습니다. 우리가 가진 데이터에서 가장 많이 등장한 숫자를 최빈값으로 지정하고 이 값을 데이터를 대표하는 중심값으로 사용하는 것입니다. 문제는 이 역시 결국 수리적 계산에 의해 구할 수 있는 값은 아닙니다. 게다가 중심값의 대푯값으로 쓰기엔 좀 애매해 보이지요.\n그렇다면, 표준편차나 분산을 대신할 만한 통계의 대푯값은 어떤 것이 있을까요? 위의 리스트에도 있듯이 구간(range)이 있습니다. 이 구간(range)는 사실 넓게는 최솟값(min)과 최댓값(Max)의 차이를 일반적으로 의미합니다. 하지만 이 구간도 다른 여러 가지 방법으로 정의하고 사용 가능합니다. 표준편차나 분산이 결국 우리가 가진 데이터의 퍼져있는 정도를 의미하는 대표선수라면 구간 역시 이러한 기능을 할 수는 있습니다. 하지만 표준편차나 분산에 비해 너무 단순하고 우리에게 제공하는 정보가 빈약함을 알 수 있습니다.\n이정도까지만 봐도 다른 대푯값에 비해 평균과 표준편차(혹은 분산)이 다른 대푯값보다 더 나은 점이 있다는 것은 알 수 있습니다. 하지만 많은 수학자와 통계학자들은 이 정도에서 그치지 않고 왜 평균과 표준편차가 더 우월하며 통계의 발전에 이익이 되는지를 연구하고 증명한 바 있습니다. 이러한 내용은 사실 제가 자세하게 설명할 만한 능력이 없기도 하거니와 통알못인 여러분들이 지금 이해하기엔 너무 어려운 내용들이니 간단하게 이야기 해보겠습니다. 희대의 천재인 가우스(Gauss)란 분은 만약 데이터의 불규칙성이 정규분포를 따르면 최소제곱법이 가장 좋은 추정방법이며 그 결과 평균이 가장 좋은 추정값이 된다고 증명하였답니다. 이렇게 말하면 너무 어렵습니다. 여기서 정규분포라던 지 최소제곱법이라던 지 이런 용어를 모르시니 당연히 이해가 안 되고 설사 이런 용어를 알더라도 저 문장만으로는 너무 의미가 어렵습니다. 간단히 말해 가우스는 평균값이 우리가 가진 데이터의 중심을 대표하는 대푯값으로서 가장 좋다는 것을 증명했다고 보시면 됩니다. 이 문제에 자꾸 목을 매면 우리는 점점 수렁으로 빠져듭니다. 그러니 믿고 가봅시다. 또 다른 한편으로는 체비체프(Chevyshev)라는 분은 데이터가 정규분포를 따르던지 따르지 않던지 이 세상의 모든 데이터는 평균값\\(\\;\\pm\\; 2 \\times\\)표준편차 범위 안에 반드시 전체 데이터의 \\(\\frac{3}{4}\\) 이상의 데이터가 존재한다고 증명하였습니다. 그냥 봐서는 그래서 뭐? 이런 생각이 들긴 하지만 다시 생각해보면 이 세상 모든 데이터를 들여다보면 우리는 언제나 데이터의 75% 이상을 평균과 표준편차만 알면 그 구간을 구할 수 있다는 것입니다. 즉, 평균과 표준편차만으로도 데이터의 상당부분을 설명 가능하다는 것이 큰 의미입니다.\n\n\n1.2.6 그래서, 뭐?\n그렇죠. 그래서 뭐 어쩌란 말인가요? 일단 여기쯤 오면 우리는 인정해야만 합니다. 평균과 표준편차가 통계에서 사용될 대푯값이며 대표선수라는 점을요. 결론적으로 평균과 표준편차는 다른 대푯값에 비해 계산이 용이하고 통계 전반에서 참값을 추정하는 추정값으로서 제일 우수하다는 점입니다. 이렇게 중요한 대표선수이니 당연히 모든 통계책의 첫 페이지에는 평균과 표준편차가 등장해야 맞습니다. 물론 통계를 아직도 어려워하시는 분들에게는 여전히 의심의 대상일 것입니다. 평균과 표준편차가 그나마 가장 효율적인 그리고 뛰어난 대표선수라는 점이 믿기지는 않으시겠지만 혹은 싫겠지만 일단 믿고 가봅시다. 우리가 공부하는 통계학이라는 분야는 그 시작과 기초가 평균과 표준편차입니다. 그만큼 중요하다는 것이지요. 너무 쉬워보였지만 사실 정말 대단한 대표선수라고 보시면 됩니다. 그런데, 왜 이렇게 제가 평균과 표준편차를 강조할까요? 사실 평균과 표준편차 둘 중에 누가 더 중요하냐고 저에게 물으신다면 저는 이렇게 말하겠습니다.\n\n\n1.2.7 분산이 제일 중요합니다!\n갑자기 제가 왜 이러는지 당황스럽죠? 당연합니다. 그러나 일단 저는 여러분들에게 통계 공부를 시작하는 이 시점에서 매우 중요한 그리고 핵심적인 한 마디를 하고 싶습니다. 누군가가 통계가 무엇이냐고 묻는 다면 저는 이렇게 말하겠습니다. 통계란 분산의 마법이다. 이제는 분산이나 표준편차나 다 같은 것이니 분산 말고 표준편차는 안 되냐는 질문은 하지 마시길 바랍니다. 여러분들이 앞으로 통계를 이해해 나가는 중심에는 분산이 있습니다. 앞으로 보게 될 기초 통계는 분산만 잘 알고 있으면 단 몇 분 안에 이해할 수 있는 것들 입니다. 그러니 이것만 기억합시다.\n통계란 분산의 마법이다!\nYouTube 바로 가기"
  },
  {
    "objectID": "chapter1.html#왜-유의할까",
    "href": "chapter1.html#왜-유의할까",
    "title": "1  통계는 왜 어려울까?",
    "section": "1.3 왜 유의할까?",
    "text": "1.3 왜 유의할까?\n\n1.3.1 p값이 0.05보다 작으니 유의하다\n통계를 조금이라도 공부해 보았거나 과거에 했던 공부를 떠올려 본다면 다른 것은 다 잊어버려도 이것 하나 만큼은 기억나실 겁니다. “p값이 0.05보다 작으니 유의합니다.” 도대체 이게 무슨 뜻일까요? 솔직히 한국말이긴 한데 외계어처럼 보이는 것이 사실입니다. 여기서 우리가 확실하게 아는 것은 0.05보다 작다는 것 말고는 다른 말은 이해가 되지 않습니다. 게다가 왜 0.05인가에 대해서도 의문이 생길 수밖에 없습니다. 도대체 p값은 무엇이고 유의하다는 것은 무슨 뜻일까요? 이렇게 자주 등장하고 이렇게 중요하고 이렇게 기초적인 개념이 이상하게도 통계학 책에는 설명이 잘 되어있지 않습니다. 정말 이상하지요? 저도 그렇게 생각합니다. 20대 후반에 회사를 다니다가 미국으로 건너가 석사과정을 시작하면서 몇 년간 안하던 공부를 하는 것도 힘든데, 공부를 영어로 하는데다가 영어로 통계학을 하니 눈앞에 캄캄했습니다. 미국 책이라고 더 친절한 것만도 아니었으니까요. 영어도 잘 못하는 아시아인이 할 수 있는 일이라고는 매번 통계강의 끝에 교수님을 붙들고 안 되는 영어로 끈질기게 물어보는 것뿐이었습니다. 물론 그래도 해결이 잘 안되어 도서관에 있는 기초 통계책은 모조리 빌려다가 같은 주제에 대해 이렇게도 읽어 보고 저렇게도 읽어보며 제 나름대로 이해하기 위한 논리를 만들어 갔습니다.\n통계가 어려운 이유는 이렇게 외계어에 가까운 외국어인 통계의 기본 용어들에 대한 자세한 설명이 없다는데 있습니다. 물론, 다시 말씀드리지만 저는 통계 비전공자 입니다. 그래서 통계학 박사님들이나 통계학과 교수님들이 보시기에 제가 지금부터 하는 설명은 엄밀한 의미로 통계학적 맥락에서는 문제가 있는 혹은 잘못된 설명일 수도 있습니다. 하지만, 저의 철학은 다릅니다. 제가 수년간 학생들 심지어 박사 학생들을 가르쳐 보니 p값조차 잘 이해하지 못하고 앵무새처럼 “p값이 0.05보다 작으니 유의하다”는 말만 반복하는 것을 너무나 많이 보았습니다. 어린 아이에게 어른이 먹는 음식을 먹여야 한다는 식의 접근은 자칫 큰 문제를 야기할 수 있습니다. 일단 아이가 먹을 수 있는 부드러운 식사부터 시작해서 서서히 어른이 먹는 음식으로 전환해 가는 것이 맞다고 봅니다. 지금 여러분은 통계의 어린이입니다. 일명 통린이라고 하지요. 다소 오류가 있는 설명이라도 일단 통계의 바다에서 생존할 수 있는 기본기를 만들어 가 봅시다. 생존이 가능해야 그 다음에 이 통계의 바다를 여행도 하고 즐길 수 있지 않을까요?\n\n\n1.3.2 p-value (p값)이란 무엇인가?\n지금도 기억하는 일화가 있습니다. 박사 방법론 수업에서 p값, 영어로 p-value는 무엇의 약자일지를 질문했습니다. 여기서 당연히 value는 우리말로 값으로 번역되었습니다. 그러면 p는 영어 단어 중 무엇의 약자일까요? 여러분들도 잠시만 눈을 감고 생각해 보시길 바랍니다. 여러분들이 알고 있는 p로 시작하는 영어 단어를 모조리 쏟아 내 보세요. 어떤 것이 과연 이 p값의 p일까요?\n혹시, possibility? 아니면 problem? preference? percent? 제 질문에 박사학생들이 많이 당황했던 기억이 납니다. 참 이상하지요? p값이란 말은 모든 통계책에 등장하고 어느 통계 수업에서도 p값이란 말 없이 강의가 진행되지 않습니다. 그런데, 어떤 선생님도 이에 대해 설명하지 않고, 어떤 학생도 질문하지 않습니다. 항상 이야기 하는 것이지만 우리는 당연한 것에 대해서도 의문을 가져야 합니다. 많은 학생들이 이런 당연한 것을 잘 모르는 것을 오히려 당연하게 여기는 것이 문제입니다. 물론 선생님들이 가르쳐주지 않은 것이 먼저 문제일 수도 있겠습니다.\np-값의 p는 probability 즉 확률을 의미합니다. 따라서 p값이란 확률값입니다. 그렇다면 여기서 말하는 확률값이란 무엇일까요? 우선, 우리가 반성할 점이 있다면 그렇게 자주 이야기하던 p값이 확률값인지 모르고 수도 없이 계산하고 정답을 찾고 해석을 해왔다는 점입니다. 지금부터 할 이야기는 앞에서 이야기한 내용에 연결됩니다. 앞에서 통계적 사고는 우리의 일상적 사고와 다르다고 이야기 했습니다. 통계적 사고를 하기 위해서는 우리가 일상에서 발생하는 모든 사건에 대해 이렇게 생각해야 한다고 했습니다. 어떤 사건이 우연히 발생할 확률이 얼마일까?\n이 질문에서 우연히 발생할 확률의 확률이 바로 우리가 말하는 p값입니다. 즉, 우리가 일상의 어떤 사건을 바라볼 때, 우리는 이 사건이 발생할 확률을 구해보고 그 결과인 확률값 즉 p값을 구한 뒤에 어떠한 통계적 결정을 하는 것입니다. 물론, 앞서 이야기 했듯이 정통 통계학적 접근에서 본다면 이 설명은 완벽하지 않습니다. 그러나 지금은 이정도만 이해하는 것이 좋습니다. 계속 공부해 가면서 p값이 가진 다른 의미들 혹은 좀 더 깊은 의미에 대해 알아보겠습니다. 꼭 기억하시길 바랍니다. p값이란 확률값이고 이 확률값은 어떤 사건이 우연히 발생할 확률의 바로 그 확률입니다.\n\n\n1.3.3 그래서 무슨 뜻일까?\n이제 우리는 p값이 무엇인지는 알았습니다. 그런데 항상 통계에서 p값이 0.05보다 작으니 유의하다고 하는 말은 무슨 뜻일까요? 일단 우리는 p값이 확률값이라는 것을 알았으니 확률값의 특성은 0부터 1까지 존재한다는 것을 눈치 챌 수 있습니다. 이를 %로 바꾸면 0.05는 5%가 됩니다. 확률값 p값이 5%보다 작으면 유의하다고 다르게 표현할 수 있겠습니다. 여기서 유의는 한문으로 유는 有로서 “있을 유”가 사용되고 의는 意로 “뜻 의”를 사용합니다. 여기서 유의하다는 것은 의미가 있다로 해석할 수 있습니다. 즉, p값인 확률값이 5%보다 작으면 의미가 있다고 해석합니다. 그런데 아직도 이게 무슨 뜻인지 이해가 잘 안되지요? 일단 왜 하필 5%일까요? 10%나 아니면 1%는 안 될까요?\n\n\n1.3.4 유의하다?\n통계에서 유의하다는 말은 영어로 significant입니다. 이 단어의 뜻은 중요한, 의미심장한, 상당한, 의미 있는 이런 뜻입니다. 이제 통계적 사고방식으로 돌아가 봅시다. 어떤 사건이 우연히 발생할 확률이 얼마일까? 라는 이 질문의 확률이 p값이고 이 확률값이 5%보다 작으면 유의하다는 의미는 이 사건이 일어날 확률이 낮다는 의미입니다. 따라서 우연히 발생할 확률이 낮은 이 사건은 우연히 발생한 것이 아니라 무엇인가 의미 혹은 이유가 있다고 해석합니다. 그래서 우리는 5%보다 작으면 유의하다는 말을 하는 것입니다. 반대로 만약에 어떤 사건이 우연히 발생할 확률이 5%보다 크다면 이 사건은 우연히 발생했다고 결론 내리고 이 사건이 발생하는데 있어 특별한 원인이나 이유가 없다고 보는 것입니다. 보통 어떤 인과관계를 통계적인 방법으로 검증해 보고자 할 때, 만약 p값이 5%보다 작으면 이 사건의 어떤 원인 때문에 이 사건의 결과가 발생했다고 결론내립니다. 그러나 만약에 p값이 5%보다 크면 이 사건은 어떤 인과관계 없이 우연히 발생했다고 결론내립니다. 그러므로 유의하다는 의미를 이해하려면 통계적인 사고방식의 통계적 질문을 이해해야 합니다.\n\n\n1.3.5 그런데 왜 5%일까?\n이 정도 이해를 하면 이제 다른 질문이 생길 것입니다. 왜 하필이면 5%일까? 제가 미국에서 공부할 때, 강의 후에 교수님을 찾아가 왜 5%이냐고 물었습니다. 10%나 아니면 1%는 안 되는 이유가 무엇이냐고 물었지요. 그 때, 교수님께서 말씀하시길 복잡한 이유와 역사가 있지만 간단하게 말하자면 과거에 프랑스의 수학자들끼리 정해놓은 것이니 너무 집착하지 말라고 하시더군요. 사실, 참 어처구니없기는 하지만 과거에 사람들이 정해 놓은 것이고 지금까지 이 원칙을 대부분의 사람들이 따르고 있으니 우리가 이 5%의 규칙을 따르는 것에는 큰 문제는 없을 것 같습니다. 다만, 여러분들이 꼭 알아야 하는 것은 이 5%의 규칙이 진리는 아니라는 것입니다. 즉, 5%보다 p값이 작은 것을 절대적인 선 혹은 절대적인 진리로 생각하시면 안 된다는 것입니다. 이것은 매우 위험한 발상입니다. 가끔 대학원생들 중에 5%보다 p값이 작게 나왔으니 이 결과에 대해서 아무런 문제가 없으며 이에 도전하는 것은 절대 진리를 거부하는 것이라는 식의 잘못된 믿음에 사로잡힌 경우를 봅니다. 이와 관련한 여러 가지 주의사항이 있지만 이것 하나만큼은 꼭 이야기 하고 싶습니다. 통계적 유의성(statistical significance)과 실질적 유의성(practical significance)는 다르다는 점입니다. 즉, 통계적으로 유의하더라도 이러한 결과가 현실에서 실질적으로 유의한 것과는 다를 수 있다는 것입니다.\n정리해 보면, 이렇습니다. p값이 5% (0.05) 보다 작다는 것은 어떤 사건이 우연히 발생할 가능성이 없다는 뜻이므로 이 사건의 발생에 무언가 이유가 있다는 뜻입니다. 이를 우리는 유의하다 (significant)고 표현하고 이 사건에는 인과관계가 있다고 해석합니다. 반대로, 만약에 p값이 5% (0.05) 보다 크다면, 이 사건은 우연히 발생했다고 판단합니다. 즉, 이 사건의 발생에는 어떤 인과관계가 없다는 뜻입니다. 이제 p값이 조금 이해가 되시나요? 차근차근 이제 조금 더 앞으로 나아가 봅시다.\nYouTube 바로 보기"
  },
  {
    "objectID": "chapter1.html#왜-이렇게-복잡할까",
    "href": "chapter1.html#왜-이렇게-복잡할까",
    "title": "1  통계는 왜 어려울까?",
    "section": "1.4 왜 이렇게 복잡할까?",
    "text": "1.4 왜 이렇게 복잡할까?\n\n1.4.1 통계적 가설과 오류\n통계책의 앞부분에 등장하지만 대부분 그냥 알겠거니 하고 넘어가는 바로 그것이 바로 통계적 가설과 오류입니다. 그런데, 사실 자세히 들여다보면 알듯 말듯 하다가 헷갈리고 그러다가 통계를 이해하는 대세에는 큰 무리가 없을 것 같아 적당히 넘어가는 부분입니다. 이런 것들이 통계책에 등장합니다.\n\\[H_0: D_{A-B}=0\\] \\[H_a:D_{A-B}\\ne0\\]\n이번에는 이 통계적 가설과 오류에 대해 알아보겠습니다. 이게 도대체 무슨 뜻일까요? 도대체 왜 통계학자들은 이런 복잡한 것들을 앞부분에 많이 설치해 두었을까요? 일단 암호같이 생긴 저 위의 기호들을 하나씩 차례로 알아봅시다. 위의 두 줄은 통계적 가설이라고 합니다. 이 두 줄은 항상 함께 움직입니다. 동시에 이 두 가설을 서로 경쟁하는 관계에 있습니다. 첫 번째 줄을 먼저 살펴봅시다. \\(H\\)라는 대문자는 영어의 Hypothesis의 약자입니다. 가설이라는 의미입니다. 그 아래의 작은 글자 \\(0\\)은 숫자 zero입니다. 이 가설은 영어로 null hypothesis 라고 합니다. null이라는 영어단어는 비어있다는 의미로 무효의, 없는 혹은 \\(0\\) (zero)의 의미입니다. 한국말로는 귀무가설 혹은 영가설이라고 부릅니다. 귀무가설의 무는 無로 아무것도 없는 것으로 돌아간다는 의미입니다. 즉, 아무 의미가 없다는 의미가 됩니다. 그러므로 이 귀무가설의 뜻은 아무 것도 의미가 없다가 됩니다. 두 번째 줄의 H 역시 영어단어 hypothesis를 의미합니다. 그 다음의 소문자 \\(a\\)는 때로는 숫자 \\(1\\)로 표기되기도 하며 이때의 \\(a\\)는 영어단어 alternative의 약자입니다. 우리말로는 대립가설이 됩니다. 사실 영어단어의 의미로는 대체가설인데 우리 책에서는 대립가설이라고 부릅니다. 아마도 이 두 개의 가설이 경쟁하는 관계에 있다 보니 이러한 경쟁관계를 대체 보다는 대립이라는 단어가 더 잘 표현한다고 생각했던 것 같습니다. 이 대립가설은 첫 번째 줄의 귀무가설을 대체하는 가설이니 당연히 귀무가설과 경쟁관계에 있는 가설입니다. 귀무가설이 아무 의미도 없다는 의미라면 대립가설은 어떤 의미가 있는 가설이 될 것입니다. 그렇다면, 통계학자들은 왜 이렇게 복잡한 가설을 만들어 놨을까요?\n\n\n1.4.2 통계적 가설\n통계학자들이 이렇게 두 가지의 가설을 먼저 정해 놓고 통계적 의사결정을 하는 이유는 보다 꼼꼼하고 안전하게 결론을 내리기 위함입니다. 사실 매우 과학적 의사결정 방법이라고 할 수 있습니다. 얼마나 많은 고민과 생각을 하면서 이러한 과정을 만들고 설계를 했는지 가늠해보면 누군지 모를 그들이 참 대단하다는 생각이 듭니다. 하지만 우리에게는 이해하고 해결해야할 과제가 된 것이지요. 그렇다면 이제 통계적 가설이 어떤 의미이고 우리가 알고 있는 것들에 어떻게 연결될 수 있을지 알아보겠습니다. 앞에서 우리는 어떤 사건이 우연히 일어날 확률을 p값으로 구하다고 했습니다. 만약 p값이 5%보다 작다면 이는 우연히 발생하지 않은 사건이므로 무언가 의미 혹은 원인이 있는 것이고, 반대로 5%보다 크게 나오면 이는 우연히 발생한 사건으로 결정한다고 이야기 했습니다. 여기서 말하는 5%보다 p값이 크게 나와 우연히 발생한 사건을 가정한 것이 바로 귀무가설입니다. 귀무가설은 아무 의미 있는 일이 일어나지 않은 것이므로 귀무가설이 의미하는 것은 통계적으로 유의하지 않은 것을 가정하는 것입니다. 반대로 대립가설이 맞는다면 즉 p값이 5%보다 작아서 무언가 의미가 있다면 이는 이 사건이 우연히 발생한 것이 아니고 뭔가 의미 혹은 이유가 있다고 판단하는 것입니다. 다시 말해 대립가설은 어떤 사건이 우연히 발생하지 않았고 뭔가 이유가 있다고 가정하는 가설입니다. 그러니 여러분들이 앞으로 하게 될 통계적 분석에서 p값 즉 확률값을 먼저 구하고 이 값이 5%보다 크면 귀무가설을 채택하여 이 사건은 우연히 발생했다고 결론내릴 것입니다. 반면, p값이 5%보다 작으면 대립가설을 채택하고 이 사건은 우연히 발생하지 않았으며 아마도 어떤 이유 혹은 의미가 있다고 결론내릴 것입니다.\n\n\n1.4.3 안유의 주임의 에피소드\n그렇다면 위의 통계적 가설을 앞에서 살펴봤던 안유의 주임의 일화에 적용해 봅시다. 다시 한 번 통계적 가설을 적어본다면 아래와 같습니다.\n\\[H_0: D_{A-B}=0\\] \\[H_a:D_{A-B}\\ne0\\]\n이제 가설의 내용을 알아봅시다. 여기서 사용된 대문자 \\(D\\)는 영어단어 difference의 약자로 사용하였습니다. 이러한 약자의 사용은 정해진 약속은 아니고 제가 편의를 위해 사용한 것으로 사용자의 의도에 의해 언제든지 바뀔 수 있습니다. 그 다음의 대문자 \\(A\\)와 \\(B\\)는 각각 지난 10년간 12월 평균 매출과 금년 12월 매출을 의미합니다. 그 둘의 차이를 구해본 것이지요. 그러므로 위의 귀무가설은 지난 10년간 12월 평균 매출과 금년 12월 매출의 차이는 없다고 가정하고 있습니다. 왜냐하면 그 차이가 \\(0\\) (zero)이라고 가정하고 있기 때문입니다. 반면에 대립가설은 이 둘의 차이가 \\(0\\)이 아니며 두 값은 다르다는 것을 의미합니다. 그러므로 만약 귀무가설이 채택된다면 안유의 주임의 신규전략은 아무런 효과가 없었으며 1,000만원의 매출이 더 발생한 사건은 우연히 발생했다고 결론을 내릴 수 있을 것입니다. 반면에, 대립가설이 채택된다면 1,000만원의 매출이 증가한 것은 안유의 주임의 새로운 전략 때문이었다고 결론 내릴 수 있습니다.\n정리해 보자면, 귀무가설과 대립가설 중 어떤 것을 선택하느냐는 앞에서 말했듯이 p값에 달려 있습니다. 만약 p값이 0.05보다 작다면 우리는 대립가설을 선택하고, 0.05보다 크다면 우리는 귀무가설을 선택하는 것입니다. 금년 12월 매출이 우연히 1,000만원 더 나올 확률이 5%보다 작으면, 이는 우연이 아니고 안주임의 신규 전략이 효과가 있다고 추정할 수 있는 것이지만, 만약 5%보다 크다면 그냥 우연히 1,000만원의 매출이 증가한 것입니다. 그렇다면 이 5%가 통계학에서 어떻게 설정되는지 다른 의미를 살펴보겠습니다.\n\n\n1.4.4 1종오류와 2종오류\n앞서 우리는 통계적 유의성과 실질적 유의성에 대해 잠시 이야기 했습니다. 통계학자들은 어떤 연구이든 실험이든 통계적인 방법을 적용할 경우 잘못된 결론을 내릴 수 있다는 것을 알고 있었습니다. 어찌 생각해 보면, 매우 겸손한 자세입니다. 내가 연구한 것은 다 옳다는 생각이 아닌 나도 모르게 내 연구결과가 틀릴 수 있다는 전제를 먼저 깔고 시작하는 것입니다. 우리는 이러한 실수를 오류하고 부릅니다. 통계적 가설과 연결해서 생각해 보면 두 가지 종류의 오류가 있을 수 있습니다. 다음의 표를 살펴보시기 바랍니다.\n\n\nTable 1.1: 1종오류와 2종오류\n\n\n진 실\n실험결과\n분 류\n\n\n\n\n귀무가설이 참\n귀무가설이 참\n아무 문제 없음\n\n\n귀무가설이 참\n귀무가설이 거짓\n1종오류 (\\(\\alpha\\))\n\n\n귀무가설이 거짓\n귀무가설이 참\n2종오류(\\(\\beta\\))\n\n\n귀무가설이 거짓\n귀무가설이 거짓\n아무 문제 없음\n\n\n\n\n언뜻 보기에는 헷갈립니다. 일단 여기서 혼동을 방지하기 위해 귀무가설이 참이면 이는 대립가설이 거짓이라는 의미이고, 귀무가설이 거짓이라면 대립가설이 참이라는 점을 먼저 아셔야 합니다. 간단한 것부터 보도록 합니다. 실제로 귀무가설이 참일 때, 연구결과가 또한 귀무가설을 참으로 결론 내린다면 아무런 문제가 없다는 점은 당연합니다. 동일하게 실제로 귀무가설이 거짓일 때, 연구결과 또한 귀무가설을 거짓으로 결론 내린다면 아무런 문제가 없습니다. 우리의 연구는 매우 훌륭했고 진실을 잘 밝혀낸 것이니까요.\n문제는 이게 교차할 때 입니다. 실제로는 귀무가설이 참인데 연구결과 귀무가설이 거짓이라고 한다면 우리는 이것을 1종오류라고 합니다. 이게 무슨 소리인지 잘 이해가 되지 않지요? 그럼 예를 들어보겠습니다. 우리가 어떤 유행병의 치료제를 개발하고 있습니다. 이 치료제로 임상실험을 하여 치료효과가 있는지 보려고 합니다. 이 경우 우리의 귀무가설과 대립가설은 무엇일까요? 귀무가설은 치료제가 효과가 없다 입니다. 왜냐하면 귀무가설을 결국 “= 0”이므로 아무로 효과가 없는 것입니다. 귀무가설을 외울 때 저는 equal zero라고 암기했던 기억이 나네요. 반면 대립가설은 치료제가 효과가 있다는 것을 가정하는 것입니다. 그러니 “zero” 즉 \\(0\\)이 아닌 것이지요. 다시 1종오류로 돌아가 봅시다. 실제로는 귀무가설이 맞는데 연구결과 귀무가설이 거짓이라고 나왔으니 연구결과는 대립가설을 참이라고 결론 내린 것입니다. 무슨 뜻이냐면, 실제로는 치료제가 아무런 효과가 없는데, 연구결과 치료제가 효과가 있다고 나온 것이지요. 이것이 1종오류입니다. 2종오류는 정반대의 경우입니다. 즉, 실제로는 귀무가설이 거짓인데 연구결과 귀무가설이 참이라고 결론 내리는 경우입니다. 위의 치료제를 예로 들어보자면, 실제로 치료제는 효과가 있는데 연구결과 치료제가 효과가 없다고 결론을 내는 경우이지요.\n\n\n1.4.5 그래서 뭐?\n이게 왜 중요할까요? 위에서 잠깐 이야기 했지만, 통계학자들은 사실 매우 겸손한 사람들입니다. 왜냐하면 본인들의 연구가 틀릴 수도 있다는 점을 전제하고 이를 논리적으로 도식화했기 때문입니다. 이러한 논리적 도식화를 위해 기본적으로 귀무가설과 대립가설을 설정하고 발생할 수 있는 오류의 종류도 두 가지로 나누어서 생각한 것이지요. 위에서 이야기 했듯이 가능한 오류는 두 가지인데 둘 중 어떤 것이 더 중요할까요? 중요하다는 표현이 좀 애매합니다만 둘 중 어떤 것이 더 치명적인 오류일까요? 앞서 보았던 치료제의 예처럼 두 종류의 오류 중에 더 치명적인 오류는 바로 1종오류입니다. 영어로는 Type 1 error 라고 합니다. 이 오류가 더 치명적인 이유는 실제로는 아무런 치료효과가 없는 약을 연구결과 치료효과가 있다고 잘 못 알고 대량생산하여 환자들에게 투여할 경우 모두 죽게 될 것이기 때문입니다. 물론 2종오류도 문제는 있습니다. 영어로 Type 2 error 라고 하는데, 실제로는 치료제가 효과가 있으나 연구결과 효과가 없다고 나오는 경우입니다. 이 경우엔 대량생산되어 환자에게 투여되지 않을 것이므로 허무하게 환자가 죽는 일은 없을 것입니다. 다만, 치료제 발견을 놓치게 되어 안타까운 일이 되는 것입니다.\n통계학자들도 1종오류가 2종오류보다 더 치명적이라는 점을 알고 있었습니다. 문제는 인간은 신이 아니므로 언제든 실수를 할 수 있고 언제든 오류가 있을 수도 있다는 점이 문제였습니다. 그래서 통계학자들은 연구결과에서 발생할 수 있는 1종오류를 전혀 없다고 할 수는 없지만 허용할 수 있는 한계를 두기로 마음먹었습니다. 그리고 이 1종오류를 그리스문자 \\(\\alpha\\)로 표현하였습니다. 그리고 이 \\(\\alpha\\)가 1종오류의 허용 가능한 한계치로 이것이 바로 우리가 말하는 유의수준 5% 즉 0.05입니다. 즉, 왜 p값을 5%로 정했는지 두 번째 그리고 좀 더 정확한 이유가 여기 있습니다. 이 5%는 허용 가능한 1종오류의 수준인 것입니다. 여기서 허용이라는 단어의 선택이 좀 애매합니다만 허용이라고 할 수도 있고 제한을 둔다고 할 수도 있는 거라고 보시면 될 것 같습니다. 다르게 말하자면, 어떤 사건이 우연히 발생했음에도 우연히 발생하지 않았다고 결론 내릴 오류를 5% 이내로 하겠다는 것이 바로 이 5%의 규칙입니다. 문제는 이 방식으로 유의수준 p값과 5%를 이해하기 시작하면 우리가 통계를 이해하기가 너무 어렵습니다. 앞서 이야기했듯이 어린 아기에게 이유식이 아닌 정식으로 밥을 먹이는 느낌입니다. 통계를 이제 막 시작한 우리들로서는 너무 이해하기 어려운 것이지요. 그래서 이런 것도 있구나 하는 정도의 이해를 하면서 앞에서 이야기 한대로 p값이란 어떤 사건이 우연히 발생할 확률정도로 이해하고 진행해도 무방하다는 것이 저의 생각입니다. 하지만 1종오류와 2종오류에 대해서 알고는 있어야 하겠죠?\nYouTube 바로 가기"
  },
  {
    "objectID": "chapter1.html#왜-이렇게-생겼을까",
    "href": "chapter1.html#왜-이렇게-생겼을까",
    "title": "1  통계는 왜 어려울까?",
    "section": "1.5 왜 이렇게 생겼을까?",
    "text": "1.5 왜 이렇게 생겼을까?\n\n1.5.1 변수와 데이터\n이번에는 변수와 데이터에 대해 알아보겠습니다. 통계를 공부해보면 수천 번 등장하는 단어가 변수입니다. 변수란 단어를 우리는 흔히 사용하고 있고 들어 알고 있습니다. 그럼 여기서 질문을 해보겠습니다. 변수란 무엇일까요? 잠시 생각해 보세요. 그렇다면 변수의 반대말은 무엇일까요? 질문이 좀 이상한가요? 이상해 보일지 몰라도 스스로에게 항상 이런 질문을 던져야 합니다. 변수란 다 아는 것 같으면서도 사실 잘 모르는 대상입니다. 인터넷을 검색해 확인해 보시기 바랍니다.\n변수의 정의를 읽어보면 무슨 뜻인지 이해가 되시나요? 저도 그냥 봐서는 잘 모르겠는 어려운 말들이 많더군요. 이런 쓸데없이 어려운 그러나 있어 보이는 정의 말고 본인의 말로 쉽게 그 뜻을 말 할 수 있어야 합니다. 저는 이렇게 표현합니다. 변수란 그 이름 그대로 변화하는 숫자입니다. 영어로 variable이라고 하는 단어의 앞부분의 vari-는 vary (변하다)라는 단어에서 파생 된 것이고, 뒤의 -able은 무엇을 할 수 있다는 의미입니다. 그러니 영어로 variable은 변화할 수 있는 이라는 뜻이 되겠네요. 그러면 예를 들어 보겠습니다.\n\n안유의 주임이 고객을 대상으로 고객 만족도를 조사할 때, ‘고객만족도’\n박경우 과장이 고객을 대상으로 향후 미래의 구매의도를 조사할 때, ‘구매의도’\n집 앞 도로에서 1시간 동안 지나가는 자동차의 브랜드를 조사할 때, ‘자동차 브랜드’\n\n예를 들어 안유의 주임이 고객만족도를 조사합니다. 매장에서 구매하는 고객을 대상으로 일일이 고객들의 만족도를 묻는다고 가정해 봅시다. 안주임은 미리 준비된 설문지를 이용해 설문지의 질문에 고객이 응답하도록 할 것입니다. 이때, 보통은 응답을 위한 보기가 있습니다. 매우 불만족, 조금 불만족, 보통, 조금 만족, 매우 만족. 이렇게 되면 5개의 보기가 있는 것이고, 이를 우리는 척도라고 부릅니다. 5개의 척도가 있으니 5점척도가 됩니다. 그러면 고객은 이 다섯 가지 중에서 하나를 고르게 됩니다. 매번 다른 고객에게 질문할 때마다 고객들의 응답은 이 다섯 가지 중의 하나이긴 하겠지만 항상 모두 같은 답을 하지는 않을 것입니다. 왜냐하면 이것은 변수이기 때문이지요. 변수란 그 응답이 계속 변화해야 합니다. 그렇다면 변수의 반대말은 무엇일까요?\n바로 상수입니다. 상수는 문자 그대로 항상 그대로 있는 숫자입니다. 즉 변하지 않습니다. 여기서 주의할 점이 있습니다. 가끔 대학원생들 중에 논문을 위한 설문조사를 할 때, 응답자에게 이런 요구를 하는 경우가 있습니다.\n\n“웬만하면 5점척도에서 다 5점으로 표기해 주세요.”\n\n참으로 바보 같은 요구이자 본인의 연구를 엉망진창으로 만드는 방법입니다. 물론 본인들은 모릅니다. 결과가 좀 이상해도 그냥 그러려니 합니다. 이게 문제가 되는 이유는 간단합니다. 변수로 만들어 놓고 응답자들로 하여금 이를 상수화 해달라고 주문하는 것입니다. 이렇게 되면 변수로서의 중요한 핵심에 문제가 생깁니다. 그것은 바로 분산입니다. 변수의 변화하는 부분이 통계적으로는 분산 혹은 표준편차가 됩니다. 만약 변수라고 해놓고서 상수가 되면 분산이 “0”이 되거나 아주 약간의 변화만 생긴다면 분산이 매우 작아지게 됩니다. 분산이 없으면 변화가 없는 숫자이고 이는 변수가 아닌 상수가 됩니다. 이렇게 되면 우리가 변수라고 이를 부를 수도 없을 뿐더러 정상적으로 존재해야할 분산이 없어져서 문제가 됩니다. 왜냐하면 앞에서 이야기 했듯이 통계란 분산의 마법인데 분산이 없다면 도대체 할 수 있는 마법이 없다는 의미가 됩니다. 자세한 것에 대해서는 뒤에서 차츰 배워가겠습니다.\n\n\n1.5.2 설문조사와 코딩\n그러면 이제 다음의 설문조사지를 살펴봅시다. 이 설문조사지는 안유의 주임이 고객만족을 조사할 때 사용했던 설문지입니다.\n\n\nTable 1.2: 고객만족도 조사 설문지\n\n\n\n\n\n\n\n\n\n\n\nNo.\n질문내용\n매우\n그렇지 않다\n조금\n그렇지 않다\n보통\n조금 그렇다\n매우\n그렇다\n\n\n\n\n1\n나는 이번의 구매가 즐겁다\n□\n□\n□\n□\n□\n\n\n2\n나는 이번의 구매가 행복하다\n□\n□\n□\n□\n□\n\n\n3\n나는 이번의 구매에 만족한다\n□\n□\n□\n□\n□\n\n\n4\n나는 다음에 다른 브랜드 제품을 구매하겠다\n□\n□\n□\n□\n□\n\n\n5\n나는 이 브랜드 제품을 다시는 구매하지 않겠다\n□\n□\n□\n□\n□\n\n\n6\n나는 앞으로도 계속 이 브랜드 제품을 구매할 것이다\n□\n□\n□\n□\n□\n\n\n\n\n안유의 주임은 Table 1.2 와 같은 내용의 설문을 하였고 50명의 고객으로부터 응답을 수집하였습니다. 그 후에 분석을 위해 50개의 설문결과를 엑셀에 코딩한 결과는 다음과 같습니다. Figure 1.1 에 그 결과를 보면 엑셀은 행(row)과 열(column)으로 되어 있습니다. 첫번째 행인 1번 행을 보면 첫번째에 ID가 있고 그 이후로 V1부터 V8까지 써 있습니다. 이 첫번째 행이 바로 변수명을 적어 놓은 행입니다. 그러므로 하나 하나의 열(column)이 변수가 됩니다. 그리고 하나 하나의 행(row)이 관찰값(observation)입니다. 관찰값이란 한명 한명의 고객을 의미합니다. 안주임이 총 50명의 고객으로부터 설문을 받았으므로 총 50개의 열(row)가 존재할 것입니다. 코딩을 할 때 항상 습관적으로 해야하는 것 중의 하나가 첫번째 변수로서 ID를 넣는 것입니다. 50명의 고객으로부터 받은 설문지에 1부터 50까지의 숫자를 적고, 이 숫자와 엑셀의 ID의 숫자를 일치시키면서 코딩을 하면 됩니다. 만약 코딩을 끝마친 후에 이 50명의 고객중 회사직원이 있어서 이 직원의 응답을 삭제해야 한다면 그 직원이 응답한 설문지의 번호와 엑셀 ID의 숫자를 맞추어 제거하면 됩니다. 만약 이러한 과정을 생략했다면, 문제가 된 응답을 제거할 방법이 없고 데이터 전체에 대한 신뢰도가 문제가 되어 수집한 응답 데이터를 모두 버리고 새로 설문을 해야하는 상황이 벌어집니다. 이러한 내용은 꼭 숙지하는 것이 좋습니다.\n\n\n\nFigure 1.1: 엑셀 코딩 결과\n\n\n이렇게 코딩화면을 보여 드리는 이유는 통계 초보자들이 코딩 단계에서 실수를 많이 하기 때문이기도 하고, 코딩하는 방법을 잘 모르기 때문이기도 합니다. 꼭 기억해야 할 것은 하나의 변수를 한 개의 열(column)에 넣어야 한다는 사실입니다. 실제 코딩을 하다보면 한 명의 설문지를 변수 순서대로 넣게 되는데 한 응답값을 입력하고 엔터를 치면 엑셀의 특성상 커서가 아래로 움직입니다. 그러나 다음에 입력해야할 값은 먼저 입력한 값의 우측에 있는 값입니다. 이러면 방향키로 계속해서 한 값을 입력하고 움직여야 하는 불편함이 생깁니다. 이러한 문제를 쉽게 해결하기 위한 방법은 엑셀 메뉴의 가장 좌측의 &lt;파일&gt;을 클릭한 후 가장 아래의 &lt;옵션&gt;을 클릭하면 엑셀 옵션 화면이 나옵니다. 여기서 &lt;고급&gt;을 클릭하면 가장 위에 “엔터키를 누르면 다음셀로 이동”이라는 메뉴가 있고 그 아래에 어느 방향을 셀로 이동할지 수정할 수 있습니다. 기본값은 “아래로”되어있는데 이 값을 “오른쪽”으로 변경하고 확인을 클릭합니다. 이렇게 하면 편하게 코딩을 할 수 있습니다.\n\n\n1.5.3 변수의 종류\n변수의 종류를 알아보기 전에 변수가 가진 특성을 알아보겠습니다.\n\n\n\nFigure 1.2: 변수의 특성\n\n\nFigure 1.2 를 보면 교육정도라는 이름의 변수가 있습니다. 이 변수는 그 하위에 4개의 속성을 가지고 있습니다. 물론 이러한 속성의 갯수와 이름은 연구자에 따라 변할 수 있습니다. 여기서는 4개로 한정해 보겠습니다. 이 변수의 속성에는 중졸/고졸/대졸/대졸이상 총 4가지가 있습니다. 즉, 이 4 가지 중 하나로 응답을 받는 것입니다. 이러한 속성은 문자열로 구성되어 있으므로 이 자체로 코딩을 해봐야 컴퓨터가 이해하기는 힘듭니다. 그래서 이 속성에 값을 부여합니다. 1/2/3/4와 같이 개별 속성에 고유 값을 부여합니다. 다만 이 값에 의미가 있는지 없는지 혹은 이 값 사이의 간격이 등간격인지 아닌지는 속성의 관계에 따라 달라집니다. 사실 변수의 종류는 이러한 속성, 값, 관계에 따라 나누어집니다. 그럼, 이제 변수의 종류에 대해 자세히 알아보겠습니다.\n우선, 변수는 범주형 변수와 연속형 변수로 나눌 수 있습니다. 책마다 부르는 이름이 다소 다를 수는 있지만 같은 것을 지칭하고 있다고 보시면 됩니다. 범주형 변수는 영어로 categorical variable이라고 하는데 카테고리 즉 범주가 있다는 의미가 됩니다. 이 변수는 영어로 discrete variable이라고 불리기도 하는데 discrete이란 단어는 분리되어 있다는 의미입니다. 가끔 책에 따라서 이 변수와 이산형 변수를 같은 변수의 다른 이름으로 보기도 하고 아예 다른 변수로 보기도 합니다만 이러한 복잡한 이야기는 좀 미뤄두겠습니다. 우리는 일단 범주형 변수라고 부르도록 하지요. 이 범주형 변수와 대비되는 것이 바로 연속형 변수입니다. 이 변수는 영어로 continuous variable이라고 합니다. 말 그대로 이 변수는 연속되는 값으로 구성된 변수입니다. 범주형과 연속형 변수의 구분을 가장 쉽게 표현하는 단어가 아마도 질적변수 양적변수라는 개념일 것입니다. 질적변수는 qualitative variable로 양적변수는 quantitative variable로 부릅니다. 범주형 변수는 질적변수와 동일한 것으로 보시면 되고, 연속형 변수는 양적변수와 동일하게 보시면 됩니다. 즉, 어떠한 수의 개념이 아닌 변수는 질적변수 혹은 범주형 변수이고, 수의 개념이 있으면 이는 연속형 변수 혹은 양적변수인 것이지요. 앞에서 보았던 교육정도라는 변수는 범주형 혹은 질적변수라고 보시면 됩니다. 왜냐하면 이 변수의 속성을 보면 중졸/고졸/대졸/대졸이상으로 이 속성을 값으로 매칭하긴 했지만 이는 숫자에 의미가 없습니다. 컴퓨터 프로그램이 이해하기 쉽게 숫자를 매칭했을 뿐입니다. 숫자에 아무런 의미가 없는 범주형 변수인 것입니다.\n\n\n\nFigure 1.3: 변수의 종류\n\n\n이제 이 변수를 다시 개별적으로 두 개씩 나누어 총 4가지의 변수의 종류를 확인할 수 있습니다. 범주형은 명목변수와 순위변수로, 연속형은 구간변수와 비율변수로 나눌 수 있습니다. 영어로 외우는 편이 어쩌면 더 쉽습니다. 그냥 nominal/ordinal/interval/ratio 이렇게 외우면 쉽습니다. 우선 명목변수부터 살펴보겠습니다. 가장 단순한 형태의 변수이며 우선 범주형이므로 질적변수입니다. 범주형 변수 중에서도 범주의 속성간 순위가 없고 속성에 할당된 값은 각 속성의 이름을 대신할 뿐 아무런 의미가 없습니다. 예를 들어 성별이나 인종 혹은 혈액형 같은 변수들이 이에 속합니다. 성별은 크게 남/녀의 두 개의 속성이 있고 이 속성 사이에는 아무런 순서가 없습니다. 그러므로 범주형 중에서도 명목변수인 것입니다. 중요한 것은 순서가 없다는 사실입니다. 인종이나 혈액형과 같이 어떤 순서가 없는 변수가 바로 명목변수입니다. 영어로 nominal variable이라고 하는데 여기서 nominal이란 단어는 명사 name의 형용사형 정도로 보시면 됩니다. 즉, 이름만 있고 다른 것이 아무것도 없다는 의미가 됩니다. 다음은 순위변수 입니다. 이 변수는 영어로 ordinal variable이라고 하고 이름 그대로 순서가 있는 변수 입니다. 정확하게는 범주 내의 속성 사이에 순서가 있다는 것입니다. 또한 이 속성을 나타내는 값은 값의 순서가 속성의 순서를 그대로 반영합니다. 앞에서 보았던 교육정도라는 변수는 순위변수입니다. 중졸/고졸/대졸/대졸이상 이라는 4가지의 속성은 각각 1/2/3/4로 매칭이 되고 이 매칭된 값의 순서는 속성의 순서를 의미합니다. 왜냐하면, 중졸이 먼저 오고 그 다음에야 고졸이 가능하고, 또 그 이후에야 대졸이 가능하기 때문이 값의 순서가 속성의 순서가 되는 것입니다. 다만, 순위변수의 값들 사이에는 등간성은 존재하지 않습니다. 정확하게는 등간격을 말할 수 없다는 의미가 됩니다. 속성 사이에 등간격 개념이 없기 때문에 당연히 이 값인 1/2/3/4 사이에 등간격은 없는 것이고 이 숫자는 그냥 대표성과 순서만의 의미를 지니게 됩니다. 성적(A/B/C/D/F)이나 교육정도가 주로 이 경우에 포함되며, 설문에서 많이 사용하는 리커르트척도 (Likert-scale)가 대표적인 순위척도입니다.\n다음은 연속형 변수입니다. 연속형 변수는 그 값이 의미 있는 숫자인 경우에 연속형 변수가 됩니다. 이 연속형 변수는 다시 두 가지로 구분됩니다. 구간변수 (interval variable)와 비율변수 (ratio variable)입니다. 구간변수는 앞에서 본 순위변수와 다르게 각 범주 사이에 등간성이 있습니다. 그러나 각 속성의 값 사이의 등간성은 있으나 속성에 할당된 값은 어디까지나 임의의 단위로서 이 숫자를 비율로 나타낼 수 없고 절대값 \\(0\\) (zero)의 의미가 없습니다. 그러므로 이 변수는 덧셈이나 뺄셈은 할 수 있어도 곱셈이나 나눗셈을 할 수는 없습니다. 사실 구간변수는 제 개인적으로 흔하게 본적은 없습니다. 대부분의 책에 등장하는 대표적인 예가 바로 온도입니다. 아마도 헷갈리는 분이 많을 것입니다. 온도에는 분명 0도가 존재하고 우리는 이 온도를 사실 비율변수처럼 이해하고 있습니다. 그러나 이는 사실이 아닙니다. 쉽게 말해, 섭씨 1도 보다 10배 더운 것이 섭씨 10도 일까요? 아니면 섭씨 0도에서 10도의 온도가 높은 것이 섭씨 10도 일까요? 앞의 예는 곱셈(나눗셈)이지만 뒤의 예는 덧셈(뺄셈)입니다. 온도의 경우에는 후자가 맞는 것이지 몇 배 처럼 곱셈이나 비율의 개념으로 말할 수 있는 것이 아닙니다. 인터넷에서 찾아보면 몇가지 예가 더 있긴 합니다만 직접 찾아보시길 권합니다. 그러나 실제로 연구를 하거나 통계조사를 할 때 구간변수를 만날 가능성은 매우 희박합니다.\n마지막으로 비율변수입니다. 일반적으로 연속형변수라고 하면 대부분은 이 비율변수를 의미합니다. 왜냐하면, 구간변수는 흔하게 볼 수 있는 변수가 아니기 때문입니다. 이 비율변수는 모든 것을 다 만족합니다. 측정된 범주의 속성값은 등간격이고, 속성에 할당된 값은 임의의 단위로서 비율이나 절대 \\(0\\) (zero)의 의미가 있습니다. 그러므로 덧셈(뺄셈) 뿐만 아니라 곱셈(나눗셈)도 가능합니다. 예를 들어 키/몸무게/나이 등이 그렇습니다. 애매하긴 한데, 시간이란 변수는 기본적으로는 구간변수 (interval variable)에 속합니다. 가끔 시간을 비율변수 (ratio variable)에 포함시키기도 하는데 이 경우 좀 개념이 다르다고 봐야 합니다. 구간변수로서의 시간은 B.C. 혹은 A.D. 와 같은 calendar year의 경우입니다. 그런데 만약 이 시간 변수를 생존시간으로 본다면 이야기가 달라집니다. 이런 경우는 흔합니다. 나이의 경우 그냥 봐서는 연속형변수인데 나이를 1년 단위로 카운트하여 셈한다면 이는 심지어 순위변수처럼 보이는 구간변수의 느낌이 강합니다. 우리가 나이를 이야기 할 때 24살이라고 하지 24.5살 이라고는 하지 않기 때문입니다. 따라서, 전반적인 변수간의 차이와 특성을 이해하는데 중점을 두시고 너무 까다롭게 변수를 구분하는 것은 피할 것을 권해드립니다. 가끔 저도 이런 문제들을 만나면 헷갈리기 일쑤라서 너무 마음을 두지 않으셔도 괜찮다는 생각이 드네요.\n그렇다면 다시 안주임의 설문지 Table 1.2 를 보겠습니다.\n이 설문지에 등장하는 위의 6개의 변수는 명목/순위/구간/비율 변수 중에서 어떤 변수일까요? 눈치가 빠르신 분들은 이미 아시겠지만, 위의 설문지와 같은 형식을 리커르트 척도 (Likert-scale) 라고 부른다고 했습니다. 그러므로 안유의 주임의 설문지 문항은 순위척도가 됩니다. 뒤에 가서 회귀분석과 같은 분석방법을 배울텐데요. 보통은 이런 설문지로 얻은 결과 데이터를 회귀분석으로 많이 분석합니다. 그런데 회귀분석에서 이를 분석 할 때, 마치 이 변수가 비율변수인것처럼 보고 분석을 합니다. 사실 2000년대 초반까지만 해도 이와 관련한 논쟁이 꽤 있었습니다. 지금은 교수님이신 제가 아는 분이, 예전 박사 학생일 때 논문을 투고 했는데 논문 심사결과 이를 심각한 문제로 보고 거의 떨어질뻔 했다고 합니다. 심사위원 중 한 명이 순위변수를 비율변수처럼 사용하여 분석했으니 잘못된 것이라는 지적을 했답니다. 물론, 아주 원론적으로는 맞는 말입니다. 문제는 이렇게되면 설문으로 분석할 수 있는 분석방법의 한계가 너무 제한되고 분석을 거의 할 수 없는 상태에 이르게 됩니다. 지금은 이런 것을 문제 삼는 경우는 없다고 봅니다. 이 문제를 해결하기 위해 어떻게 심사위원과 편집장을 설득할 수 있었을까요? 기본적으로 고객만족은 눈에 보이지는 않지만 모든 고객의 마음에 존재한다고 전제합니다. 그렇지 않다면 이를 응답으로 끌어내어 데이터로 만들 수 없을테니까요. 문제는 인간의 마음속에 존재하는 고객만족을 비율변수로 응답을 만들어낼 방법이 사실 없다는 것입니다. 물론 100점 만점으로 고객만족의 점수를 받을 수도 있지만, 다른 심사위원이 고객만족이 왜 100점까지만 있느냐고 한다면 이 또한 참으로 애매한 문제입니다. 척도(scale)을 세분화하면 할수록 더 정확한 결과가 나올 것이라고 생각할 수도 있지만, 그렇지 않습니다. 만점이 다를 수도 있다면, 사람마다 척도(scale)의 간격이 또한 다를 수 있고 그러면 오히려 더 부정확한 결과가 나올 것입니다. 오히려 위의 리커르트 척도처럼 말로써 매우 그렇지 않다, 조금 그렇지 않다, 보통이다, 조금 그렇다, 매우 그렇다라고 지침을 주면 더 정확할 수 있다는 것입니다. 거꾸로 말해 조금 그렇다라고 응답한 고객에게 100점 만점으로 점수를 쓰라고 하면 어떤 사람은 60점을 어떤 사람은 90점을 줄 수 있다는 것입니다. 모두 자기 나름의 기준은 있지만, 우리가 데이터를 만들 때는 최대한 동일한 기준으로 동일한 생각을 가지고 응답하도록 하는 것이 데이터의 객관성을 유지하는데 도움이 됩니다. 지금은 이런 지엽적인 문제로 괴롭히는 심사위원은 없지만, 여전히 이런 기초적인 통계지식에 집착해서 상위 수준의 연구를 방해하는 심사위원은 꽤 많습니다.\n통계적 지식을 쌓아 가는 것은 무엇보다 중요하지만, 원칙과 맞고 틀림에 너무 집착하면 오히려 더 큰 세상을 이해할 수 있는 기회 자체를 잃을 수 있습니다. 항상 내가 틀릴 수도 있다는 전제를 가지고 있는 것이 중요합니다. 통계학자들이 그런 철학으로 가설과 오류를 설정했듯이 말입니다. 통계는 계속 변화하고 발전하고 있습니다. 우리가 알고 있던 과거의 통계기술과 지식, 방법이 불과 몇 년 안에 오래된 것이 되고 새로운 것이 나오는 그런 시대입니다. 최근의 머신러닝이나 인공지능과 같은 기술이 등장하면서 통계는 기초지식으로 매우 중요하긴 하나 절대 불변의 진리는 아닐 수도 있다는 것입니다.\nYouTube 바로 가기"
  },
  {
    "objectID": "chapter1.html#왜-이렇게-헷갈릴까",
    "href": "chapter1.html#왜-이렇게-헷갈릴까",
    "title": "1  통계는 왜 어려울까?",
    "section": "1.6 왜 이렇게 헷갈릴까?",
    "text": "1.6 왜 이렇게 헷갈릴까?\n\n1.6.1 상관관계와 상관계수\n이제는 다소 통계스러운 것을 알아 봅시다. 보통 통계책의 초반에 등장하고 복잡한 수식이 등장하면서 설명이 나오지만 이 역시 적당히 이해하고 넘어가도 될만 하여 그냥 그저 그렇게 넘기는 대상이 바로 상관관계입니다. 사실 상관관계의 정의는 이렇습니다. “한 변수와 다른 변수가 공변하는 함수관계” 그다지 어려워 보이지 않습니다. 상관관계의 정의를 보면 일단 두 개의 변수가 필요하다는 것을 알 수 있습니다. 그리고 이 두 변수가 공변 즉 함께 변화하는 함수관계가 곧 상관관계라는 것입니다. 상관관계에는 두 가지가 있습니다. 양의 상관관계와 음의 상관관계입니다. 양의 상관관계를 살펴봅시다.\n\nX가 증가할 때, Y가 증가한다\nX가 감소할 때, Y가 감소한다\nY가 증가할 때, X가 증가한다\nY가 감소할 때, X가 감소한다\n\n위의 네 개의 문장은 모두 양의 상관관계를 설명하는 문장으로 사실상 다 같은 뜻입니다. 양의 상관관계란 결론적으로 두 변수가 같은 방향으로 움직인다는 의미가 됩니다. 다음으로 음의 상관관계를 살펴봅시다.\n\nX가 증가할 때, Y가 감소한다\nX가 감소할 때, Y가 증가한다\nY가 증가할 때, X가 감소한다\nY가 감소할 때, X가 증가한다\n\n마찬가지로 위의 네 개의 문장은 모두 음의 상관관계를 설명하는 문장입니다. 음의 상관관계란 두 변수가 서로 다른 방향으로 움직인다는 의미입니다. 그런데 사실 상관관계에서 중요한 것은 이것만이 아닙니다. 상관관계를 나타내는 숫자인 상관계수에는 두 가지 중요한 의미가 담겨 있습니다.\n첫째는 힘이고 둘째는 방향입니다. 먼저 상관계수의 특성을 알아보겠습니다. 상관계수는 -1부터 시작해서 증가하여 \\(0\\)을 거쳐 +1까지만 존재합니다. 즉 최대값이 +1이고 최소값이 -1입니다. 상관계수가 만약 2.5라면 이것은 잘못된 것입니다. 상관계수는 1을 넘을 수 없기 때문입니다. 만약 상관계수가 +1 이라면 우리는 이를 완벽한 양의 상관관계라고 표현하고, 상관계수가 -1 이라면 이를 완벽한 음의 상관관계라고 부릅니다. 반면에 만약 상관계수가 \\(0\\) (zero)이라면 우리는 두 변수 사이에 아무런 관계도 없다고 설명합니다. 참으로 알듯 말듯 합니다. 중요한 것은 여기서 상관계수의 +와 - 는 모두 상관관계의 방향을 의미합니다. 앞서 상관계수에는 힘과 방향이 있다고 이야기 했지요? 음수이냐 양수이냐 하는 문제는 상관관계의 방향을 알려줍니다. 반면에 상관계수의 숫자 자체는 상관관계의 힘을 의미합니다. 상관계수가 절대값 1에 가까워질 수록 힘이 센 것입니다. 그러므로 +1과 -1이 가장 힘이 센 것입니다. 여기서 힘이 세다는 것의 의미는 데이터들이 서로 가깝게 모여있다는 의미이고 힘이 약하다는 의미는 데이터들이 서로 떨어져 있다는 의미가 됩니다. 그런데 이렇게 말로 해서는 이해가 안되지요? 그럼 이제 그림을 봅시다. 상관관계는 복잡한 수식을 먼저 보는 것이 아니라 그림을 보면서 이해하는 것이 더욱 중요합니다.\n\n\n\n\n\n\n\n(a) \\(\\gamma_{xy}=1.0\\)\n\n\n\n\n\n\n\n(b) \\(\\gamma_{xy}=0.8\\)\n\n\n\n\n\n\n\n(c) \\(\\gamma_{xy}=0.4\\)\n\n\n\n\n\n\n\n(d) \\(\\gamma_{xy}=0.0\\)\n\n\n\n\nFigure 1.4: 양의 상관관계\n\n\nFigure 1.4 은 양의 상관계수가 +1인 것부터 \\(0\\) (zero) 까지의 산포도를 보여주고 있습니다. 산포도란 우리가 가진 변수 \\(x\\)와 \\(y\\)를 두 축으로 하는 점을 찍은 그림입니다. 여기서 \\(\\gamma_{xy}\\)는 변수 \\(x\\)와 \\(y\\)의 상관계수를 의미합니다. 상관계수가 양수일 때, 점들이 우상향의 모습으로 찍혀있습니다. 이것은 방향입니다. 그러나 상관계수의 힘이 약해질수록, 즉, 상관계수의 값이 +1에서 작아질수록 점들이 점점 더 넓게 퍼지고 있습니다. 그러다가 상관계수가 \\(0\\) (zero)이 되면 거의 공모양처럼 둥글게 점들이 모여있는 것을 볼 수 있습니다. 이처럼 상관계수는 두 변수 사이의 패턴을 방향과 힘으로 보여주는 것입니다. 양의 상관관계가 있을 때, 우리는 자연스럽게 두 변수가 같은 방향으로 움직인다는 것을 알 수 있습니다. 그러나 상관계수가 \\(0\\) (zero)이 되면 두 변수 사이의 관계를 뭐라 말하기 어렵게 됩니다. 왜냐하면 사실상 두 변수는 아무런 관계가 없기 때문입니다.\n\n\n\n\n\n\n\n(a) \\(\\gamma_{xy}=0.0\\)\n\n\n\n\n\n\n\n(b) \\(\\gamma_{xy}=-0.4\\)\n\n\n\n\n\n\n\n(c) \\(\\gamma_{xy}=-0.8\\)\n\n\n\n\n\n\n\n(d) \\(\\gamma_{xy}=-1.0\\)\n\n\n\n\nFigure 1.5: 음의 상관관계\n\n\n다음으로 Figure 1.5 는 음의 상관관계를 보여줍니다. 상관계수가 “0” (zero)에서 시작하여 -1까지 줄어들 때의 산포도를 보여줍니다. 음의 상관관계란 결국 우하향하는 산포도를 보여주는 것이고 상관관계의 힘이 커질수록, 즉 상관계수가 \\(0\\) (zero)에서 -1까지 작아질 수록 점들이 모이게 되는 것입니다. 상관계수가 +1이거나 -1인 경우에 보면 점들이 모여 선처럼 보이는 것을 확인할 수 있습니다. 그런데, 바로 이 점에서 많은 분들이 오해하는 부분이 있습니다. 상관관계의 힘이 커지는 것은 점들이 얼마나 잘 모여 있는지를 의미하는데, 이를 점들이 모여서 이루는 각도가 상관관계와 관련이 있다고 오해하는 경우가 많습니다. 아래의 그림을 보면 이를 쉽게 이해할 수 있습니다.\n\n\n\n\n\n\n\n(a) \\(\\gamma_{xy}=1.0\\)\n\n\n\n\n\n\n\n(b) \\(\\gamma_{xy}=1.0\\)\n\n\n\n\n\n\n\n(c) \\(\\gamma_{xy}=1.0\\)\n\n\n\n\n\n\n\n(d) \\(\\gamma_{xy}=0.0\\)\n\n\n\n\nFigure 1.6: 상관계수가 +1인 경우와 0인 경우\n\n\nFigure 1.6 에서 보듯 첫 세개의 그림은 모두 상관계수가 +1입니다. 점들이 모여 이루는 선의 각도와 관계없이 점들이 모여서 선처럼 보인다면 모두 상관계수는 +1인 것입니다. 다만, 가장 우측의 경우는 예외입니다. 점들이 모여 선처럼 되어 있으나 선들이 이루는 모양을 보면 x축에 평행한 모습입니다. 그러므로, 이는 \\(x\\)가 증가해도 \\(y\\)는 아무런 변화가 없다는 것이되어 \\(x\\)와 \\(y\\)의 상관관계는 \\(0\\) (zero)이 됩니다. 이러한 형태는 음의 상관계수에도 동일하게 적용됩니다.\n\n\n\n\n\n\n\n(a) \\(\\gamma_{xy}=0.0\\)\n\n\n\n\n\n\n\n(b) \\(\\gamma_{xy}=-1.0\\)\n\n\n\n\n\n\n\n(c) \\(\\gamma_{xy}=-1.0\\)\n\n\n\n\n\n\n\n(d) \\(\\gamma_{xy}=-1.0\\)\n\n\n\n\nFigure 1.7: 상관계수가 -1인 경우와 0인경우\n\n\n앞의 경우와 동일하게 Figure 1.7 에서 우측 세 개의 그림은 모두 상관계수가 -1인 경우입니다. 그러므로, 꼭 기억해야할 것은 점들이 모여 선을 이룰 때, 이 직선의 각도와 상관관계는 아무런 관련이 없다는 것입니다. 한 가지 더 중요한 것이 있습니다. 우리가 공부하는 상관관계는 선형관계 (Linear relationship)을 전제로 한다는 점입니다. 선형관계라는 것의 의미는 두 변수가 만들어 내는 관계 (relationship)가 직선 (Line)의 형태로 이루어졌다는 것입니다. 즉, 상관계수는 두 변수가 직선형태의 선형관계일 경우에만 상관계수의 의미가 정확한 것이며, 만약 두 변수가 비선형적인 관계에 있을 경우 상관계수 자체를 믿을 수 없고 이 때의 상관계수는 잘못된 것이란 의미가 됩니다.\n\n\n\n\n\n\n\n(a) \\(\\gamma_{xy}=-0.82\\)\n\n\n\n\n\n\n\n(b) \\(\\gamma_{xy}=-0.09\\)\n\n\n\n\n\n\n\n(c) \\(\\gamma_{xy}=0.36\\)\n\n\n\n\n\n\n\n(d) \\(\\gamma_{xy}=0.0\\)\n\n\n\n\nFigure 1.8: 비선형관계에서의 상관계수\n\n\nFigure 1.8 에서 보듯이 점들이 직선의 형태가 아닌 꺾여 있거나 그냥 곰모양으로 뭉쳐있는 경우를 볼 수 있습니다. 마지막의 경우는 당연히 선형도 아니고 방향성도 알 수 없으므로 상관계수가 \\(0\\) (zero)이 되어 의사결정에 큰 영향을 미치지는 않으나, 앞의 세 가지의 경우에는 상관계수가 마이너스에서 플러스까지 다양하게 나오지만 분명히 그 움직임이 감소하다 증가하거나 증가하다 감소하는 등의 변화를 보입니다. 이 경우의 상관계수는 완전히 잘못된 것이므로 사용할 수 없습니다. 그러므로, 단순히 통계 프로그램으로 상관계수만을 확인하는 것은 매우 위험한 일입니다. 상관계수와 함께 산포도를 그려 변수 간의 전반적인 패턴을 분명히 확인할 필요가 있습니다.\n\n\n1.6.2 상관관계와 인과관계\n상관관계는 사실 내용을 들여다 보면 그렇게 어려운 내용은 아닙니다. 문제는 상관관계를 해석하는 과정에서 문제가 발생합니다. 많은 분들이 이 상관계수를 보고 두 변수의 상관관계를 해석할 때, 많은 경우 인과관계로 해석하는 경우가 많다는 것입니다. 인과관계(Causal relationship)란 원인과 결과 사이의 관계를 의미합니다. 저녁식사를 했기 때문에 배가 부른 것이고, 수입이 있기 때문에 지출이 있다는 식입니다. 여기서 저녁식사와 수입은 원인이고, 배가 부른 것과 지출이 발생한 것은 결과입니다. 즉, 둘 사이의 관계가 명확한 원인과 결과로서 인과관계가 있는 것이지요.\n그러나, 상관관계는 인과관계가 아닙니다. 상관관계에서는 원인과 결과가 없습니다. 그러므로 우리가 두 변수 \\(x\\)와 \\(y\\)의 상관계수 0.8을 해석할 때, 변수 \\(x\\)와 \\(y\\)는 0.8의 상관관계가 있다라고 말하고 이는 \\(x\\)가 증가할 때, \\(y\\)가 증가하고 또한 \\(y\\)가 증가할 때 \\(x\\)도 증가하는 관계일 뿐이라는 것입니다. 논문들을 보면 상관계수를 설명하면서 상관계수가 0.8이 나왔으니 \\(x\\)의 증가 때문에 \\(y\\)가 증가하는 것이 분명하다라는 식으로 해석하는 경우를 봅니다. 이는 상관관계를 인과관계로 해석하는 잘못된 경우입니다. 상관계수를 해석할 때는 항상 인과관계를 제외하고 설명해야 합니다.\n고생하셨습니다.\n이제 통계기초가 끝났습니다. 여러분들은 통계를 본격적으로 배우기 위한 생각의 전환에 성공하셨습니다. 생각을 바꾸고 통계의 기본적인 언어적 차이를 이해하셨을 것이라고 생각됩니다. 이제 본격적인 통계의 세계로 여행을 떠나봅시다!!\nYoutube 바로 가기"
  },
  {
    "objectID": "chapter2.html#멀고도-먼-길의-시작",
    "href": "chapter2.html#멀고도-먼-길의-시작",
    "title": "2  첫 도전 t-test",
    "section": "2.1 멀고도 먼 길의 시작",
    "text": "2.1 멀고도 먼 길의 시작\n\n2.1.1 t-test란 무엇일까?\n축하합니다!! 이제 여러분들은 통계다운 통계를 시작하게 되었습니다. 아마 모든 통계책의 가장 앞쪽에 등장하는 통계적인 방법이 바로 이 t-test일 것입니다. 우리말로는 t-검정이라고 합니다. 솔직히, t-검정은 공식도 비교적 단순하고 쉬워 보입니다. 그래서 굳이 자세하게 가르치지도 않지만 학생들도 굳이 꼬치꼬치 캐묻지 않는 대상입니다. 그러나 여기에 중요한 것이 있습니다. t-검정의 공식을 암기하고 문제를 풀어 정답을 맞히는 것보다 더 중요한 것은 바로 이 t-검정의 근본을 이해하는 것입니다. 이를 제대로 알고 간다면 이후에 등장할 분산분석 (ANOVA: Analysis of Variance)도 쉽게 이해될 수 있습니다. 그러나 이를 그냥 암기하고 넘어간다면 앞으로 등장할 통계가 어렵게만 느껴질 것입니다.\n위키 백과에서 t-test가 무엇인지 찾아보았습니다.\n\nt-테스트(t-test) 또는 t-검정은 검정하는 통계량이 귀무가설 하에서 t-분포를 따르는 통계적 가설 검정이다. t-검정은 검정 통계량의 스케일링 항 값이 알려진 경우 검정하는 통계량이 정규 분포를 따르는 경우에 가장 일반적으로 적용된다. 이 경우 모집단의 분산과 같은 스케일링 항을 알 수 없으나 이를 데이터를 기반으로 한 추정 값으로 대체하면 테스트 통계는 t-분포를 따른다.\n\n알 수 없는 말들이 많지요? 아마 어떤 통계책을 찾아보아도 비슷할 것입니다. 이렇게 설명해서는 도대체 알 수가 없습니다. 사실 그 이름부터가 도대체 알 수 가 없습니다. 여러분들이 새로운 통계방법을 공부할 때, 가장 중요한 것 몇 가지를 알려드리겠습니다. 첫 번째는 이 방법의 목적이 무엇인지 명확히 알아야 합니다. 책에 나오는 정의 말고 본인의 말로 표현할 수 있어야 합니다. 두 번째는, 이 새로운 통계적 방법의 기본적인 맥락입니다. 물론 수학적 감각이 뛰어나다면 몇 가지 공식이나 수식을 통해서 빠르게 이해할 수 있습니다. 하지만, 우리 같은 초보들에게는 머나먼 일이지요. 하지만 그래도 기본적인 프로세스와 흐름 및 방법은 알고 있어야 합니다. 세 번째는 분석결과를 어떻게 해석해야 하는지 알아야 합니다. 마지막으로 모든 분석방법은 절대 완벽하지 않으므로 각 방법이 가진 주의사항을 알아야합니다. 그럼 이제 t-test로의 여행을 떠나 봅시다!!\n\n\n2.1.2 이름이 왜 t-test일까?\nt-test의 발원지(?)가 영국 더블린의 기네스 맥주 공장이라는 사실을 알고 계신가요?\n여러 가지 설이 존재합니다만, 가장 많은 사람들이 신뢰하는 것은 바로 이 기네스공장입니다. 놀랍지요? 기네스 맥주는 아서 기네스란 사람의 이름을 따서 기네스란 이름이 됩니다. 아서 기네스는 잉글랜드 출신이었고 아일랜드에 정착을 하는데, 그러다보니 당시 잉글랜로서는 아일랜드 지배 강화를 위해 기네스를 우대합니다. 그런 이유인지는 모르겠으나 아서 기네스는 망한 양조장을 1년에 45파운드의 임대료를 내고 무려 9,000년간 임대를 하게 됩니다. 아직도 8000년 가까이 임대기간이 남아있다고 하니 정말 엄청나죠? 하여간 19세기 후반 기네스 맥주는 해가 지지 않는 대영제국의 위세를 타고 전 세계에 이름을 날리게 됩니다.\n이 시기는 경영학에서도 과학적 관리기법이라는 것들이 등장하기 시작하는 시기이고 당연히 당시 영국은 이런 변화를 주도하는 국가였습니다. 이런 분위기 때문이었는지 기네스는 맥주 양조장으로선 처음으로 과학자를 영입합니다. 처음엔 옥스퍼드대 출신의 화학자 토머스 베넷 케이스를 영입합니다. 1893년에 입사한 그는 맥주의 품질은 홉에서 연질 수지가 차지하는 비율과 관련이 있다고 보고 연질수지의 양을 추정해보려고 당시에 주로 사용되던 대형표본이론을 적용해 150개 이상의 표본으로 연구를 진행하고 싶었지만 충분한 표본을 확보하지 못하고 양도 적어 어려움이 있었습니다. 어느 보리가 연질 수지가 많은지 혹은 연질 수지가 비슷해도 어떤 보리가 더 많이 생산되는지 실험할게 많았던 것이지요.\n결국 맥주생산에 사용할 보리로 어떤 보리가 가장 좋은지 알아내려면 어마어마한 노력이 필요했습니다. 이 시기까지만 해도 아직 소규모의 표본으로 통계적 연구를 진행할 수 있는 이론적 기반이 없었던 것이지요. 이러한 이유로 연구가 지지부진할 때 기네스에 윌리엄 실리 고셋이 등장합니다. 고셋은 옥스퍼드에 입학하기 전에 윈체스터 대학을 다녔고 화학과 수학을 공부했으며 옥스퍼드를 졸업하고 더블린으로 건너가 기네스에서 일하기 시작합니다. 그가 연구한 분야는 기네스에서 가장 중요한 단일 성분인 보리의 수확량을 향상시키는 것이었습니다. 보리는 다른 작물과 마찬가지로 여러 가지 종류가 있는데 어떤 품종은 다른 것 보다 생산량이 더 많습니다. 같은 면적과 비슷한 조건에서 재배되었더라도 한 품종은 다른 것 보다 두 배의 생산량을 생산할 수도 있습니다. 이것은 복잡한 문제로 이어지는데요. 한 종류의 보리가 다른 것 보다 더 많이 생산된다면, 어떻게 합리적인 수준의 과학적 확실성을 결정할 수 있을지 문제가 되는 것이지요. 앞서 토머스 케이스가 어려워하던 문제가 바로 이것입니다.\n하지만 1900년대 초에는, 통계가 오늘날과 같지 않았습니다. 가설 실험은 존재했지만 매우 작은 표본에 대한 원칙은 없었기 때문에 당시에는 실험에서 충분한 크기의 샘플을 얻기 위해서는 넓은 땅에 많은 종류의 보리를 엄청나게 많이 재배하는 것이 유일한 해결책이었습니다. 그러나 고셋에게 이것은 용납할 수 없는 일이었습니다. 시간도 많이 걸리지만 가설 검사를 위해 엄청난 양의 농작물을 재배하는 것은 낭비였기 때문이죠. 고셋은 통계학 지식을 활용하여 문제 해결에 착수합니다. 특히, 그는 표본이 작은 정규 분포 모집단의 평균을 추정할 때 발생하는 연속 확률 분포를 공식화했고 두 개의 표본이 주어진다면 표본 크기가 작더라도 한 표본의 평균이 다른 표본의 평균과 어떻게 같은지를 계산할 수 있게 됩니다. 이것이 바로 우리가 알고 있는 t-test입니다.\n그런데 왜 이름이 이럴까요? 당시 기네스의 다른 직원이 신문에 글을 기고하다가 우연히 기네스의 영업 비밀을 누설하게 되었다고 합니다. 그래서 결국 기네스에서는 어떠한 유의 출판도 허용하지 않게 됩니다. 이 문제를 우회하기 위해 고셋은 본명대신 필명을 사용하여 회사의 눈을 피하기로 합니다. 혹자들은 기네스와 사전에 합의 되었다고도 하는데 그런 것 같지는 않습니다. 어쨌거나 그래서 윌리엄 고셋은 ’Student’란 필명으로 논문을 한편 쓰는데요. 이 논문에 등장한 테스트를 student test 혹은 student t-test라고 불렀습니다. 즉 student라는 단어의 마지막 t를 붙여 t-test라고 하는 것이지요. 만약 윌리업 고셋이 본인의 이름으로 출판을 했다면 아마도 고셋 테스트가 되었을 가능성이 컸을 겁니다.\nStudent. (1908). The probable error of a mean. Biometrika, 1-25.\n바로 이 논문이 그 유명한 student의 t-test가 처음으로 세상에 빛을 보게 되는 그 논문입니다. 구글 스칼라에서 검색하셔도 되고 위의 링크를 따라 가셔도 보실 수 있습니다. 생각보다는 그리 어렵지 않은 영어로 되어 있습니다. 시간이 되신다면 읽어보셔도 좋겠습니다. 저는 너무 지루하고 어렵고 졸려서 포기했습니다.\n\n\n2.1.3 t-test의 목적\n앞에서 t-test의 이름이 왜 t-test가 되었는지 배경은 설명했습니다. 이 설명에 t-test의 목적 비슷한 것이 잠시 지나가기는 했습니다만, 이제 확실하게 t-test의 목적이 무엇인지 이야기 하겠습니다. 사실 정확하지는 않으나 시작단계에서는 이렇게 외워두십시요.\n“t-test의 목적은 두 집단이 같은지 다른지 비교하기 위한 것이다.”\n\n\n\nFigure 2.1: t-test의 목적\n\n\nFigure 2.1 에 t-test의 목적을 그림으로 그려봤습니다. A와 B라는 두 집단 혹은 그룹이 같은지 다른지 알고 싶을 때 우리는 t-test를 하는 것입니다. 그런데, 여기서 우리가 집단 혹은 그룹이라고 표현하기는 했지만 통계학에서는 이를 표본(혹은 샘플)이라는 말로 사용합니다. 그런데 통계를 조금 공부해 보신 분들은 모두 알겠지만, 통계에는 표본(=sample)이라는 단어도 있고 모집단(=population)이라는 단어도 있습니다. 이 둘을 구분하지 못하면 우리는 t-test의 본질적인 의미 파악이 어려워집니다. 그러면 외국어라 생각하고 통계의 표본과 모집단의 차이에 대해 먼저 알아보고 갑시다.\n\n\n2.1.4 표본과 모집단\n표본은 영어로 sample이라고 합니다. 그냥 우리말로 샘플이라고 쓰기도합니다. 저도 이 둘을 섞어서 사용하니 이해하시길 바랍니다. 모집단은 영어로 population이라고 합니다. 그러면 표본과 모집단의 차이는 무엇일까요? 다음의 그림을 한 번 봅시다.\n\n\n\nFigure 2.2: 표본과 모집단\n\n\n먼저 표본과 모집단의 차이를 이해하려면 Figure 2.2 를 보면 됩니다. 그림의 모든 사람을 모집단이라고 합니다. 즉, 모집단이란 우리가 연구하려는 대상 전체를 말합니다. 예를 들면 대한민국 성인남성의 키와 몸무게를 알고 싶다면, 이 연구의 모집단은 대한민국의 모든 성인남성이 됩니다. 정말 엄청나게 큰 숫자가 될 것입니다. 대한민국의 모든 성인남성을 모아서 키와 몸무게를 재는 일은 정말 엄청난 일입니다. 이러한 연구를 하겠다고 하면 개인의 수준에서는 불가능합니다. 그래서 통계에서는 모집단의 일부만을 대상으로 데이터를 모아서 연구를 합니다. 이때의 표본이 바로 이 모집단의 일부로 그림에서 우측의 검은 상자 안에 있는 파란색의 사람들을 의미합니다. 그러나 표본은 아무렇게나 모으는 것이 아닙니다. 샘플을 모으는 것을 샘플링이라고 하는데 이 샘플링은 매우 엄격한 기준에 의해 진행되어야 합니다. 왜냐하면 표본(샘플)이 항상 모집단을 대표할 수 있어야 하기 때문입니다.\n또한 통계학에서는 모집단과 표본에 사용할 수 있는 기호를 분리해 두었습니다. 그림에서 보듯이 관측치라는 것은 흔히 데이터의 사이즈(크기)를 의미합니다. 설문조사를 했다면 설문에 응답한 응답자의 숫자가 바로 여기에 해당합니다. 문제는 같은 관측치 혹은 사이즈라고 해도 모집단의 경우에는 대문자 N을 사용하고, 샘플의 경우 소문자 n을 사용합니다. 여기서 주의할 점이 있습니다. 여러분들은 아마도 거의 평생에 모집단 데이터를 만날 일이 없을 것이라는 점입니다. 아주 일부의 운 좋은 그리고 능력 있는 사람들만이 이 모집단 데이터에 접근할 수 있지 않을까 생각됩니다. 저도 아직 모집단 데이터를 본적은 없습니다. 너무 거대한 데이터이므로 아마 제게 주어진다고 해도 쉽게 분석하기는 어렵지 않을까 생각합니다. 그러므로 우리가 논문을 쓰거나 보고서를 쓸 때, 통계적인 부분을 기술할 경우 데이터의 사이즈를 영문으로 표현할 때는 소문자 n을 사용하는 것이 맞습니다. 가끔 논문을 읽다보면 본인의 논문에 강력한 인상을 남기려는 것인지는 모르겠으나 샘플 사이즈를 n이 아닌 N으로 표기하는 경우를 간혹 봅니다. 잘못된 경우입니다.\n다른 기호들을 살펴보겠습니다. 평균값을 보면 모집단은 \\(\\mu\\) 라고 쓰여 있습니다. 그리스문자로 “뮤”라고 읽습니다. 의미는 평균값이고 모집단의 평균값입니다. 반면에, 샘플의 평균값은 \\(\\bar{x}\\)라고 쓰여 있습니다. 이것은 “엑스 바”라고 읽습니다. 여기서 위의 줄이 하나 그어져 있는 것을 바(bar)라고 읽는 것이지요. 이것은 샘플 즉 표본의 평균입니다. 이러한 구분은 표준편차에서도 나타납니다. 모집단의 표준편차는 \\(\\sigma\\) 이고 “시그마”라고 읽습니다. 반면에 샘플의 표준편차는 영어의 standard deviation의 소문자 s를 사용합니다. 물론 분산은 각 표준편차의 기호에 제곱을 하면 됩니다. 이제 여러분들은 통계라는 외국어의 기본언어를 익히신 것입니다. 어떤 책에 \\(\\mu\\) 라고 쓰여 있으면, 아하 이것은 모집단의 평균값을 의미하는 구나하고 이해하시면 됩니다. 더불어 여러분들이 논문이나 보고서를 쓰실 때는 위의 모집단이 아닌 샘플에 해당하는 기호를 꼭 써야한다는 점을 기억하시기 바랍니다.\n\n\n2.1.5 t-test의 목적을 더 알아보자\n앞서 t-test의 목적은 두 집단이 같은지 혹은 다른지 알고 싶을 때 하는 통계적 분석방법이라고 했습니다. 이제 이를 좀 더 구체화해 봅시다. t-test의 목적은 두 집단이 동질한지 아니면 이질적인지를 통계적으로 분석하겠다는 것입니다. 그렇다면 어떻게 두 집단이 동질한지 혹은 이질적인지 알 수 있을까요? 너무 당연한 질문처럼 보이지만 매우 중요한 문제입니다. 만약 두 집단에 각각 10개의 데이터 값이 있을 때, 만약 이 값들을 1대1로 비교하겠다면 우리는 10×10=100개의 조합을 생각해야합니다. 게다가 이 100개의 비교를 어떻게 해야 할까요? 상당히 어려운 문제가 됩니다. 만약 각 집단에 1억 개의 데이터가 존재한다면 우리는 더 이상의 분석을 진행할 수 없을 것입니다. 그러면 이제 여기서부터 우리가 앞서 공부했던 통계의 대표적인 측정값들이 등장해야 합니다. 두 개의 집단을 비교하는데 우리는 어떤 통계적인 측정값을 이용할까요? 당연히 평균입니다. 왜 그럴까요? 앞서 이야기 한 것처럼, 평균값은 데이터의 중심을 대표하는 대푯값입니다. 그러므로 각 집단의 중심을 대표하는 대푯값인 평균값으로 비교하면 두 집단이 같은지 다른지 알 수 있습니다.\n\n\n\nFigure 2.3: t-test의 보다 구체적인 예제\n\n\n이렇게 대푯값으로서의 평균의 의미는 엄청납니다. 개별 데이터의 값들을 1대 1로 매칭해서 비교할 필요가 없습니다. 한 집단의 샘플 사이즈(n)가 1억 개라도 괜찮습니다. 지금의 컴퓨팅능력이면 평균값 정도는 쉽게 우리에게 알려줍니다. 이제 다시 우리는 앞의 t-test를 좀 더 구체적인 예제로 만들어 보겠습니다. 두 집단이 같은지 다른지를 평균값으로 비교하겠다는 것은 좀 막연한 느낌이 듭니다. 구체적인 예를 들어봅시다. 우리가 사는 동네에는 근처에 두 개의 대학이 있습니다. 하나는 A대학이고 다른 하나는 B대학입니다. 가까이에 있는 두 대학교이기에 평소에는 큰 차이를 느끼지 못했습니다. 그런데, 금년 봄에 이 두 대학의 학생들이 각자 자기 대학의 로고가 새겨진 점퍼를 입고 다니는 것을 자세히 보니, A대학과 B대학의 남학생들의 키가 좀 달라보였습니다. 궁금한 나머지 이와 관련한 t-test를 진행해 보기로 했습니다. 이를 우리 나름대로의 통계 프로젝트 No.1으로 명명하겠습니다. 이 프로젝트의 목적을 구체적으로 말하면 무엇일까요? 아마도 A대학과 B대학의 남학생의 평균키가 같은지 다른지 알아보겠다 정도가 될 것입니다.\n이러한 프로젝트의 목적은 바로 t-test의 목적이 됩니다. 보다 구체적인 평균키가 궁금했던 나머지 우리는 두 대학에 연락하여 남학생의 평균키를 알려달라고 부탁했고, 다행스럽게도 두 대학의 남학생의 평균키를 다음과 같이 확인할 수 있었습니다.\n\n\n\nFigure 2.4: 두 대학교 남학생의 평균키를 비교하는 t-test\n\n\n이제 통계 프로젝트 No.1의 목적이자 t-test의 목적을 보다 통계적인 사고방식을 기반으로한 질문으로 바꿔보면 이렇게 될 것입니다.\n\nA대학 남학생 평균키(178.5cm)와 B대학 남학생 평균키(179.9cm)가 우연히 같은 확률은 얼마나 될까?\nA대학과 B대학의 남학생 평균키 차이인 1.4cm가 우연히 발생했을 확률은 얼마나 될까?\n\n위의 두 질문은 같은 질문을 다른 방법으로 표현한 것 뿐입니다. 이제 우리는 기본적인 t-test의 목적을 이해했습니다. 첫 술에 배부를 수는 없습니다. 가야할 길이 아직 멀고도 멀어서 조금은 지칠 수도 있지만 원래 처음이 어려운 법입니다. 이제 첫 번째 산을 넘었으니 다음 산을 향해 나아가 봅시다.\nYouTube 바로 가기"
  },
  {
    "objectID": "chapter2.html#몸풀기가-이렇게-어렵다니",
    "href": "chapter2.html#몸풀기가-이렇게-어렵다니",
    "title": "2  첫 도전 t-test",
    "section": "2.2 몸풀기가 이렇게 어렵다니",
    "text": "2.2 몸풀기가 이렇게 어렵다니\n\n2.2.1 그래서 어떻게 하겠다는 것일까?\n앞에서 우리는 t-test의 목적이 무엇인지 그리고 우리의 예제를 t-test의 목적에 맞춰 통계적 의사결정 방법에 맞게 질문하는 법을 알아보았습니다. 우리가 하려는 t-test의 목적은 다음과 같습니다.\n\nA대학 남학생 평균키(178.5cm)와 B대학 남학생 평균키(179.9cm)가 우연히 같은 확률은 얼마나 될까?\nA대학과 B대학의 남학생 평균키 차이인 1.4cm가 우연히 발생했을 확률은 얼마나 될까?\n\n여기서 두 집단이 다르다면, 즉 두 대학의 남학생의 평균키가 다르다는 의미가 될 것입니다. 평균키가 다르다는 것은 두 대학 남학생의 평균키의 차이가 크다는 의미가 될 것입니다. 위에서 보았듯이 두 대학 남학생의 평균키의 차이는 1.4cm 입니다. 어떤가요? 평균키의 차이가 큰 것인가요? 아니면 작은 것인가요? 여기부터가 진짜 통계입니다. 누군가는 이 차이가 크다고 할 것이고 누군가는 그냥 크지 않다고 할 수 있습니다. 만약 이 차이가 크다면 우리는 이 두 대학 남학생의 키 차이 1.4cm가 우연히 발생한 것이 아니라고 할 것입니다. 반면, 만약 이 차이가 작다면 우리는 이 두 대학 남학생의 키 차이 1.4cm가 우연히 발생한 것이라고 결론 내릴 것입니다. 그런데 도대체 얼마나 커야 큰 것이고 얼마나 작아야 작은 것일까요?\n여기서 우리의 지혜가 필요합니다. 우리가 가진 숫자는 1.4cm의 차이라는 것뿐이고, 이 평균값의 차이만 가지고서는 이 값이 큰지 혹은 작은지 판단할 방법이 없습니다. 그러므로 우리는 판단에 도움이 될 만한 다른 참고할만한 숫자가 필요합니다. 그게 무엇일까요? 여태 우리가 배운 통계는 너무나 단순해서 아는 것이 없다고 생각할 수도 있으나 이미 여러분들은 답을 알고 있습니다.\n무엇일까요? 바로 표준편차 (혹은 분산)입니다. 왜 그럴까요?\n\n\n2.2.2 표준편차로 다시 돌아가자\n앞에서 살펴보았던 예를 다시 봅시다. 우리가 가진 데이터가 {1, 2, 3, 4, 5}라고 합시다. 이 데이터의 평균은 아래와 같이 3입니다. 그리고 분산의 공식을 적용해서 분산을 구해보면 분산은 2.5입니다.\n\\[(1+2+3+4+5)\\div5=3\\]\n\\[\\text{Variance}=s^2=\\frac{\\sum_{i=1}^n (x_i-\\bar{x})^2}{n-1}\\]\n\\[\\frac{(1-3)^2+(2-3)^2+(3-3)^2+(4-3)^2+(5-3)^2}{4}=2.5\\]\n분산이란 우리가 가진 데이터가 평균을 중심으로 얼만큼 퍼져 있는가를 말해 주는 대푯값입니다. 즉, 평균값으로부터 데이터가 퍼져 있는 평균적인 거리(distance)입니다. 그럼 다시 생각해 봅시다. 우리의 데이터는 {1, 2, 3, 4, 5}였습니다. 평균은 3이고 분산은 2.5입니다. 여기에 다시 제곱근을 붙여 분산을 표준편차로 바꾸면 평균값과 단위가 일치하게 됩니다. 2.5에 제곱근을 씌우면 약 1.58정도 됩니다. 따라서 우리의 데이터는 3을 중심으로 플러스와 마이너스 양방향으로 1.58정도 퍼져 있는 것이고 그 범위는 대략 1.42부터 4.58까지 입니다.\n중요한 것은 여기서 표준편차의 퍼져있는 정도 (=편차)가 의미 있는 (=원인이 있는) 편차인지 아니면 의미 없는 (=원인이 없는) 편차인지 알아야 합니다. 복잡한 설명을 다 차치하고 단순하게 생각해봅시다. A대학교의 남학생의 평균키는 178.5cm입니다, 이것은 평균일 뿐이고 A대학교 모든 남학생의 키가 178.5cm일 수는 없습니다. 그러면 이제 이 키라는 변수는 더 이상 변수가 아니고 상수가 될 것입니다. 또한, 현실에서 모든 A대학의 남학생의 키가 같은 것은 상상할 수 없습니다. 말도 안 되는 것이지요. 현실에서 아무리 키가 똑같아 보이는 두 사람일지라도 정밀한 장비로 키를 재본다면 아주 미세하게라도 분명히 차이가 날 것입니다. 그러므로 이러한 표준편차는 특별한 의미가 없는 혹은 특별한 원인이 없는 편차라고 보는 것이 당연합니다. 만약 이 편차에 뭔가 원인이 있거나 의미가 생겨버린다면 이는 사실 꽤나 고차원적인 통계로 넘어가게 됩니다. 지금 우리가 배우는 기초통계에서는 표준편차 (혹은 분산)이란 의미 없는 말 그대로 무작위의 (random) 편차입니다. 편차도 결국엔 일종의 차이 값이지요. 왜냐하면 표준편차란 평균값을 기준으로 데이터의 평균적인 차이일 뿐인 것이기 때문입니다.\n그러므로 이제 우리는 두 대학의 평균키의 차이인 1.4cm가 큰 차이인지 작은 차이인지 결정할 수 있는 비교대상인 표준편차라는 새로운 숫자를 하나 더 가지게 되었습니다. 그렇다면 이제 다시 이 문제로 돌아와서 살펴봅시다. 두 대학의 평균키의 차이인 1.4cm는 다른 의미로 보자면 두 집단의 수많은 데이터들 사이의 평균적인 거리가 1.4cm라는 의미가 됩니다. 즉, 두 집단의 평균값의 차이도 일종의 편차인 것입니다. 여기서 이제 우리가 데이터를 통해 표준편차 s를 얻었다고 가정해 봅시다.\n그러면 우리의 의사결정은 다음과 같은 방법으로 진행될 것입니다.\n\n두 집단 A와 B의 데이터 사이의 평균적인 거리는 1.4cm이고\n두 집단 A와 B의 데이터들의 표준편차는 Scm 입니다.\n만약 이 1.4cm가 표준편차 Scm보다 현저히 작다면, 우리는 이 1.4cm의 차이에 큰 의미를 둘 수 없을 것이므로 이 1.4cm의 차이는 우연히 발생했다고 결론 내릴 것입니다.\n그러나 만약 이 1.4cm가 표준편차 Scm보다 현저히 크다면, 우리는 이 1.4cm의 차이에 큰 의미를 둘 수 있을 것이므로 이 1.4cm의 차이는 우연히 발생하지 않았으며 무언가 이 차이에는 원인 혹은 이유가 있을 것이라고 결론 내릴 수 있을 것입니다.\n\n\n\n2.2.3 통계는 분산의 마법이다\n아직도 이 말이 어색하실 것입니다. 그러나 t-test부터 분산의 역할은 매우 중요합니다. 왜냐하면 평균값의 차이만 가지고서는 이 값이 충분히 큰지 혹은 충분히 작은지 판단할 수 없기 때문입니다. 그러므로 특별한 의미가 없는 무작위의 random한 차이인 표준편차를 가져와서 표준편차와 평균값의 차이를 비교하는 것이 t-test의 핵심입니다. 그러므로 이미 분산의 마법이 시작된 것이지요. 만약 우리에게 분산 (혹은 표준편차)가 없었다면 이러한 통계적인 분석은 불가능 했을 것입니다. 분산이나 표준편차가 통계에서 가지는 의미는 엄청납니다. 특히 기초통계에서는 분산과 표준편로 거의 모든 문제를 해결해 나갑니다. 그러므로 다시 한 번 마음속에 새겨두길 바랍니다. 통계는 분산의 마법입니다.\nYouTube 바로 가기"
  },
  {
    "objectID": "chapter2.html#너무-빨리-먹으면-체합니다",
    "href": "chapter2.html#너무-빨리-먹으면-체합니다",
    "title": "2  첫 도전 t-test",
    "section": "2.3 너무 빨리 먹으면 체합니다",
    "text": "2.3 너무 빨리 먹으면 체합니다\n우리는 앞서 t-test의 목적과 t-test를 위해서는 평균값의 차이뿐만 아니라 표준편차가 비교 대상으로서 필요하다는 것을 이해했습니다. 그러면, 이제 바로 t-test로 들어가야 하겠지만 아직 그 전에 넘어야할 산이 몇 개 있습니다. 바로 t-test로 직행하지 않는 이유는 제가 수년간 가르쳐보니 너무 빨리 먹으면 체하더라는 경험 때문입니다. t-test로 가기 전에 우리는 z-test라는 이유식을 먼저 먹고 갈 것입니다. 사실, 많은 통계책에서는 z-test와 t-test를 별개의 분석방법으로 보기도 하지만, 그 근본은 같은데서 시작한 것으로 z-test를 이해하게 되면 t-test를 이해하는데 도움이 많이 됩니다. 또한 이제부터 볼 z-test에 등장하는 내용들은 앞으로 통계에서 매우 자주 나오는 것이므로 잘 봐두시면 좋겠습니다. 일단 t-test와 z-test의 관계에 대해 알 수 있는 그림을 하나 보여드리겠습니다.\n\n\n\nFigure 2.5: t-test와 z-test의 관계\n\n\n이미 앞에서 본 적이 있는 그림입니다. 차이가 있다면, 모집단 아래에 z-test라고 되어 있고, 표본 아래에 t-test라고 되어 있는 것이 다릅니다. 기본적으로 z-test와 t-test의 차이는 분석하는 데이터가 모집단일 경우에는 z-test를 하는 것이고, 분석하는 데이터가 표본일 경우에는 t-test를 한다는 것입니다. 그러니 이제 여러분들은 모집단에는 z-test 그리고 표본에는 t-test라고 외워두시면 됩니다. 그럼 이제 본격적으로 z-test에 대해 알아보겠습니다.\n\n2.3.1 정규분포란?\n통계를 조금 공부해보신 분이라면 정규분포라는 말을 들어보셨을 것입니다. Figure 2.6 과 같이 생긴 것이 정규분포입니다. 흔히 정규분포를 종 모양 (bell shape)이라고 말합니다. 이 분포곡선은 가운데의 \\(\\mu\\)인 평균값을 중심으로 좌우가 대칭인 곡선입니다. 즉, 정 가운데를 중심으로 접으면 양쪽이 똑같다는 뜻입니다. 또한 정규분포곡선의 양쪽 끝은 “0” (zero)을 향해 가지만 영원히 닿지는 않습니다. 아래의 그림에서 보면 두 개의 값만 있으면 정규분포를 규정할 수 있습니다. 바로 평균값 \\(\\mu\\) 와 표준편차 \\(\\sigma\\) 입니다. 앞에서 우리는 통계의 대푯값이 평균과 표준편차라고 했는데 이 두 개의 값으로 만들 수 있는 곡선이 바로 정규분포곡선입니다. 이 곡선은 통계에서 기본이 되는 중요한 곡선입니다.\n문제는 보통은 여기까지 설명하고 끝이 난다는 점입니다. 물론 똑똑하신 분들이나 이공계분들에게는 너무 쉽고 당연한 것들이지만 문과돌이에게는 그래서 어쩌란 말인가 싶습니다. 여기서 중요한 것 두 가지를 이야기 하겠습니다.\n\n평균과 표준편차가 다르다면 세상에는 무한대 개의 서로 다른 정규분포가 존재한다.\n정규분포곡선 아래의 색깔을 칠한 면적이 확률이다\n\n이 두 가지를 꼭 알아야 합니다. 특히 두 번째, 정규분포곡선 아래의 색깔을 칠한 면적은 확률을 의미한다는 이것이 매우 중요합니다.\n그러므로 Figure 2.6 의 곡선 아래 면적의 합은 당연히 “1”이 됩니다. 왜냐하면 확률의 합은 1이기 때문입니다. 이러한 배경을 바탕으로 만약 우리가 가진 데이터가 정규분포를 따른다면, 우리는 평균과 표준편차 두 개의 값으로 많은 것을 알 수 있습니다. Figure 2.6 의 정 중앙은 평균값이며 이 평균을 중심으로 좌우로 1×표준편차만큼 좌우로 구간이 파란색을 칠해져 있습니다. 그 안의 34.1%라는 것이 바로 이 파란색 부분의 면적이자 확률입니다. 그러므로 평균값±1×표준편차의 구간 안에는 우리가 가진 데이터의 68.2%의 관찰값이 존재하게 됩니다. 전체 데이터의 절반 이상이 평균값을 중심으로 ±1×표준편차의 구간 안에 존재한다는 것입니다. 이를 이제 ±2×표준편차의 구간으로 확대해보면 파란색 바깥쪽의 초록색 구역이 됩니다. 즉 ±1×표준편차부터 ±2×표준편차의 구간 사이에 각각 13.6%의 데이터가 존재하고 이를 합하면 초록색의 면적은 27.2%가 되는 것을 알 수 있습니다. 그러므로 평균값을 중심으로 ±2×표준편차의 구간에는 총 95.4%의 데이터가 포함되게 되어 있습니다. 즉, 거의 모든 데이터가 이 안에 들어간다는 것입니다. 단 4.6%의 데이터만이 이 바깥에 존재합니다. 마지막으로 이 구간을 평균값을 중심으로 ±3×표준편차까지 확대하면 전체 데이터의 99.7%가 이 안에 존재합니다. 실로 놀라운 일입니다. 아닌가요?\n\n\n\nFigure 2.6: 정규분포곡선\n\n\n\n\n2.3.2 p값과 정규분포곡선의 관계\n여기서 한 가지 더 이야기할 것은 앞서 우리가 어떤 사건이 우연히 일어날 확률의 확률값이 바로 p값이라고 했습니다. 그런데, 이 p값을 어디서 어떻게 구하는 것인지에 대해서는 이야기 하지 않았습니다. 이 정규분포가 가지는 의미를 이야기 하자면, 정규분포의 아래 면적이 확률이라고 했습니다. 바로 이 면적이 우리가 구할 p값입니다. 물론 통계에는 정규분포 말고도 많은 분포곡선들이 존재합니다. 일단 여기서는 정규분포곡선만 생각합시다. 우리가 어떤 사건이 우연히 발생할 확률을 알고 싶다면 지금은 정규분포의 아래의 면적을 구해야 합니다. 그러려면 고등학교에서 배운 적분을 활용해야 합니다. 이미 예상하시다시피 정규분포곡선의 식을 적분을 하는 것은 가능한 일이지만 이는 문과돌이에게는 불가능에 가까운 일이며 미친 짓입니다. 그러니 이 문제를 해결할 필요가 있습니다.\n\n\n2.3.3 표준 정규분포\n보통 통계책들은 왜 표준 정규분포가 필요한지 설명하지 않고 바로 표준 정규분포의 특징을 이렇게 설명합니다. 표준 정규분포란 평균이 “0” (zero)이고 표준편차가 “1”인 정규분포를 표준 정규분포라고 한다. 맞는 설명입니다만 아직 우리가 왜 이 표준 정규분포가 필요한지 모르겠다는 데에 문제가 있습니다. 앞에서 우리는 이 세상에는 평균과 표준편차만 다른 무한대 개의 정규분포가 있다고 이야기 했습니다. 그리고 지금 우리는 이 정규분포의 아래쪽 면적을 구하고 싶습니다. 왜냐하면 이 면적이 곧 확률이며 이 확률이 바로 우리가 원하는 p값이기 때문입니다. 문제는 면적을 구하려면 적분을 해야하는데, 매번 적분을 해서 p값을 찾아내려면 우리는 거의 통계 자체보다 계산에 엄청난 노력과 시간을 보내야만 할 것입니다. 솔직히 저도 정규분포를 적분 할줄 모릅니다. 우리 문과돌이들의 애환이라고 할 수 있습니다.\n사실 이 복잡한 적분을 할 수 있다고 해도 이는 분명히 시간과 노력의 낭비입니다. 그래서 친절한 우리의 통계학자들은 우리를 위해 표준 정규분포를 정의하고 표준 정규분포곡선의 아래쪽 면적을 친절하게 표로 만들어 주었습니다. 즉, 우리는 정규분포를 적분할 수고를 덜 수 있다는 것입니다. 이제 어떻게 이 표준 정규분포를 이용할지 알아 봅시다.\n\n\n2.3.4 표준 정규분포 사용 예제\n이제 다음의 예제를 사용하여 표준 정규분포를 사용해 봅시다. 금년 A 대학교는 신입생 1000명을 대상으로 영어 실력 고사를 시행하였습니다. 시험 결과 영어점수의 분포가 정규분포에 근사하였습니다. 여기서 근사란 정규분포를 비슷하게 따랐다는 것을 의미합니다. 그러므로 우리는 영어 점수에 정규분포를 적용할 수 있습니다. 영어시험 결과 평균점수는 82점이었고 표준편차는 5점이었습니다. 이 때, 82점부터 90점까지의 점수를 받은 학생 수는 몇명일까요?\n만약 이 문제를 적분해서 풀으려 한다면 평균이 82이고 표준편차가 5인 정규분포곡선에서 Figure 2.7 처럼 82점부터 90점까지의 붉은 부분의 면적에 적분을 적용해 계산해야 합니다. 이 면적이 곧 확률이므로 “계산된 확률×1000명”을 구해보면 82점부터 90점까지의 점수를 받은 학생 수를 구할 수 있습니다. 그런데 이걸 적분할 수 있을까요? 불가능합니다. 아니 정확히는 무의미합니다.\n\n\n\nFigure 2.7: 정규분포곡선으로 적분할 경우\n\n\n그래서 우리는 Figure 2.7 의 붉은 부분을 적분하는 대신에 우리가 가진 정규분포곡선을 표준 정규분포곡선으로 변환해야 합니다. 그 방법이 바로 표준화입니다. 표준화 공식을 알아보기 전에 위의 정규분포가 어떻게 표준 정규분포가 될 수 있는지 그림으로 먼저 살펴보겠습니다.\nFigure 2.8 를 살펴보면 위쪽의 정규분포는 우리가 가진 1000명의 학생의 시험점수를 그린 것입니다. 중앙의 평균값이 82점이고 우리가 알고 싶어 하는 90점까지의 구간이 붉은 색으로 칠해져 있습니다. 이를 표준 정규분포로 바꾸어야 하는데 기본적인 개념은 이렇습니다. 화살 점선으로 표현되어 있듯이 정규분포의 중앙의 82점은 자연스럽게 표준 정규분포의 “0”으로 전환됩니다. 왜냐하면 지금 이 부분은 평균값이기 때문에 굳이 계산을 하지 않아도 알 수 있습니다. 문제는 우리가 가진 정규분포의 90점이 표준 정규분포에서 얼마인지 알 수는 없습니다. 이 값을 알려면 표준화 공식을 적용해야 합니다. 표준화란 말 그대로 데이터를 표준화된 숫자로 변경하는 것입니다. 표준화의 장점은 단위(unit)가 없어진다는 점입니다. 일단 표준화 공식을 확인해 보겠습니다.\n\n\n\nFigure 2.8: 정규분포와 표준정규분포\n\n\n\\[\\text{z-score}=\\frac{x-\\mu}{\\sigma}\\]\nz-score란 표준화점수로 z값이라고도 합니다. 분자의 \\(x\\)는 우리가 원래 가지고 있던 숫자입니다. 예제에서 평균점수인 82점이나 우리가 알고 싶어 하는 90점이 이 \\(x\\)에 속합니다. 그 다음에 등장하는 \\(\\mu\\)는 당연히 평균값이고 분모의 \\(\\sigma\\)는 표준편차입니다. 쉽게 말해 표준화란 주어진 값에서 평균값을 뺀고난 후 표준편차로 나누어준 수입니다. 이렇게되면 앞서 이야기 했듯이 원래 \\(x\\)가 가지고 있던 단위(unit)가 사라집니다. 이 z값을 굳이 해석해 보자면, 1 표준편차당 관찰값(\\(x\\))가 평균으로부터 얼마나 떨어져 있는지를 의미합니다.\n그럼 이제 82점과 90점을 표준화 공식에 따라 변경해보겠습니다. 이 방법을 영어로는 z-transformation이라고도 합니다.\n\\[z_{82}=\\frac{82-82}{5}=0\\] \\[z_{90}=\\frac{90-82}{5}=1.6\\]\n\\(z_{82}\\)는 원래의 82점을 z값으로 변환한 값이라는 의미입니다. 82점에서 평균점수인 82점을 빼고난 후 표준편차 5로 나누면 0 (zero)이 됩니다. 즉, 우리가 원래 가지고 있던 정규분포의 82점을 표준 정규분포상의 0 (zero)으로 변환한 것입니다. 이는 위의 Figure 2.8 에서 보아도 알 수 있는 사실입니다. 다음으로 우리가 가진 정규분포상의 90점을 표준 정규분포로 전환하려면 90에서 평균인 82를 빼고 이를 다시 5로 나누면 됩니다. 결과는 1.6이 됩니다. 즉, 우리가 가진 정규분포에서의 90점은 표준 정규분포상에서 1.6이 됩니다. 흔히 이것을 z값이 1.6이라고 표현합니다. 그러므로 우리가 구하고자 하는 면적은 표준 정규분포상에서 0부터 1.6까지의 면적이 됩니다. 이 면적을 구하려면 원래는 적분을 해야하지만 친절하게도 통계학자들이 이 면적 즉 확률에 관한 표를 만들어 두었습니다. 이것을 z-table이라고 하는데 모든 통계 교과서의 뒤쪽에 항상 포함되어 있으며 인터넷에서 표준 정규분포표라고 검색하면 찾을 수 있습니다. 이제 우리는 이 z-table을 이용하여 확률을 구해보겠습니다.\n\n\n2.3.5 표준 정규분포표의 사용법\n인터넷에서 표준 정규분포표를 검색하여 사용해보겠습니다. 아래의 Figure 2.9 는 표준 정규분포표의 상단입니다. 책마다 다소 다르게 사용할 수도 있으니 이부분을 잘 보는 것이 중요합니다. 상단에 표준 정규분포 곡선이 있고 붉은색으로 왼쪽 끝부터 1까지 면적이 표시되어 있습니다. 이것이 의미하는 바는 이 표준 정규분포표는 좌측 끝부터 해당 z값까지의 확률값을 표현하고 있다는 의미입니다.\n\n\n\nFigure 2.9: 표준정규분포표 읽는 법\n\n\n그러면 이제 표준 정규분포표의 구성을 보겠습니다. Figure 2.10 에 표준 정규분포표를 잘라서 보여드리겠습니다. 표준정규분포표에서 우리가 원하는 값을 찾는 방법은 다소 독특합니다. 표준 정규분포표의 가장 왼쪽의 첫번째 열은 소수 첫번째 자리까지만 표현되어 있습니다. 그리고 표의 가장 상단 첫번째 행에는 소수 둘째 자리가 표현되어 있습니다. 따라서 우리가 찾는 z값이 0.40이라면 좌측 첫번째 열에서 0.4를 찾고 그 행에서 0.00에 속하는 값을 읽으면 0.6554가 됩니다. 이는 Figure 2.9 가 설명하듯, 표준 정규분포의 왼쪽 끝부터 z값인 0.40까지의 면적이자 확률이 0.6554라는 것이고 이를 환산하면 65.54%가 됩니다. 만약 우리가 찾는 z값이 0.45라면 좌측 첫번째 열에서 0.4를 찾고 그 행에서 0.05에 해당하는 값인 0.6736이 바로 확률값이 됩니다. 이런 방식을 적용하면 적분을 하지 않고 우리가 원하는 확률값을 찾을 수 있습니다.\n\n\n\nFigure 2.10: 표준 정규분포표에서 z값을 찾는 법\n\n\n다시 우리의 예제로 돌아와 봅시다. 우리가 원하는 것은 Figure 2.11 에 있습니다.\n\n\n\nFigure 2.11: 정규분포에서 표준 정규분포로 전환\n\n\n우리는 원래 가지고 있던 90점을 표준화하여 z값 1.6을 구했습니다. 그러므로 표준 정규분포표 즉 z-table에서 찾아야 하는 z값은 1.6입니다. 그러면 이제 다시 표준 정규분포표로 돌아가 z값 1.6에 해당하는 확률값을 찾아 봅시다.\n\n\n\nFigure 2.12: 표준 정규분포표를 이용한 z값 찾기\n\n\n앞에서 해보았듯이 우리가 찾을 값은 1.6이므로 첫번째 열에서 1.6을 찾고 0.00에 해당하는 값을 찾으면 됩니다. 그림에서 볼 수 있듯이 0.9452입니다. 그런데 Figure 2.9 와 Figure 2.11 를 비교해 보면, 우리가 원하는 것은 평균값 0을 중심으로 좌측의 면적은 제외한 것을 찾고 싶습니다. 그렇다면 어떻게 해야할까요? 앞서 우리는 정규분포곡선의 특징을 이야기할 때, 평균값을 중심으로 좌우대칭이라는 이야기를 했습니다. 그러므로 평균값 0을 중심으로 좌측의 확률은 0.5가 됩니다. 그러므로 우리가 원하는 확률은 0.9452 - 0.5 = 0.4452가 됩니다. 즉, 44.52%인 것입니다. 그러므로 이 확률에 1000명을 곱하면 44.52% × 1000 ≈ 445명 정도가 됩니다. 그러므로 1000명의 신입생을 대상으로 시험을 본 결과 평균이 82점 표준편차 5점을 따르는 정규분포인 경우 82점부터 90점까지 받은 학생은 대략 445명이라는 것입니다. 지금까지 우리가 한 이것이 바로 z-test입니다.\nz-test를 정리해 보자면 우리가 가진 데이터가 정규분포곡선을 따를 때, 우리는 우리가 원하는 어떤 값을 이용해 확률을 구할 수 있는데, 굳이 적분할 필요는 없고 이를 표준 정규분포로 전환한 후에 표준 정규분포표를 사용하면 된다는 것입니다. 여기서 표준 정규분포를 이용하기 위해서 우리는 기존의 데이터의 값을 z값으로 변환해야 하는데, 이를 z-transformation이라고 하고 표준화라고 하기도 합니다.\n\n\n2.3.6 배운 것들을 연결해보자\n우리가 배운 것들을 처음부터 지금까지 연결해보겠습니다.\n\n통계적 사고방식이란 어떤 사건이 우연히 발생할 확률이 얼마일까 질문하는 것이다.\n여기서 말하는 어떤 사건이 우연히 발생할 확률이 바로 p값이다.\n만약 p값이 0.05보다 작다면 대립가설을 선택하고 (귀무가설을 기각하고) 유의하다고 하며, 이때 우리는 이 사건이 우연히 발생하지 않았으며 무엇인가 원인 (혹은 이유)가 있다고 판단한다.\n반면에, p값이 0.05보다 크다면 대립가설을 기각하고 (귀무가설을 선택하고) 이 사건은 우연히 발생했다고 판단한다.\n정규분포곡선과 같은 확률분포곡선의 아래쪽 면적이 우리가 찾는 p값 즉 확률값이다.\n그러므로 우리가 찾고자 하는 p값은 확률분포곡선 (여기서는 정규분포곡선)의 아래 면적을 적분으로 구해야한다.\n정규분포곡선을 적분하는 것은 미친짓이다.\n그러므로, 우리가 가진 정규분포를 표준 정규분포로 전환하기 위해 z값을 구한다.\n계산된 z값을 표준 정규분포표를 이용해 확률값을 찾아 사용한다.\n\n이해가 되시나요? 이 과정이 바로 z-test입니다. 사실 이러한 과정은 우리가 배울 t-test도 동일합니다. 약간의 변형이 있을 뿐입니다. 그러면 다시 t-test의 예제로 돌아가서 t-test의 목적을 살펴봅시다.\n\nA대학 남학생 평균키(178.5cm)와 B대학 남학생 평균키(179.9cm)가 우연히 같은 확률은 얼마나 될까?\nA대학과 B대학의 남학생 평균키 차이인 1.4cm가 우연히 발생했을 확률은 얼마나 될까?\n\n위에서 우리가 찾는 확률이 바로 p값이면서 우리는 이 p값을 확률분포곡선을 이용해 찾아낼 것입니다. 다만 우리는 여기서는 z-test가 아닌 t-test를 해야하므로 우리가 사용할 확률분포곡선은 정규분포곡선이 아닌 t-분포곡선을 사용할 것입니다. 여러 종류의 확률분포곡선이 존재하지만 이것들에 대해 지금 더 알아가는 것은 그다지 도움이 되지 않고 통계공부의 어려움만 증가할 뿐이라서 차근차근 알아가 보겠습니다. 이제 여러분은 통계적인 분석의 문을 열고 방금 그것을 시작했습니다. 축하합니다! 스스로를 칭찬해 줍시다!!\nYouTube 바로 가기"
  },
  {
    "objectID": "chapter2.html#단순하지만-헷갈릴-수도",
    "href": "chapter2.html#단순하지만-헷갈릴-수도",
    "title": "2  첫 도전 t-test",
    "section": "2.4 단순하지만 헷갈릴 수도",
    "text": "2.4 단순하지만 헷갈릴 수도\n\n2.4.1 t-test를 바로 시작하지 못하는 두번째 이유\n우리는 t-test를 하기에 앞서 z-test를 배웠습니다. 이제 바로 t-test를 해도 될 것 같은데 여기서 한 가지 짚고 넘어가야 하는 문제가 있습니다. 바로 양측검정과 단측검정입니다. 사실 매우 어려운 개념은 아닙니다만 가끔 결정적인 순간에 헷갈리는 것입니다. 통계적 가설에 대한 이야기인데 다시 통계적 가설로 돌아가 봅시다. 우리가 지금 수행할 t-test의 예제를 다시 확인해 보면 Figure 2.4 와 같습니다.\n우리는 A대학과 B대학의 남학생들의 평균키가 같은지 다른지 알고 싶습니다. 앞서 통계학자들은 가설을 먼저 세우고 이를 검증해나가는 방식의 과학적 연구방법을 만들었다고 했습니다. 이를 위해 우리는 통계적 가설로서 귀무가설과 대립가설을 만들어야 합니다. 물론 말로 만들 수도 있습니다.\n\n귀무가설: A대학과 B대학 남학생의 평균키는 같다\n대립가설: A대학과 B대학 남학생의 평균키는 다르다\n\n위와 같이 만들 수 있겠죠. 그런데 같은 내용을 약간 다른 말로 만들어 볼 수도 있습니다.\n\n귀무가설: A대학과 B대학 남학생의 평균키의 차이는 0이다\n대립가설: A대학과 B대학 남학생의 평균키의 차이는 0이 아니다\n\n이렇게 크게 두 가지로 귀무가설과 대립가설을 만들어 볼 수 있습니다. 그러나 통계학자들은 이러한 가설을 말로 쓰는 것을 별로 좋아하지 않았습니다. 그래서 이러한 통계적 가설을 기호로 표기하였습니다. 첫번째의 경우는 아래와 같이 표현될 수 있습니다.\n\n\\(H_0: \\bar{x}_a = \\bar{x}_b\\)\n\\(H_a: \\bar{x}_a \\ne \\bar{x}_b\\)\n\n그런데 여기서 우리는 대립가설에 주목할 필요가 있습니다. 첫번째의 \\(\\bar{x}_a\\)는 A대학 남학생의 평균키를 \\(\\bar{x}_b\\)는 B대학 남학생의 평균키를 의미합니다. 여기서 \\(\\mu\\)를 사용하지 않는 이유는 우리가 사용한 데이터는 샘플 데이터이기 때문입니다. 대립가설은 두 대학 남학생의 평균키가 다르다라고만 되어 있습니다. 이 “다르다”라는 말은 다분히 논리적인 의미로서 무엇이 어떻게 다르다는 것인지에 대해서는 아무런 세부사항을 이야기 하고 있지 않습니다. 그렇다면, 저 두 개의 평균값이 다를 수 있는 경우는 몇 가지가 있을까요? 아마도 두 가지 일 것입니다.\n\\[\\bar{x}_a \\ne \\bar{x}_b \\Rightarrow \\bar{x}_a &gt; \\bar{x}_b \\; \\text{or} \\; \\bar{x}_a &lt; \\bar{x}_b\\]\n이렇게 말입니다.\n즉, “다르다”는 A대학 남학생 평균키가 B대학 남학생 평균키 보다 크거나 작은 두 가지의 경우를 모두 포함합니다. 이렇게 되면 앞에서 쓴 통계적 가설을 다른 표현이지만 같은 의미로 이렇게도 사용할 수도 있습니다.\n\n\\(H_0: \\bar{x}_a = \\bar{x}_b\\)\n\\(H_a: \\bar{x}_a &gt; \\bar{x}_b \\; \\text{or} \\; \\bar{x}_a &lt; \\bar{x}_b\\)\n\n이렇게 되면 귀무가설은 동일하고 대립가설만 바꾼것이지만 앞의 것과 의미는 동일합니다. 이 두가지는 말로 표현하자면 A대학과 B대학 남학생의 평균키는 같다 혹은 다르다를 귀무가설과 대립가설로 쓴 것입니다. 만약 A대학과 B대학 남학생의 평균키의 차이는 0이다 혹은 아니다를 통계적 가설로 쓴다면 이렇게도 바꿔 쓸 수 있습니다.\n\n\\(H_0: D_{a-b} = 0\\)\n\\(H_a: D_{a-b} \\ne 0\\)\n\n당연한 이야기이지만 이는 또 이렇게도 바꿔 쓸 수 있습니다.\n\n\\(H_0: D_{a-b} = 0\\)\n\\(H_a: D_{a-b} &gt; 0 \\; \\text{or} \\; D_{a-b} &lt; 0\\)\n\n그러면 총 4개의 통계적 가설이 사실 내용을 같은 내용이라는 것이 됩니다. 이처럼 대립가설에서 단순히 같지 않다 혹은 다르다 라고 표현되는 경우를 우리는 양측검정이라고 합니다. 왜냐하면 단순히 다르다 라고만 하면 이는 클 수도 있고 작을 수도 있다는 의미가 되기 때문입니다. 즉 우리는 양측검정의 경우 클 수도 있는 경우와 작을 수도 있는 경우 두 가지를 모두 동시에 생각해서 p값을 구해야 한다는 의미가 됩니다.\n반면에 단측검정이란 대립가설에서 한 방향으로 명확하게 그 방향성이 정해진 경우를 의미합니다. 예를 들어보면 이렇습니다.\n\n\\(H_0: \\bar{x}_a = \\bar{x}_b\\)\n\\(H_a: \\bar{x}_a &gt; \\bar{x}_b\\)\n\n이 경우에는 A대학 남학생의 평균키가 B대학 남학생의 평균키보다 크다는 방향성을 정확하게 제시하고 있습니다. 이러한 경우를 단측검정이라고 합니다. 또한 이를 앞에서 살펴본 것처럼 다르게 표현할 수도 있습니다.\n\n\\(H_0: D_{a-b} = 0\\)\n\\(H_a: D_{a-b} &gt; 0\\)\n\n이렇게 말입니다. 그렇다면 당연히 B대학의 남학생 평균키가 A대학의 남학생 평균키 보다 크다는 통계적 가설도 만들 수 있을 것입니다.\n\n\\(H_0: \\bar{x}_a = \\bar{x}_b\\)\n\\(H_a: \\bar{x}_a &lt; \\bar{x}_b\\)\n\n이를 다른 방식으로 표현하면 이렇게도 할 수 있습니다.\n\n\\(H_0: D_{a-b} = 0\\)\n\\(H_a: D_{a-b} &lt; 0\\)\n\n이런 경우를 모두 단측검정이라고 합니다. 즉 크거나 작은 경우 중에 한 가지만을 대상으로 p값을 구하는 경우입니다. 그렇다면 양측검정과 단측검정을 그림과 함께 알아보겠습니다.\n\n\n2.4.2 확률분포곡선으로 보는 양측검정과 단측검정\n이제 우리는 아래의 통계적 가설이 모두 같은 의미라는 것을 알고 있습니다. 한 번 보시길 바랍니다.\n\n귀무가설: A대학과 B대학 남학생의 평균키는 같다\n대립가설: A대학과 B대학 남학생의 평균키는 다르다\n\\(H_0: \\bar{x}_a = \\bar{x}_b\\)\n\\(H_a: \\bar{x}_a \\ne \\bar{x}_b\\)\n\\(H_0: \\bar{x}_a = \\bar{x}_b\\)\n\\(H_a: \\bar{x}_a &gt; \\bar{x}_b \\; \\text{or} \\; \\bar{x}_a &lt; \\bar{x}_b\\)\n귀무가설: A대학과 B대학 남학생의 평균키의 차이는 0이다\n대립가설: A대학과 B대학 남학생의 평균키의 차이는 0이 아니다\n\\(H_0: D_{a-b} = 0\\)\n\\(H_a: D_{a-b} \\ne 0\\)\n\\(H_0: D_{a-b} = 0\\)\n\\(H_a: D_{a-b} &gt; 0 \\; \\text{or} \\; D_{a-b} &lt; 0\\)\n\n이러한 양측검정의 통계적 가설을 확률분포곡선과 연결해서 보면 이렇습니다.\n\n\n\nFigure 2.13: 양측검정의 예\n\n\n우리는 두 대학중 어느 한 대학이 클 수도 혹은 작을 수도 있는 두 가지의 가능성을 모두 생각해 둬야 합니다. Figure 2.13 에서는 편의상 표준 정규분포를 이용하여 보여드립니다. 실제 t-test를 할 때는 t분포를 이용해야 합니다. 그러나 여기서는 양측검정의 이해를 돕기위한 것이므로 표준 정규분포로 이해해 봅시다. 우리가 관심 있는 p값은 여전히 5% (0.05)입니다. 그러므로 양쪽에 이 5%을 분배하여 2.5%씩 붉은색으로 칠 했습니다. 위의 분포곡선에서 아래의 \\(x\\)축은 우리가 계산한 어떤 z-값을 의미 합니다. 앞에서 90점이라는 영어점수를 1.6으로 표준화했을 때의 1.6과 같은 값을 의미합니다. 그러므로 만약 붉은 면적 아랫부분의 z값이 1.6이라면 우리는 5%의 확률을 얻은 것입니다. 그러나 실제로 표준정규분포에서 양측검정으로 5%가 되려면 그때의 z값은 1.96이 되어야 합니다. 이를 Figure 2.14 로 확인해보면 보다 쉽게 이해할 수 있습니다. 그림에서 보듯, 양측검정에서 p값 5%를 맞추기 위해서는 -1.96과 1.96이 되어야 합니다. 즉, z값이 1.96이거나 혹은 -1.96이면 정확히 5%가 됩니다. 이러한 값을 우리는 c.v. (critical value)라고 합니다. 즉, 우리가 z-test를 할 때 항상 z값이 1.96보다 크거나 -1.96보다 작다면 우리는 양측검정에서 5%보다 작은 p값을 가지게 되어 대립가설을 채택하게 됩니다. 그림에서처럼 만약 우리의 z값이 1.6이거나 혹은 -1.6이라면 어떻게 될까요? 그림을 잘 보면 z값이 1.6이거나 -1.6일 경우 각 값에서 선을 위로 그어 표준 정규분포에 맞닿도록 하면 그림의 붉은 면적보다 더 넓은 면적이 양쪽으로 나나타게 됩니다.\n\n\n\nFigure 2.14: 양측검정의 critical value\n\n\n이렇게 되면 면적이 5%보다 넓어지게 되므로 당연히 p값은 5%보다 커지게 되어 귀무가설을 채택하게 됩니다. 즉 이 사건은 우연히 발생한 것이 됩니다. 즉 우리는 양측검정에서 표준 정규분포를 이용할 경우 우리가 구하는 z값이 1.96보다 크거나 -1.96보다 작을 것을 기대해야 5%보다 작은 p값을 얻을 수 있는 것입니다.\n이제 단측검정을 살펴봅시다. 앞의 양측검정은 둘 중 어느 대학의 남학생의 평균키가 크더라도 관계가 없습니다. 우리는 단지 다를 것을 기대했을 뿐입니다. 그러나 단측에서는 방향성을 명확하게 가설에 포함시키게 됩니다. 다음의 네 가지 경우는 같은 의미입니다. 어떤 책에서는 이를 우측검정이라고 부르기도 합니다.\n\n귀무가설: A대학과 B대학 남학생의 평균키는 같다\n대립가설: A대학 남학생의 평균키는 B대학 남학생의 평균키보다 크다\n귀무가설: A대학과 B대학 남학생의 평균키의 차이는 0이다\n대립가설: A대학과 B대학 남학생의 평균키의 차이는 0 보다 크다\n\\(H_0: \\bar{x}_a = \\bar{x}_b\\)\n\\(H_a: \\bar{x}_a &gt; \\bar{x}_b\\)\n\\(H_0: D_{a-b} = 0\\)\n\\(H_a: D_{a-b} &gt; 0\\)\n\n그리고 당연히 반대 방향의 다른 종류의 단측검정이 하나 더 있습니다. 아래의 네가지 통계적 가설은 모두 같은 의미입니다. 어떤 책에서는 아래의 경우를 좌측검정이라고도 부릅니다.\n\n귀무가설: A대학과 B대학 남학생의 평균키는 같다\n대립가설: A대학 남학생의 평균키는 B대학 남학생의 평균키보다 작다\n귀무가설: A대학과 B대학 남학생의 평균키의 차이는 0이다\n대립가설: A대학과 B대학 남학생의 평균키의 차이는 0 보다 작다\n\\(H_0: \\bar{x}_a = \\bar{x}_b\\)\n\\(H_a: \\bar{x}_a &lt; \\bar{x}_b\\)\n\\(H_0: D_{a-b} = 0\\)\n\\(H_a: D_{a-b} &lt; 0\\)\n\n그럼 이제 단측검정을 그림으로 알아봅시다. &lt;그림 1-16&gt;은 단측검정 중에서도 우측검정을 보여주고 있습니다. 예상하듯이 우리가 원하는 p값 5%를 우측으로 몰았습니다. 이때의 c.v. 는 표준 정규분포의 경우 1.64정도가 됩니다. 즉, 우리가 구한 z값이 1.64보다 크다면 이는 p값이 5% 보다 작아 유의하게 되는 것입니다. &lt;그림 1-17&gt;은 단측검정의 좌측검정을 보여줍니다. 그림을 사실 좌우로 대칭시킨 정도의 차이만 있을 뿐이며 이 경우의 c.v. 역시 마이너스만 붙인 -1.64가 됩니다. 즉, 우리가 구한 z값이 -1.64보다 작으면 p값은 5%보다 작아지는 것입니다.\n\n\n\nFigure 2.15: 단측검정에서 우측검정\n\n\n\n\n\nFigure 2.16: 단측검정에서 좌측검정\n\n\n그런데, 여기까지 보고나니 좀 헷갈리는 것이 있습니다. 일단, 양측검정과 단측검정의 차이는 대립가설의 차이라는 것은 확실히 알겠습니다. 왜냐하면 귀무가설은 항상 똑같기 때문입니다. 그렇다면 이 대립가설의 차이는 언제 누가 어떻게 정해야 할까요? 사실 여러분들이 단순히 시험을 보기 위해서라면 아마도 시험문제에서 단측인지 양측인지 이야기해줄 것입니다. 그러나 가끔 문제 안에 이 내용을 살짝 넣어 버리는 경우가 있습니다. 더 정확하게는 여러분들이 연구할 때는 어떻게 해야 할까요? 여기서 여러분들이 헷갈리면 안되는 것이 하나 있습니다. 통계가 만능이 아니라는 점입니다. 통계는 어디까지나 여러분들이 수행하고 있는 과학적 연구에 있어서 검증방법의 하나로 사용되고 있다는 점입니다.\n기본적으로 대립가설은 이미 연구자가 기존의 이론과 연구들을 모두 섭렵하고 난 후에 논리적인 기반을 탄탄하게 갖추고서 대립가설을 결정하는 것입니다. 그러므로 여러분들이 하고 있는 연구의 대립가설이 방향성이 있는지 없는지를 살펴보아야 합니다. 방향성이 없다면 즉 클 수도 있고 작을 수도 있다면 양측검정이 적용되어야 하고, 방향성이 분명하다면 즉 어떤 이유나 논리로 인해 크거나 작다는 한 쪽을 명확히 할 수 있다면 단측검정이 되는 것입니다. 그러므로 양측이냐 단측이냐는 통계 자체가 해결해 주는 것이 아니라 여러분들이 연구할 때 연구자가 얼마나 충분히 이론/기존연구/논리를 고려했느냐에 달려있는 것입니다. 추가적으로 통계적 가설의 대립가설을 말로 풀어쓴 것이 논문에 사용되는 연구가설이라는 점을 참고 하시기 바랍니다.\n두번째로 헷갈리는 것은 단측검정에서 우측검정과 좌측검정 중에서 무엇을 써야 하느냐 입니다. 사실 이 문제는 약간의 트릭이 있습니다. 우리가 사용하는 확률분포가 좌우대칭이라면 사실 고민할 것이 없습니다. 왜냐하면 접으면 똑같기 때문입니다. 앞에서 우리는 A대학 남학생의 평균키를 178.5cm, B대학 남학생의 평균키를 179.9cm로 했습니다. 두 평균값의 차이를 구할 때, A에서 B를 빼면 -1.4cm가 되고, B에서 A를 빼면 1.4cm가 됩니다. 그러므로 차이가 양수라면 우리는 자연스럽게 우측검정을 하면 되고, 차이가 음수라면 우리는 자연스럽게 좌측검정을 하면 됩니다. 두 가지 방법의 결론은 어차피 같기 때문에 우리는 크게 걱정할 것이 없습니다. 마치 데칼코마니처럼 둘은 접으면 동일한 분포곡선이기 때문입니다. 물론 만약에 우리가 사용할 확률분포가 좌우대칭이 아니라면 이야기는 좀 달라질 수 있지만 일단 여기까지 이해하는 것이 중요합니다. 이제야 본격적인 t-test를 공부할 준비가 끝났습니다. 사실 여기까지만 잘 이해하셨다면 t-test는 우리가 이미 아는 내용의 응용에 불과하기 때문에 의외로 쉽게 이해될 것입니다. 달려봅시다!!\nYouTube 바로 가기"
  },
  {
    "objectID": "chapter2.html#이제야-t-test를-하다니",
    "href": "chapter2.html#이제야-t-test를-하다니",
    "title": "2  첫 도전 t-test",
    "section": "2.5 이제야 t-test를 하다니",
    "text": "2.5 이제야 t-test를 하다니\n\n2.5.1 t-test로 돌아가자\n이제서야 우리는 t-test를 할 수 있게 되었습니다.\n혹시 잊어버렸을지 모르니 다시 앞에서 한 것들을 복습해 봅시다. 기본적으로 t-test의 목적은 두 그룹이 같은지 다른지 알아보기 위해 실시하는 통계적 검정방법입니다. 여기서 두 그룹이란 샘플을 의미합니다. 만약 이 두 그룹이 모집단이라면 우리는 z-test를 할 것입니다. 그리고 두 샘플이 같은지 다른지 알고 싶어서 대표값인 평균값이 같은지 다른지 확인할 것입니다. 문제는 두 샘플의 평균값을 알고 이 차이를 알아도 이 차이가 얼마나 커야 통계적으로 큰 것인지 혹은 얼마나 작아야 통계적으로 작은 것인지 알 길이 없습니다. 그래서 우리는 이 차이가 큰지 혹은 작은지 판단하기 위해 참고가 될만한 다른 대표값을 가져와서 비교하기로 했습니다. 그것은 바로 표준편차입니다. 표준편차는 평균을 중심으로 데이터가 평균적으로 퍼져있는 정도입니다. 이 편차는 의미 없는 편차이며 단지 무작위적(random)으로 퍼져 있는 것입니다. 그러므로 우리가 계산한 평균값의 차이가 표준편차보다 충분히 크다면 우리는 이 평균값의 차이가 우연이 아니라고 판단할 것이지만, 반대로 평균값의 차이가 표준편차보다 작거나 비슷하다면 이 평균값의 차이는 우연이라고 판단할 것입니다. 우리가 풀려고 했던 예제는 다음의 그림입니다(Figure 2.4).우리는 두 대학의 남학생의 평균키가 달라야 할 만한 특별한 이유를 알지 못하고 그 방향성 또한 모르기 때문에 양측검정으로 이 분석을 진행할 것입니다.\n\n귀무가설: A대학과 B대학 남학생의 평균키는 같다\n대립가설: A대학과 B대학 남학생의 평균키는 다르다\n\\(H_0: \\bar{x}_a = \\bar{x}_b\\)\n\\(H_a: \\bar{x}_a \\ne \\bar{x}_b\\)\n\\(H_0: \\bar{x}_a = \\bar{x}_b\\)\n\\(H_a: \\bar{x}_a &gt; \\bar{x}_b \\; \\text{or} \\; \\bar{x}_a &lt; \\bar{x}_b\\)\n귀무가설: A대학과 B대학 남학생의 평균키의 차이는 0이다\n대립가설: A대학과 B대학 남학생의 평균키의 차이는 0이 아니다\n\\(H_0: D_{a-b} = 0\\)\n\\(H_a: D_{a-b} \\ne 0\\)\n\\(H_0: D_{a-b} = 0\\)\n\\(H_a: D_{a-b} &gt; 0 \\; \\text{or} \\; D_{a-b} &lt; 0\\)\n\n이것이 바로 우리의 통계적 가설입니다. 그럼 이제 무엇이 필요할까요? 기본적으로는 앞에서 했던 z-test의 과정과 비슷합니다. z-test를 할 때 우리는 먼저 z값을 구했고 이를 표준정규분포를 이용하여 진행했습니다. 그러므로 우리가 t-test를 진행하기 위해서는 t-test에 맞는 값과 분포가 필요할 것입니다. 이 것이 바로 t값과 t분포입니다. 그냥 이름 앞에 t만 넣으면 되는 방식입니다. 그렇다면 t값 (t-value)의 공식을 z값 (z-value)의 공식과 함께 비교해 보도록 합니다.\n\\[\\text{z-value}=\\frac{x-\\mu}{\\sigma}\\] \\[\\text{t-value}=\\frac{\\bar{x}_a-\\bar{x}_b}{\\frac{s}{\\sqrt{n}}}\\]\n잘 보면, 두 공식은 매우 닮아 있습니다. 분자부분은 우리가 관심이 있는 두 값의 차이이면서 평균에 대한 것입니다. 분모부분은 약간 차이는 나지만 표준편차를 공통적으로 포함하고 있습니다. t값의 분모에 있는 \\(s\\)는 샘플의 표준편차입니다. 혹시라도 까먹으신 분들은 없을 것이라고 생각됩니다. 또한 t값의 분모에 있는 \\(n\\)은 샘플 사이즈입니다. 그럼 t값 공식을 자세히 분해해 봅시다. t-test에서 우리의 핵심 관심사는 두 그룹의 평균값의 차이입니다. 두 샘플의 평균값의 차이가 분명히 분자에 있습니다. 그러나 우리가 앞서 이야기 했듯이 이것 만으로는 도통 이 값이 큰지 작은지 알 수 없습니다. 그래서 우리는 표준편차 \\(s\\)를 가져와서 나누어 비율로 만듭니다. 물론 표준편차 s를 \\(\\sqrt{n}\\)으로 나누기는 합니다만 이 부분은 뒤에서 다시 살펴보겠습니다. 다시 한번 이 t값 공식에 대해 정리하겠습니다.\n\n두 그룹의 평균값의 차이는 우리의 핵심 관심사이다\n두 그룹의 평균값의 차이를 분자에 둔다\n그러나 이 값만으로는 충분히 큰지 작은지 알 수 없다\n그래서 비교대상인 표준편차를 가져와 분모에 넣고 나누어 비율을 만든다\n표준편차는 의미 없는 무작위의(random) 편차이다\n그러므로, 평균값의 차이가 표준편차보다 작거나 비슷하다면 이 평균값의 차이는 우연히 발생했다고 판단한다\n반대로 평균값의 차이가 표준편차보다 충분히 크다면 이 평균값의 차이는 우연히 발생하지 않았다고 보고 무엇인가 원인 혹은 이유가 있다고 추정한다\n\n이 프로세스가 바로 t-test입니다. 모든 통계책은 t값을 구하는 공식을 외우라고만 합니다. 자세한 설명은 없고 계속 문제만 풀게합니다. 그래서 학생들은 이 공식이 의미하는 바를 이해 못하고 외우다가 문제를 풀고 시험이 끝나면 바로 잊어버립니다. 이제는 억지로 외우지 마시길 바랍니다. 공식이 왜 이렇게 생겼는지 이해했으니 암기는 미뤄두셔도 괜찮습니다.\n\n\n2.5.2 왜 표준편차를 샘플 사이즈로 나누나?\n앞에서 t값을 구하는 공식에 표준편차 s를 \\(\\sqrt{n}\\)으로 나눠주는 부분이 있었습니다. 왜 그럴까요? 일단 우리는 한 가지 알아 둬야 할 것이 있습니다. 우리가 사용한 데이터는 모집단이 아닌 샘플이라는 사실입니다. 조금 철학적인 접근을 해보겠습니다. 우리는 어떤 데이터이든 사실 모집단 데이터를 이용해 분석하고 싶은 욕망이 있습니다. 왜냐하면 이렇게 모집단 데이터로 분석을 하는 것이 가장 정확할 것이기 때문입니다. 그러나 앞서 이야기 했듯이 모집단의 데이터를 모으는 것은 엄청난 시간과 노력을 요구합니다. 그래서 우리는 모집단의 부분이면서 모집단의 특성을 잘 나타낼 수 있는 샘플을 만들어서 샘플 데이터를 분석합니다. 그런데 여기서 우리는 가장 기본적이면서 중요한 대표값인 평균과 표준편차에 대해 의문을 갖게 됩니다. 샘플의 평균과 표준편차와 모집단의 평균과 표준편차는 과연 잘 맞을까? 일치할까? 라는 것입니다. 이러한 의문은 역사적으로도 있었습니다.\n1920년대 미국에 대공황이 시작되자 당시의 경제학자들과 정치인들은 매우 당황했습니다. 당시에는 이제 막 경제지표에 통계적 방법이 사용되기 시작한 시기였습니다. 당시의 통계학자들은 미국의 실업률이 20%이상으로 심각한 수준이라는 경고를 했습니다. 문제는 이에 대해 당시의 대부분의 경제학자들이 이 수치를 믿을 수 없다면서 오히려 이는 대공황이 아닌 경제흐름상 사이클의 일부이며 곧 모든 것이 회복될 것이라고 주장했습니다. 그러면서 미국 전체를 대상으로 전수조사를 한 실업률이 아니고서는 믿을 수 없다고 주장하기에 이릅니다. 당연합니다. 우리는 모집단 데이터에서 평균과 표준편차의 참값을 알고 싶지만, 시간과 재정의 한계로 샘플 데이터에서 계산된 평균과 표준편차의 추정된 참값으로 분석을 진행합니다. 고민은 이 추정된 참값이 진짜 참값에 얼마나 가까운가 하는 것입니다. 그래서 이러한 고민들이 반영되어 지금 우리가 사용하는 샘플에 기반한 통계적 분석이 만들어진 것입니다.\n다시 위에서 이야기한 표준편차 \\(s\\)를 \\(\\sqrt{n}\\)으로 나눠주는 부분으로 돌아가 보겠습니다. 기본적으로는 그렇습니다. 우리의 표준편차 \\(s\\)는 샘플의 표준편차입니다. 또한 우리의 샘플은 모집단의 일부이고 그래서 샘플 사이즈 (\\(n\\))은 다양할 수 있습니다. 샘플 사이즈가 n=100 일수도 있고, n=1,000,000일수도 있습니다. 학자들이 살펴보니 샘플 사이즈에 따라서 표준편차가 크게 영향을 받는 것을 발견하였습니다. 실제로 샘플 사이즈가 커질 수록 샘플의 표준편차는 점점 작아집니다. 이는 단순히 작아지는 것이 아니고 사실은 모집단의 표준편차인 \\(\\sigma\\)에 가깝게 접근하는 것입니다. 그래서 위의 t값을 계산하는 공식에서 단순히 표준편차 \\(s\\)가 아닌 여기에 샘플 사이즈를 감안해 보다 정확한 수치로 보정해주는 것입니다. 사실 이러한 설명은 정통 통계학적으로 맞다고 하기 어렵지만 우리 수준에서는 일단 이정도로 알고 지나가면 되겠습니다.\n\n\n2.5.3 자유도 (degree of freedom)\n사실 앞에서 보았던 t값의 공식은 거기서 끝이 아닙니다. 한가지 더 있습니다. 공식이 하나 더 있다기 보다는 공식에 관련된 개념이 하나 새로 등장합니다. 그것이 바로 자유도, 영어로는 degree of freedom입니다. 참으로 난감하지 않을 수가 없습니다. 이름이 자유도라니 이 무슨 난리일까요?\n\\[\\text{t-value}=\\frac{\\bar{x}_a-\\bar{x}_b}{\\frac{s}{\\sqrt{n}}} \\quad \\quad \\quad _{(df=n-1)}\\]\nt값 공식 뒤에 \\(df = n-1\\) 이라는 것이 있습니다. 여기서 df가 바로 degree of freedom의 약자인 자유도입니다. 일단 이 \\(df = n -1\\) 이라는 공식에 집중해 보겠습니다. 자유도는 샘플 사이즈에서 1을 뺀 것이라는 의미입니다. 그러므로 샘플 사이즈가 커지면 자유도가 커지고, 샘플 사이즈가 작아지면 자유도가 작아진다는 의미가 됩니다. 이를 좀 다르게 해석해보면, 샘플 사이즈가 커지면 더 자유로워지고, 샘플 사이즈가 작아지면 덜 자유로워진다고 할 수 있습니다. 과연 더 자유로운 것은 무엇이고 덜 자유로운 것은 무엇일까요? 통계에서 자유롭다는 것은 앞에서 본 정규분포를 따르는 경우를 의미합니다. 왜냐하면 정규분포를 따르면 이미 많은 것이 계산되어 있어서 우리가 그다지 힘들여 무엇인가를 할 필요가 없기 때문입니다.\n이러한 패턴을 Figure 2.17 을 통해서도 알 수 있습니다. 여기서 노란색의 분포곡선은 자유도가 1일 때의 t분포곡선입니다. 자유도가 1이라면 샘플 사이즈는 2개일 것입니다. 여기서 샘플 사이즈를 늘려 자유도가 3인 붉은색의 t분포곡선이 그 위쪽에 존재하고 전보다 좀 더 뾰족해지고 좌우로 퍼져있는 편차가 줄어들어 보입니다. 여기서 샘플 사이즈를 더 늘려서 자유도가 30인 t분포곡선을 초록색으로 그리면 이 t분포곡선이 파란색의 표준정규분포와 거의 비슷해 지는 것을 볼 수 있습니다. 그러므로 샘플사이즈가 커져서 자유도가 증가하면 할수록 t분포곡선은 표준 정규분포곡선을 향해 움직이게 된다는 의미입니다. 이는 어쩌면 당연한 것인데, 우리가 샘플 사이즈를 계속 늘리다보면 언젠가는 모집단에 이르게 될 것이기 때문입니다. 그러므로 샘플 사이즈가 커질 수록 우리가 가진 t분포곡선은 표준 정규분포곡선처럼 되는 것입니다. 다시 강조하자면 샘플 사이즈가 커진다는 것은 자유도가 커져 보다 자유롭다는 것인데 이는 우리의 t분포곡선이 표준 정규분포곡선에 접근할수록 우리의 통계가 보다 자유로워진다는 의미로 사용된다고 보시면 됩니다.\n\n\n\nFigure 2.17: 정규분포와 t분포의 관계\n\n\n\n\n2.5.4 본격적인 t-test를 해보자\n여태까지 공부한 것을 모두 정리해서 t-test를 진행해 보겠습니다. 잊지말고 Figure 2.4 의 그림을 떠 올리며 다시 정리해 봅시다.\n\\[\\text{t-value}=\\frac{\\bar{x}_a-\\bar{x}_b}{\\frac{s}{\\sqrt{n}}} \\quad \\quad \\quad _{(df=n-1)}\\]\nA대학 남학생의 평균키는 178.5cm, B대학 남학생의 평균키는 179.9cm였으며 우리는 이제 이를 바탕으로 t값을 구하고자 합니다. 이제 우리에게 필요한 정보는 \\(s\\)와 \\(n\\)입니다. 여기서 표준편차 \\(s\\)를 7.05cm 라고 하고, 샘플 사이즈 \\(n\\)이 101명이었다고 가정하겠습니다. 다시 한 번 말씀드리지만 어디서 어떻게 이런 표준편차와 샘플 사이즈가 계산되었냐는 여기서는 중요하지 않습니다. 왜냐하면 지금 우리는 t-test의 기초를 이해하는 과정이기 때문에 세부적인 계산방법은 추후에 다루겠습니다. 솔직히, 시험을 제외하고는 이런 계산을 직접할 일이 없기 때문에 저는 공식에 집착하는 것이 매우 불필요하고 무용하다고 생각합니다. 미국에서도 시험때는 한 장의 종이에 필요한 공식을 써서 시험장에 가지고 들어갈 수 있었습니다. 그러니 굳이 쓸데없이 공식을 암기하는데 시간을 낭비할 필요가 없었습니다. 그럼 계산해 보겠습니다.\n\\[\\text{t-value}=\\frac{\\bar{x}_a-\\bar{x}_b}{\\frac{s}{\\sqrt{n}}}=\\frac{_{178.5-179.9}}{\\frac{7.05}{101}} \\approx -1.996\\]\n이 계산을 통해 구한 t값은 -1.996입니다. 우리는 앞에서 이야기 했듯이 양측검정을 할 것이라서 t값이 1.996보다 큰 부분의 면적과 t값이 -1.996보다 작은 면적 양쪽의 면적의 합을 p값으로 사용할 것입니다. 이게 무슨 뜻인지 잘 이해가 되지 않으신다면 분자의 빼는 순서를 바꾸면 이해가 되실 것입니다.\n\\[\\text{t-value}=\\frac{\\bar{x}_a-\\bar{x}_b}{\\frac{s}{\\sqrt{n}}}=\\frac{_{179.9-178.5}}{\\frac{7.05}{101}} \\approx 1.996\\]\n그렇다면 이제 이 면적을 어떻게 구해야 할까요? 물론 적분을 하면 됩니다만 우리는 앞에서 적분을 하지 않고도 p값을 구하는 방법을 z-test에서 배웠습니다. 앞에서는 z값을 구한다음 z-table (표준 정규분포표)를 이용해 적분 없이 p값을 구했습니다. 그렇다면 t-test에 t값이 있었다면 당연히 t-table이 있어야 하지 않을까요? 맞습니다. 우리는 t-table을 이용할 것입니다. 이 또한 통계학자들이 친절하게도 미리 만들어서 우리의 모든 통계 교과서 뒤쪽에 부록으로 넣어두었습니다. 필요하다면 인터넷에서 검색해도 됩니다.\n\n\n\nFigure 2.18: t-table\n\n\nFigure 2.18 은 t-table을 짧게 축약한 것입니다. 가장 상단의 첫번째 행을 자세히 보면 첫번째 줄에 cum. prob라고 되어 있습니다. 이는 cumulative probability의 약자로 누적확률이라고 보시면 됩니다. 이 누적확률 우측으로는 t.50 t.75 t.95 t.975 등이 있습니다. 이는 t분포에서 단측검정 기준으로 \\(1-\\alpha\\)의 값을 의미합니다. 즉, t.975 는 t분포의 좌측 끝에서부터 우측의 어느 t값까지의 총 면적이 97.5%가 되는 t값을 의미합니다. 어렵죠? 여기서 α는 앞에서 살펴보았던 1종오류의 그 \\(\\alpha\\)입니다. 우리는 유의수준 \\(\\alpha\\)라고도 부릅니다. 즉 우리가 항상 말하는 5% (0.05)가 바로 이 \\(\\alpha\\)입니다. 이 부분이 좀 복잡하다면 보다 쉽게 보기 위해 cum. prob 아래에 one-tail과 two-tails가 있습니다. 여기서 one-tail은 단측검정을, two-tails는 양측검정을 의미합니다. 그리고 우측에는 우리가 원하는 \\(\\alpha\\) 값을 적어 놓았습니다. 우리는 앞서 양측검정을 하기로 했습니다. 그리고 당연히 우리의 유의수준 \\(\\alpha\\)는 0.05입니다. 이 값에 맞는 열을 찾으면 됩니다. 그리고나서 좌측의 첫번째 열을 보면 one-tail과 two-tails 아래에 df가 있습니다. 자유도 입니다. 우리의 샘플 사이즈는 101이므로 자유도 \\(df = 101- 1 = 100\\)이 됩니다. 그러면 여기에 해당하는 행을 찾아서 맞춰보면 됩니다.\n\n\n\nFigure 2.19: t-table에서 c.v. 찾는 법\n\n\nt-table에서 이 방법으로 값을 찾아보면 1.984라는 값이 나옵니다. 이 값은 앞에서 설명한 c.v. (critical value)로서 이 값은 일종의 임계치로 이 값보다 커야만 p값이 \\(\\alpha\\) 보다 작아진다는 의미가 됩니다. 여기서는 t값의 c.v.가 1.984이고 \\(\\alpha\\)는 0.05였으며, 우리가 구한 t값은 1.996이었기 때문에 우리의 t값이 c.v.보다 크므로 우리의 p값은 5%보다 작아지므로 우리는 귀무가설을 기각하고 대립가설을 채택하게 되어, 두 대학의 남학생의 평균키의 차이 1.4cm는 우연히 발생한 것이 아니라는 결론을 내리게 됩니다.\n여러분들의 이해를 돕기위해 t분포곡선 상에서 어떻게 되는 것인지 보겠습니다. Figure 2.20 을 보면 양쪽의 붉은 면적이 바로 유의수준 \\(\\alpha\\) 입니다. \\(\\alpha\\)는 5% (0.05)이지만 우리는 양측검정을 하기로 했으므로 이를 둘로 나누어 각 2.5%씩 두개의 붉은 면적이 5%의 확률이 됩니다. 이때 이 면적이 x축과 닿는 지점이 바로 c.v.가 되는데 이때의 t값은 1.984라는 것입니다. 즉, t값이 1.984가 되면 정확히 p값은 5% (0.05)가 된다는 의미입니다. 따라서 만약 우리의 t값이 1.984 보다 크다면 (혹은 -1.984 보다 작다면), 면적이 지금보다 더 작아질 것이므로 우리의 p값은 5%보다 작아집니다. 반면에 만약 t값이 1.984 보다 작다면 (혹은 -1.984 보다 크다면), 면적이 지금보다 더 커지게 되어 p값은 5%보다 커지게 됩니다.\n\n\n\nFigure 2.20: t분포에서 c.v.와 유의수준 \\(\\alpha\\)\n\n\n\n\n2.5.5 t-test의 해석과 결론\n사실 통계 프로그램을 사용하면 이러한 복잡한 계산을 직접할 일이 없습니다. 문제는 그러다 보니 많은 사람들이 사용하기 쉬운 통계 프로그램에 데이터만 넣고 무작정 돌린 후에 p값이 5% 보다 큰지 작은지만 확인하고 해석 또한 별도의 말 없이 “p값이 0.05보다 작으니 유의하다”라는 말로 끝내는 경우를 많이 봅니다. 솔직히 이는 통계분석을 하긴 했는데, 무슨 뜻인지는 모르겠으니 무작정 유의하다라고 하는 것입니다. 제가 가장 경계하는 것이 그냥 무작정 유의하다라는 말을 반복하는 것입니다. 유의하다면 이게 그래서 무슨 뜻인지 해석을 해야하는데, 그런 해석이 없는 것이지요. 정리해 보면 이렇습니다.\n\nA대학 남학생의 평균키는 178.5cm, B대학 남학생의 평균키는 179.9cm 이다.\n표준편차 s는 7.05cm 이고, 샘플 사이즈 n은 101명이다.\nt값의 공식을 이용해 구한 t값은 1.996이다.\nt-table에서 양측검정 (two-tails)의 유의수준 \\(\\alpha\\) = 0.05와 \\(df = 101 - 1 = 100\\)을 이용해 찾은 c.v.은 1.984이다.\n우리의 t값이 c.v. 보다 크므로 p값은 5% (0.05)보다 작아 유의하다.\n그러므로 우리는 귀무가설을 기각하고 대립가설을 채택하기로 한다.\n이는 두 대학의 평균키 차이 1.4cm가 우연히 발생하지 않았으며, 여기에는 무언가 이유 혹은 원인이 있다고 추정할 수 있다.\n\n여기서 중요한 것은 유의하다로 끝내서는 안된다는 것입니다. 유의하므로 이 결과를 이렇게 저렇게 보아야 한다고 해석해야 합니다. 이것이 우리가 통계를 이용해 분석하는 궁극적인 목적이기 때문입니다. 단순히 유의하다 아니다가 통계의 목적이 아니라는 점을 분명히 알고 있어야 합니다.\nYouTube 바로 가기"
  },
  {
    "objectID": "chapter2.html#t-test를-종류별로-알아보자",
    "href": "chapter2.html#t-test를-종류별로-알아보자",
    "title": "2  첫 도전 t-test",
    "section": "2.6 t-test를 종류별로 알아보자",
    "text": "2.6 t-test를 종류별로 알아보자\n\n2.6.1 t-test에도 종류가 있다\n사실 우리가 앞에서 t-test의 예제로 사용한 것은 정말 극단적으로 쉬운 예를 들기 위해 만든 것입니다. t-test에는 크게 세 가지 종류가 있습니다. 그리고 이 세 가지 종류의 t-test에 사용되는 t값을 구하는 공식도 또한 다릅니다. 사실 저도 공식을 외우지도 못합니다. 뿐만 아니라 때로는 공식을 봐도 계산하려면 진땀을 뺍니다. 저는 공식을 굳이 외울 필요가 없다고 생각합니다. 혹시 통계전공자라면 모르겠으나 비전공자로서 통계적 분석을 하려고 한다면 굳이 공식을 외울 필요는 없다고 봅니다. 요즘처럼 컴퓨터가 발달한 시대에 어지간한 계산은 프로그램이 다 알아서 해주는데 굳이 이걸 외워야 하나 싶습니다.\n그러나 한 가지는 꼭 알아야 합니다. t-test의 종류별 특징입니다. 어떤 상황에서 무엇을 목적으로 할 때 이런 종류의 t-test를 사용해야 한다는 점은 분명히 알아야 합니다. 만약 이를 헷갈리면 엉뚱한 방법을 적용해서 분석을 하게되고 당연히 결과도 문제가 되기 때문입니다. 그러면 이제 t-test의 종류에 대해 알아보겠습니다.\n\n\n2.6.2 Two-sample t-test\n여기서 주의할 점은 통계 프로그램마다 이름이 조금씩 다를 수 있다는 것입니다. 어떤 프로그램에서는 이를 independent t-test라고 부르기도 합니다. 기본적으로 이 t-test는 두 개의 독립적인 샘플을 대상으로 두 샘플이 동일한지 아닌지에 대한 분석을합니다. 만약 두 샘플이 동일한 모집단에서 나온 것이라면 동일 할 것이고, 서로 다른 모집단에서 나온 것이라면 다를 것이라는 생각에서 분석을 합니다. 우리가 앞에서 보았던 두 대학의 남학생의 평균키의 차이를 알고자 할 때 사용하는 방법입니다(Figure 2.4).\n\\[\\text{t-value}=\\frac{\\bar{x}_a-\\bar{x}_b}{\\sqrt{\\frac{s^2}{n_a}+\\frac{s^2}{n_b}}} \\quad (_{s^2}=\\frac{\\sum(x_a-\\bar{x}_a)^2+\\sum(x_b-\\bar{x}_b)^2}{n_a+n_b-2})\\]\n실제로 two-sample t-test의 t값 공식은 꽤 복잡합니다. 앞에서 우리는 쉽게 설명하기 위해 단순화한 것입니다. 여기서 자유도 \\(df\\) 는 \\(n_a+n_b-2\\) 가 됩니다. 그리고 여기서 \\(n_a\\) 는 A대학의 샘플 사이즈이고 \\(n_b\\) 는 B대학의 샘플 사이즈입니다. 저도 기억에 이 계산은 학생 때 시험에서 한번인가 해본 것 같습니다. 절대 외우실 필요는 없다고 봅니다.\n\n\n2.6.3 One-sample t-test\n이 t-test는 이름과 같이 샘플이 한 개인 경우에 하는 t-test입니다. 이 경우 샘플은 한 개인데 이 샘플의 평균값이 우리가 알고 있는 어떤 값과 동일한지 아닌지 알고 싶을 때 하는 방법입니다. 예를 들어 설명해 보겠습니다.\n\n\n\nFigure 2.21: One-sample t-test\n\n\n어느 대학교 X의 남학생의 평균키가 178.5cm였습니다. 금년도 정부 발표에 의하면 우리나라 20대 남성의 평균키가 180.0cm라고 합니다. 그래서 우리는 X대학 남학생 샘플의 평균키가 180.0cm와 같은지 아닌지 알고 싶습니다. 이런 경우 실시하는 것이 바로 one-sample t-test입니다.\n\\[\\text{t-value}=\\frac{\\bar{x}_a-\\bar{x}_b}{\\frac{s}{\\sqrt{n}}} \\quad \\quad \\quad _{(df=n-1)}\\]\n사실 우리가 앞의 예제에서 사용했던 식입니다. 앞에서는 설명의 용이성을 위해 two-sample t-test의 예에 one-sample t-test의 공식을 썼던 것입니다. 이제는 우리가 차이를 알았으니 이게 맞는 것이구나 하고 생각하면 됩니다. 두 방식의 공식은 매우 달라 보이지만 근본적인 원리는 동일하기 때문에 크게 고민할 필요가 없습니다.\n\n\n2.6.4 Paired t-test\n이 방법은 독특하게 paired라는 이름이 붙어 있습니다. 영어의 paired는 짝 지어진 이란 뜻으로 통계에서는 반복측정의 경우 paired 라는 단어를 주로 사용합니다. 반복측정이란 동일한 대상에게 다른 시점에 복수로 측정하는 것을 의미합니다. 다만 우리는 t-test이므로 딱 2회 측정한 것입니다. 예를 들어보겠습니다. 어느 통계 강의에서 중간고사까지는 기존의 강의교재를 이용하여 수업을 진행하다가 중간고사 이후 기말고사까지는 새로운 강의교재를 사용하여 수업을 진행하였습니다. 이때 새로운 강의교재가 사용되기 이전과 이후의 시험점수를 비교하였습니다. 해당 강의를 수강한 학생은 동일하며 모든 학생이 다른 강의교재로 수강하고 2회 시험을 보았습니다.\n\n\n\nFigure 2.22: Paired t-test\n\n\n우리가 궁금한 것은 새로운 교재로 강의를 한 것이 학생들의 실력향상에 도움이 되었는지 아닌지 입니다. 그러므로 동일한 학생들이 2회 시험을 보았고 새로운 교재를 사용하기 전과 후의 시험점수를 비교하고자 합니다. 이런 경우에 사용하는 것이 바로 paired t-test 입니다.\n\\[\\text{t-value}=\\frac{\\bar{x}_{diff}}{\\frac{s_{diff}}{\\sqrt{n}}} \\quad \\quad \\quad _{(df=n-1)}\\]\n여기서 작은 글자로 diff라고 되어 있는 것은 차이 (difference)를 의미합니다. 즉 분자에는 동일 학생의 두 번의 점수의 차이값의 평균이고, 분모에 들어가는 것은 이 차이의 표준편차입니다.\n축하합니다!\n여러분들은 지금 통계학에서 만나는 첫번째 통계분석 방법을 마스터했습니다.\n여기까지 오느라 수고 많이 하셨습니다. 사실 t-test는 무작정 공식을 암기하는 그런 것이 아니었습니다. 매우 논리적이며 이 논리에는 여러 이야기들이 숨어 있었습니다. 우리는 그중에서도 통계는 분산의 마법이라는 것을 확인할 수 있었고 이제 비로소 보다 깊은 통계의 세계로 들어갈 준비를 마쳤습니다. 다시 한 번 말씀드리지만 공식을 암기하는 것은 바보같은 일입니다. 계산은 컴퓨터 프로그램이 알아서 해줄 것입니다. 다만 우리는 어떤 경우에 어떤 방법을 적용할 것이지 알고 있어야 합니다. 이제 이론적으로 t-test를 마스터 했으니 실제 프로그램을 이용해서 실습을 진행해 봅시다.\nYouTube 바로 가기"
  },
  {
    "objectID": "chapter2.html#t-test를-실습해-보자",
    "href": "chapter2.html#t-test를-실습해-보자",
    "title": "2  첫 도전 t-test",
    "section": "2.7 t-test를 실습해 보자",
    "text": "2.7 t-test를 실습해 보자\n\n2.7.1 통계프로그램의 선택\n이제 우리는 컴퓨터 프로그램을 이용해 t-test 실습을 해 보겠습니다. 어떤 프로그램을 사용해야 할 까요? 가르치는 사람 입장에서 가장 난감한 것이 바로 이 문제입니다. 전 세계적으로 일반인들이 가장 애용하는 역사와 전통을 자랑하는 프로그램은 바로 SPSS입니다. 그러나 이것 말고도 다양한 통계 프로그램이 있습니다. SAS, STATA, R 등이 그것입니다. 이 중에서 어떤 것으로 실습 하는 것이 좋을까요? 사실 무엇이든 상관없습니다. 특히 통계의 기초적인 수준에서는 아무 관계가 없습니다. 문제는 비용입니다. 대부분의 통계 프로그램들은 돈을 주고 라이선스를 사야만 합니다. 최근에는 R과 같은 오픈소스 프로그램이 등장하여 큰 바람을 일으키고 있기도 합니다. 먼저 대표적인 통계 프로그램을 비교해 보겠습니다.\n\nSAS\n\n사용 편의성: 낮음\n배움의 용이성: 매우 낮음\n통계기초에는 문제가 없으나 고급방법론으로 갈수록 복잡\n비용: 매우 높음\n\nSPSS\n\n사용 편의성: 높음\n배움의 용이성: 매우 높음\n통계기초에는 문제가 없으나 고급방법론으로 갈수록 매우 복잡\n비용: 매우 높음\n\nSTATA\n\n사용 편의성: 높음\n배움의 용이성: 높음\n통계기초 + 고급방법론 모두를 상당히 쉽게 사용할 수 있음\n비용: 매우 높음\n\nR\n\n사용 편의성: 매우 낮음\n배움의 용이성: 매우 매우 낮음\n통계기초 + 최신 고급방법론까지 모두 제공/업데이트\n비용: 무료\n\n\n제가 처음 통계를 가르칠 때 가장 고민한 문제가 바로 프로그램의 선택이었습니다.\nSAS는 약간의 프로그래밍 느낌이 있어서 초보자들은 데이터를 불러오는 것만으로도 어려움을 느껴 포기하는 프로그램입니다. 다만 어느 정도의 프로그래밍이 가능하다면 데이터를 자유롭게 가공하여 분석할 수 있으며 필요에 따라 내가 원하는 분석방법을 만들어서 사용할 수도 있습니다. 그렇지만 배우기 정말 어려운 프로그램입니다. 저도 미국에서 석사학생 시절에 SAS를 사용했었는데 참 고생했던 기억이 납니다. 다음은 가장 많이 사용하는 SPSS입니다. GUI (Graphical User Interface)가 워낙 잘 되어 있는 프로그램이어서 클릭만으로 통계분석이 가능한 프로그램입니다. 더구나 굉장히 많은 통계 책들이 SPSS 사용법을 친절하게 알려주고 있어서 통계를 잘 모르더라도 책을 통해 클릭하면서 따라가다 보면 통계분석을 할 수 있는 장점이 있습니다. 제가 학부생 시절에 조금 사용해 본 경험이 있습니다. 워낙 쓰기 쉬워서 약간의 센스만 있어도 사용할 수 있습니다. 세번째는 STATA입니다. 비교적 최근에 등장하여 성장한 프로그램입니다. SAS적인 특성과 SPSS적인 특성 모두가 반영되어 필요에 따라서는 명령어를 타이핑하여 실행할 수도 있으며 이것이 어렵다면 SPSS처럼 GUI를 이용하여 클릭만으로 통계 분석을 진행할 수 있습니다. 가장 큰 장점은 SAS나 SPSS에 비해 최신의 방법론이 빠르게 업데이트되고 있다는 점입니다. 그래서 저는 박사학생 시절부터는 STATA를 사용해 왔습니다. 마지막은 R이라는 프로그램인데요. 사용 편의성이 낮고 배우기에 너무 어려운 프로그램입니다. 그러나 전 세계의 전문가 그룹이 최신의 방법들을 패키지로 만들어 계속 업데이트 하고 있어 발전속도가 매우 빠른 프로그램입니다. 최근에는 R의 사용 편의성 개선을 위해 R을 인스톨 한 후에 RStudio라는 프로그램을 인스톨하면 기존의 R보다는 보다 사용하기 편리한 환경에서 통계분석을 할 수 있게 되었습니다. 지속적인 RStudio의 발전이 일반인에게는 큰 희망이 되는 상황입니다. 그러나 SPSS와 같은 프로그램에 비하면 여전히 사용하기 어려운 프로그램입니다. 문제는 SAS, SPSS, STATA 모두 유료 프로그램인데 반해 R만 무료라는 점입니다. 제가 고민하는 부분이 이 지점입니다. 만약 제가 유료 프로그램으로 실습을 하면 여러분들이 모두 돈을 지불하고 유료 프로그램을 구입해야 하는데 쉽지 않은 결정입니다. 그래서 전 세계의 많은 사람들이 어둠의 경로를 통해 이 프로그램들을 다운받아 사용하고 있는 것이 현실입니다. 만약 제가 유료 프로그램을 사용하면 현실적으로 여러분들을 범죄의 길로 인도하는 상황이 되어 고민이 많았습니다.\n\n\n2.7.2 Jamovi의 사용\n그래서 수 년간 여러 프로그램들을 찾아 오던 끝에 몇 년 전에 Jamovi라는 프로그램을 알게 되었습니다. 일단, 이 프로그램의 장점은 오픈소스이기에 무료라는 점입니다. 더불어 SPSS처럼 GUI가 발달하여 사용편의성이 매우 높은 프로그램입니다. 심지어 편의성 측면에서는 SPSS 보다도 좋습니다. 또한 결과를 리포트하기에 용이하게 되어 있습니다. 더구나 최근 이 Jamovi는 기존의 단점을 극복하고 진정한 최고의 프로그램이 되었습니다. 기존에는 데이터에 한글이 들어갈 경우 에러가 발생 하는 문제 등이 있었지만 지금은 해결되었습니다. 물론, 메뉴의 한글화 작업이 아직 이루어지지 않아 불편할 수도 있으나 이는 충분히 극복 가능한 부분이라고 생각됩니다. 생각보다 빠르게 다양한 분석 패키지가 업데이트되고 있습니다. 이 프로그램은 R을 베이스로 작동되어 jamovi를 인스톨 하기 전에 먼저 R을 인스톨 하실 것을 권장합니다. 저는 불과 몇 년 전까지만 해도 약간의 불편함을 느꼈지만 최근에는 거의 불편함을 못 느끼고 오히려 정말 좋은 프로그램이라고 생각하고 사용합니다. 학생들에게는 무조건 이 프로그램을 권유합니다.\n\nR 다운로드: https://www.r-project.org/\nJamovi 다운로드: https://www.jamovi.org/\n\n제가 처음 강의를 시작할 때만해도 Jamovi가 아직 정식 1.0 version이 출시되기 전이었습니다. 지금은 정식 1.0 version이 출시되고 계속 업데이트 되고 있습니다. 초기의 프로그램이 멈추거나 화면이 깨지는 현상은 최근에는 거의 발생하지 않습니다. 이후에 다른 훌륭한 오픈소스 프로그램을 또 알려드릴 것이고 실습에 사용할 것입니다. 당장 사용하지 않더라도 R과 RStudio를 모두 인스톨 해 놓을 것을 추천드립니다. 언젠가 사용할 날이 올 것입니다.\n\n\n2.7.3 실습에 사용할 데이터\n제가 처음 이 강의를 시작 했을 때만해도 별도의 실습용 데이터 저장소를 만들지 않았습니다. 저의 게으름 때문이지요. 그러나 이제 실습용 데이터를 쉽게 다운로드 받을 수 있게 GigHub에 저장소를 만들었습니다. 원래 우리가 사용할 실습 데이터는 kaggle.com 에서 다운받은 것이었습니다.\n\n실습용 데이터 다운로드: https://github.com/who4u78/Ko_stat_sample_data\n캐글: www.kaggle.com\n\nGitHub에서 다운받으셔도 되지만 한 번쯤 캐글에 들어가서 둘러보길 권합니다. 캐글에서 데이터 검색을 하시고 검색어를 “student alcohol consumption”으로 하신 후에 데이터셋에서 student-mat.csv 라는 파일을 다운받아 사용하시면 됩니다. 다운로드를 위해서는 로그인을 하셔야 할 것입니다. 이 데이터는 학생들의 수학성적을 모아 놓은 데이터입니다.\n\n\n2.7.4 실습을 해보자\n제가 유튜브 동영상 강의를 선호하는 이유가 바로 이 실습 때문입니다. 글로 실습을 설명하는 것은 참 비효율적이라는 생각이 듭니다. 책을 쓰면서 아무리 다시 생각해 보아도 글보다는 영상으로 실습을 직접 확인하는 것이 좋다고 판단됩니다. 그러니 유튜브링크로 들어가 직접 실습해 보실 것을 권해드립니다. 가장 좋은 방법은 더블 스크린 환경에서 하나의 화면에는 동영상을 띄우고 다른 화면에는 실습 프로그램을 띄워서 사용하시면 보다 편안한 환경을 구축 할 수 있습니다. 그러면 이제 실습의 세계로 들어가 봅시다!!\nYouTube 바로 가기"
  },
  {
    "objectID": "chapter3.html#이제-다시-시작해-보자",
    "href": "chapter3.html#이제-다시-시작해-보자",
    "title": "3  분산분석 (ANOVA)",
    "section": "3.1 이제 다시 시작해 보자",
    "text": "3.1 이제 다시 시작해 보자\n\n3.1.1 새로운 시작은 아는 것에서 부터\n이제 우리는 통계의 첫 관문을 통과 했습니다. z-test와 t-test가 무엇인지 알게 되었고 이를 jamovi라는 통계 프로그램을 통해 분석할 수 있게 되었습니다.\n축하드립니다!!!\n별 것 아닌 것 같아도 사실 여러분들은 굉장히 크고 의미 있는 한 걸음을 내딛은 것입니다. 통계를 공부하는 사람들이 대부분 여기까지 하고 다음부터는 그냥 SPSS같은 프로그램을 따라 하기 바빠집니다. 그러다보니 나중에 어떤 통계 결과표를 보고서도 해석 하는 못하고 그저 유의하다는 말만 반복하게 되는 것입니다. 사실 통계를 공부하는 학생들을 이렇게 만드는 그 원인은 아마도 분산분석 (ANOVA) 때문일 것입니다. 어떻게든 t-test까지는 알듯 말듯 하면서 힘겹게 공부해서 진도를 나갔는데, 그 다음에 만나는 것이 바로 분산분석입니다. 여기부터는 정말이지 도통 알 수 없는 말들의 향연이자 그냥 계산하고 결과보고 유의한지 아닌지만 알게 되는 상황이 됩니다. 그래서 대부분의 통계를 공부하는 분들이 분산분석에서 통계를 포기하기에 이릅니다.\n하지만 저는 여러분들에게 포기하지 말라고 말씀드리고 싶네요. 아직 포기하기엔 이릅니다. 저와 함께 이제 한 발자국 더 통계의 세계로 여행을 떠나 봅시다. 그렇다고 무조건 쉽게 알려드리겠다는 장담을 하지는 않겠습니다. 다만 앞에서도 그랬듯 최대한 여러분들이 이해하기 쉽게 차근차근 나아가겠습니다.\n이제 우리가 시작할 분산분석은 영어로 ANOVA라고 합니다. 이 ANOVA라는 단어는 줄임말입니다. 정확하게는 Analysis of Variance의 약자입니다. 영어를 해석해 보면 말 그대로 분산분석입니다. 자, 그럼 이제 분산분석의 시작점을 잡아야 합니다. 분산분석의 시작점은 우리가 앞서 배운 t-test입니다. 그러면 복습도 할 겸 다시 t-test의 정의를 살펴보겠습니다.\n\n모집단의 표준편차가 알려지지 않았을 때, 정규분포의 모집단에서 모은 샘플(표본)의 평균값에 대한 가설검정 방법\n\n위의 정의를 이제는 조금 이해하시겠지요? 사실 그리 쉽게 설명한 정의는 아니지만 우리는 위에 등장한 모집단, 표준편차, 정규분포, 샘플(표본), 평균값 그리고 가설검정이라는 단어들을 이미 다 공부했습니다. 그러니 천천히 읽고 생각해 보면 그다지 어려운 표현은 아니라는 생각이 들 것입니다. 하지만 너무 어렵게 표현한 것만은 사실입니다. 굳이 이렇게 설명했어야 했나라는 생각은 정말 많이 드네요.\n앞서 t-test를 처음 공부할 때, 제가 t-test의 목적을 그냥 이렇게 이해하는 것이 좋다고 이야기 했습니다. “어떤 두 집단이 같은지 다른지 알고 싶을 때 하는 테스트.” 그렇습니다. 좀 쉬운 그러나 너무 단순화한 t-test의 목적이기는 합니다. 하지만 핵심적인 내용을 명확하고 쉽게 담고 있는 정의입니다.\n\n\n\nFigure 3.1: t-test의 목적\n\n\n그래서 우리는 앞서 A와 B라는 두 대학교의 남학생의 평균키가 같은지 다른지 알아보고자 하는 t-test를 진행하였습니다. 여기서 우리는 두 대학의 남학생의 키가 동질적인지 아닌지 알고 싶었습니다. 이 목적을 달성하기 위해 t-test를 했던 것이지요. 그런데, 만약에 다음과 같이 우리 동네에 대학교가 하나 더 있다고 가정하면 우리는 이제 세 개의 대학의 남학생의 평균키가 같은지 다른지 알고 싶은 상황이 됩니다. 이렇게 되면 어떻게 해야 할까요?\n\n\n\nFigure 3.2: ANOVA의 목적\n\n\n\n\n3.1.2 꼼수의 대마왕\n사실 인간은 잔머리를 잘 씁니다. 쉽게 말해 꼼수의 대마왕이지요. 우리는 여태 힘들게 t-test를 배웠고 이제 막 한 숨 돌리던 차였습니다. 그런데 갑자기 우리 앞에 분산분석이 나타나니 마음 한편이 좀 불편했을 수 있습니다. 이렇게 되고 나니, 저 세 개의 그룹을 비교하려고 할 때 우리는 새로운 분산분석을 배우려 하기 보다는 기존에 알던 t-test를 이용해 어떻게든 새로운 공부를 피해보고 싶기 마련입니다. 그래서 처음에 누구나가 생각하는 방법이 바로 이것입니다.\n\n\n\nFigure 3.3: Multiple t-test\n\n\n우리는 이것을 Multiple t-test라고 부릅니다. 즉, t-test를 여러 번 한다는 의미가 됩니다. 이 예를 Multiple t-test로 해결하려면 일단 A대학과 B대학을 t-test로 비교해서 B대학 남학생이 키가 더 크다고 나오고, 두 번째로 B대학과 C대학을 t-test로 비교하여 B대학 보다는 C대학이 크다고 나오고, 마지막으로 이를 A대학과 C대학을 t-test로 비교하여 확실히 A대학보다 C대학의 남학생 키가 크다고 나오면 우리는 이 세 번의 t-test 결과를 종합하여 이렇게 결론 내릴 것입니다. A대학 \\(\\leq\\) B대학 \\(\\leq\\) C대학 이런 식으로 말입니다.\n어떤가요? 그럴듯하지요? 뭐 이렇게 보면 굳이 분산분석이라는 새로운 방법을 배울 필요가 없어 보입니다. 그런데 말입니다. 그럴 리가 있나요. 세상 그렇게 단순하지 않습니다. 이 Multiple t-test에는 한 가지 심각한 문제가 있습니다. 여기서 등장하는 것이 앞서 배웠던 1종 오류입니다. 기억나시나요?\n\n\n3.1.3 1종 오류의 재등장\n다시 한 번 이야기 하자면, 1종 오류란 귀무가설이 실제로는 참인데, 연구결과 귀무가설이 기각되어 거짓이라고 나오는 상황입니다. 예를 들어 어떤 치료제가 실제로는 아무 효과가 없는데, 연구결과 이 치료제가 효과가 있다고 나타난 경우입니다. 그렇다면 이 1종 오류가 여기에서 왜 등장할까요? 먼저 우리는 1종 오류(\\(\\alpha\\))에 대해서 다시 떠 올려야 합니다. 앞서 \\(\\alpha\\)를 유의수준이라고 부른다고 했고 이 유의수준을 5%로 정한다고 이야기 했습니다. 즉, 우리가 일반적으로 말하는 p값의 기준인 5%가 다른 한편으로는 1종 오류를 5%로 제한하겠다는 의미라는 것이지요. 즉, 우리의 분석결과가 아무리 잘 못 되었다 하더라도 1종 오류가 발생할 가능성이 5%보다는 낮다는 것을 의미합니다.\n이제 다시 multiple t-test로 돌아가 봅시다. 우리는 세 번의 t-test를 진행하였고 이 세 번의 t-test의 결과를 종합하여 “A대학 \\(\\leq\\) B대학 \\(\\leq\\) C대학”라는 결론을 도출했습니다. 그리고 이 세 번의 t-test에서 매 번 우리는 자연스럽게 5%의 유의수준 (\\(\\alpha\\))를 사용했습니다. 문제는 우리가 5%의 유의수준 (\\(\\alpha\\))를 세 번 사용하여 이를 종합하여 결론을 내렸기 때문에 우리가 이 분석에서 실제로 사용한 유의수준은 5%가 아닌 약 15%가 됩니다. 왜냐하면 5%를 세 번 사용했으니 대략 3을 곱하면 15%가 되는 것입니다.\n물론 정확한 유의수준을 구하는 공식은 다음과 같습니다.\n\\[\\alpha_{FW} = 1- (1-\\alpha)^c \\approx \\alpha \\times c \\]\n위의 공식에서 c는 Multiple t-test를 몇 회 하였는지를 의미합니다. 결국 앞서 우리가 이야기 했듯이 이 값은 대략 사용된 유의수준에 테스트 횟수를 곱한 값과 유사합니다. 따라서 위의 예제의 경우 우리는 나름대로 5%의 유의수준을 기준으로 테스트했다고 생각했지만 실제로는 15%의 유의수준을 가지고 테스트한 것이 되었으므로 1종 오류의 가능성이 분명히 생긴 것입니다. 결론적으로 말하자면 그룹이 3개 이상인 경우 t-test를 여러 차례 시행하는 Multiple t-test는 불가 하다는 것입니다. 그러니 우리는 싫어도 분산분석을 배워야 하겠네요.\n이제 우리는 분산분석을 공부해야 하는 이유를 알았습니다. 그러면 다시 마음을 잡고 새로운 통계의 세계로 여행을 떠나 봅시다!!!\nYouTube 바로 가기"
  },
  {
    "objectID": "chapter3.html#anova-말고-변수",
    "href": "chapter3.html#anova-말고-변수",
    "title": "3  분산분석 (ANOVA)",
    "section": "3.2 ANOVA 말고 변수",
    "text": "3.2 ANOVA 말고 변수\n\n3.2.1 본격적인 시작 전에 알아야할 그것, 변수\n이제 우리는 ANOVA를 공부해야만 한다는 사실을 알았습니다. Multiple t-test로 어떻게 해보고 싶었지만 안 되기 때문입니다. 분산분석을 시작하기 전에 우리는 변수에 대해 알아보고 갈 것입니다. 만약 변수에 대해 잘 알고 있다면 그냥 넘기셔도 됩니다. 우리가 공부할 내용은 다음의 것들입니다.\n\n독립변수\n종속변수\n통제변수\n\n그럼 이제 하나씩 시작해 봅시다.\n\n\n3.2.2 독립변수\n굳이 통계가 아니어도 독립변수라는 이름은 많이 들었을 것입니다. 아무 생각 없이 들으면 그냥 그러려니 할 수도 있지만, 가만히 생각해보면 이름이 참 독특합니다. 독립변수. 도대체 무엇으로부터 독립인 것일까요? 책이나 인터넷을 찾아보면 다음과 같이 설명이 되어 있습니다.\n\n독립변수: 연구자/조사자가 의도적으로 변화시키는 변수 혹은 다른 말로 예측변수(predictor variable) 또는 설명변수(explanatory variable)\n\n여기서 독립이란 것이 무슨 뜻일까요? 독립변수라고 할 때의 독립이 의미하는 것은 논리적 관계성에서의 독립을 의미합니다. 일반적으로 우리는 변수를 이용해 논리적 인과관계를 연구하거나 다루게 됩니다. 이러한 인과관계에서 독립적인 위치를 가진 변수가 독립변수입니다. 인과관계에서 독립적인 위치란 원인과 결과의 관계에서 원인을 의미합니다. 왜냐하면 결과는 원인에 의해 영향을 받거나 좌우되기 때문에 독립적일 수 없기 때문입니다. 따라서 독립변수란 인과관계에서 원인이 되는 변수라고 이해하면 보다 쉽습니다.\n다만, 위에 책이나 인터넷에 나온 것처럼 연구자/조사자가 의도적으로 변화시킬 수 있다고 하여 이 독립변수를 연구자가 마음대로 바꿔도 된다는 의미가 아닙니다. 어디까지만 독립적인 변화가 가능하고 이러한 독립적인 변화를 이용하여 연구자나 조사자가 연구/조사를 진행할 수 있다는 의미입니다. 의도적이라는 말에 너무 의미를 두게 되어 마치 조작이 가능하고 더 나아가서 조작하거나 마음대로 바꿔도 된다고 이해하는 것은 매우 위험합니다.\n\n\n3.2.3 종속변수\n종속이란 단어는 사실 일상생활에서는 많이 사용하는 단어는 아닙니다. 종속이란 어딘가에 속해 있다. 정확하게는 주가 되거나 강한 힘을 가진 어떤 것에 좌우되는 것을 의미합니다. 여기서 말하는 주가 되거나 강한 힘을 가진 어떤 것이 앞에서 이야기한 독립변수이고 이 독립변수에 의해 좌우되는 것이 바로 종속변수입니다. 책이나 인터넷을 찾아보면 이런 설명이 되어 있습니다.\n\n종속변수: 연구자/조사자가 독립변수의 변화에 따라 어떻게 변하는지 알고 싶은 변수 혹은 다른 말로 반응변수(response variable) 또는 결과변수(outcome variable)\n\n그러므로 여기서 말하는 종속은 논리적 인과관계에서의 종속을 의미합니다. 따라서 원인과 결과의 관계에서 종속에 해당하는 것은 결과이고 이 결과를 의미하는 변수가 종속변수입니다. 종속변수는 우리가 연구에서 알고 싶은 주요한 대상이자 결과입니다. 이 결과를 어떻게 하고 싶을 때 우리는 이 결과에 영향을 미칠만한 독립변수를 이용해 독립변수의 변화에 따라 종속변수가 어떻게 되는지 연구하는 것입니다. 다음의 Figure 3.4 에서 보면 고등교육이라는 변수는 독립변수이고 임금수준의 상승은 종속변수입니다. 일반적으로 경제학에서는 대학교육과 같은 고등교육을 투자로 인지합니다. 왜냐하면 상당한 돈과 시간을 투자하여 졸업 후 상당한 수준의 임금상승을 기대하는 행위이기 때문입니다. 따라서 고등교육을 받았기 때문에 임금이 높다는 것은 논리적 인과관계에서 이상이 없습니다. 중요한 것은 많은 연구자들이 이렇게 단순한 논리적 인과관계는 무시한 채로 아무 변수나 독립변수에 혹은 종속변수에 넣어서 분석하는 경우가 많다는 것입니다. 논문 심사를 하다 보면, 인과관계가 전혀 없거나 심지어 인과관계가 바뀌어 원인과 결과를 뒤집어서 논문을 발표하는 학생을 가끔 봅니다. 큰 일이 아닐 수 없습니다. 대부분 지도교수의 지도를 무시하고 단행한 경우 발생하는 일입니다. 연구 전에 충분히 읽어보고 생각하여 논리적 인과관계에 대해 확신을 가지고 연구를 진행해야 합니다. 의외로 이런 경우가 많습니다.\n\n\n\nFigure 3.4: 독립변수 vs. 종속변수\n\n\n\n\n3.2.4 통제변수\n보통은 Control variable이라고 하는 변수입니다. 기본적인 역할은 독립변수와 동일합니다. 즉, 종속변수에 영향을 주는 변수입니다. 그러나 이 변수는 독립변수의 역할을 하면서도 사실상 주인공이라기보다는 조연에 가깝습니다. 그렇다고 무시하거나 없으면 안 되는 존재입니다. 예를 들면, 어느 식당의 재방문율을 종속변수로 하고 고객만족을 독립변수로 하는 연구/조사를 진행한다고 가정합니다. 이런 경우, 가장 많이 하는 실수가 단 하나의 독립변수만으로 종속변수에 대한 영향을 확인하는 것입니다. 이게 왜 문제가 되냐 하면, 종속변수인 재방문율에 영향을 미치는 중요한 변수는 오직 고객만족 하나일리는 없기 때문입니다. 고객만족 말고도 예를 들어 음식의 맛이나 서비스의 품질, 혹은 인테리어 등의 분위기 등이 중요한 변수일 수 있습니다. 만약 이런 중요한 통제변수를 제외하고 단 하나의 독립변수만으로 분석을 하게 되면, 이 하나의 변수가 다른 모든 변수들을 대표하게 되어 문제가 됩니다. 일반적으로 이런 상황을 Model mis-specification 이라고 부릅니다. 즉 모형이 잘못되었다는 의미가 됩니다.\n현재 우리가 공부하는 분산분석은 단 한 개의 독립변수만을 가지고 분석하는 일원배치 분산분석(One-way ANOVA)입니다. 물론 그렇다고 일원배치 분산분석은 다 잘못된 것이라는 의미는 아닙니다. 그러나 보다 현실적이고 깊이 있는 연구/조사를 하고자 한다면 상당한 수준의 중요한 변수들을 통제변수로 포함하여 분석하는 것이 좋습니다. 우리가 앞으로 공부할 통계적인 방법 중에 이런 것들이 있을 것입니다.\n이제 슬슬 보다 본격적인 분산분석을 공부해 봅시다.\nYouTube 바로 가기"
  },
  {
    "objectID": "chapter3.html#anova-전에-알아야-할-것들",
    "href": "chapter3.html#anova-전에-알아야-할-것들",
    "title": "3  분산분석 (ANOVA)",
    "section": "3.3 ANOVA 전에 알아야 할 것들",
    "text": "3.3 ANOVA 전에 알아야 할 것들\n\n3.3.1 일원배치 분산분석의 독립/종속변수\n우선 우리가 지금 배우는 것은 일원배치 분산분석입니다. 일원배치라는 말은 저도 참 이해가 어렵기는 합니다만 영어로는 One-way로 번역합니다. 여기서 One-way가 의미하는 것은 독립변수가 한 개라는 것입니다. 그러므로 Two-way ANOVA는 이원배치 분산분석이 되고 여기서는 독립변수가 두 개가 됩니다. 중요한 것은 모든 분산분석에서 독립변수와 종속변수는 동일한 특징이 있다는 점입니다. 이것이 바로 우리가 분산분석을 공부하기 전에 알아야 하는 것입니다.\n\n분산분석에 사용되는 변수의 특징\n\n종속변수: 연속형 변수 (Continuous variable)만 가능함\n독립변수: 이산형(Discrete variable) 혹은 범주형 변수(Categorical variable)만 가능함\n\n\n위에서 이야기하는 변수의 종류가 무엇인지 잘 모르겠다면 앞부분의 Section 1.5.3 을 다시 공부해보시기 바랍니다.\n예를 들어 보겠습니다. 아주 오래전에나 가능했던 것이지만, 예전에는 연구윤리라는 개념이 없었던 시절이 있었습니다. 당시에 영상물이 어린이들의 폭력성에 미치는 영향을 연구하고자 어린 아이들을 세 그룹으로 나누어 한 그룹에는 폭력적인 영화장면을, 다른 그룹에는 드라마를, 마지막 그룹에는 공익광고를 보여준 뒤에 이 아이들을 관찰실에 들여보낸 후 아이들이 관찰실에서 보이는 폭력적인 행동을 점수화 하였습니다. 생각해보면 사람을 상대로 그것도 어린 아이들을 상대로 이런 실험을 실제로 했다는 것이 믿기지 않지만, 과거에는 이런 일들이 일어나기도 했습니다.\n하여튼, 이 경우 적용되는 분석방법이 바로 분산분석입니다. 그렇다면 위의 예에서 독립변수와 종속변수는 무엇인지 설명해 볼까요?\n\n종속변수: 점수화된 아이들의 폭력성\n독립변수: 세 가지 종류의 영상(폭력영화/드라마/공익광고)\n\n좀 이해가 되시나요? 그렇다면 다른 예를 들어보죠. 신종플루 치료제를 개발 중인 어느 제약회사에서 신종플루 감염자를 대상으로 신약의 효과를 측정하고자 합니다. 이 경우 종속변수와 독립변수는 어떤 식으로 만들어질까요?\n\n종속변수: 신약을 복용한 후 완치까지 걸린 날짜\n독립변수: 세 가지 약을 복용한 그룹(개발중인 신약/기존의 독감약/플라시보)\n\n이 경우 완치까지 걸린 날짜가 종속변수가 됩니다. 반면에 독립변수는 세 가지 그룹이 있을 수 있습니다. 첫 번째 그룹은 개발 중인 신약을 복용한 그룹이고, 두 번째 그룹은 기존의 독감약을 복용한 그룹입니다. 이 두 그룹을 비교하는 것은 충분히 이해가 됩니다. 기존 독감약에 비해 개발 중인 신약이 어느 정도의 효과인지 비교할 수 있겠지요. 마지막의 플라시보는 무엇일까요? 보통 위약이라고도 부릅니다. 위약효과라는 표현도 있죠. 간단하게 말해 아무 효과도 없는 밀가루 덩어리를 약처럼 만들어서 먹이는 겁니다. 즉, 아무것도 처치하지 않은 그룹이죠. 이 그룹은 사람의 자연적인 면역력으로 치료가 되는 기간을 측정하는 것입니다. 물론 현실에서는 매우 위험하고 윤리적인 문제가 있습니다. 어디까지나 하나의 예로서 든 것뿐입니다.\n또 다른 예를 들어보겠습니다. 이 예는 나중에 우리가 직접 통계 소프트웨어를 이용해 분석할 문제이기도 합니다.\n만약 어느 인터넷 서비스 기업 (ISP: Internet Service Provider)이 자신의 고객들의 총 지불금액이 고객별 이용대금 지불방법에 따라 차이가 있는지 알고 싶다면 종속변수와 독립변수는 어떻게 될까요?\n\n종속변수: 총 지불금액 (Total charges)\n독립변수: 대금 지불방법 (총 4가지 그룹)\n\n계좌이체 (Bank transfer)\n신용카드 (Credit card)\n전자수표 (Electronic check)\n종이수표 (Mailed check)\n\n\n\n\n3.3.2 ANOVA를 위한 데이터 코딩\n이번에는 엑셀에 데이터 코딩하는 것과 관련해서 잠깐 설명하고자 합니다. 갑자기 웬 데이터 코딩이냐고 하시겠지만 이게 용어가 워낙 오래된 것이라서 안 쓸 수도 없고 그러네요. 요즘에는 코딩이란 말이 프로그래밍이란 말과 혼용되어 사용되지만 사실 데이터 분석에서 코딩이란 말은 데이터를 입력하는 것을 의미합니다. 지금이야 온라인으로 설문조사를 하고 그 결과가 자동으로 엑셀에 입력되지만 과거에는 종이로 설문지를 만들어 돌리고 그 결과를 책상 한편에 쌓아 두고 한 부 한 부 정성스럽게 엑셀에 입력해야 했습니다. 이 작업을 코딩이라고 불렀지요. 지금도 그렇기는 합니다만, 요즘은 이렇게 종이로 받은 설문지를 직접 코딩하는 경우가 많지는 않지만 여러분이 스스로 통계 조사와 분석을 하려면 당연히 알아야 합니다. 왜냐하면 이걸 잘 못해서 혹은 몰라서 분석 자체를 시작도 하지 못하는 경우가 많기 때문입니다.\n아래의 Figure 3.5 를 보면 코딩이 완료된 엑셀 화면에서 한 개의 행(row)는 관찰값(observation)을 의미합니다. 여기서 관찰값이란 예를 들면 설문조사를 했을 경우 한 명의 설문 응답자의 응답을 의미합니다. 동일한 한 명의 사람이 응답한 결과는 한 개의 행(row)에 입력되는 것입니다. 그러므로 만약 100명의 사람들에게서 설문 응답을 받아 이를 제대로 코딩했다면 100개의 행(row)을 갖게 되는 것입니다.\n\n\n\nFigure 3.5: 데이터 코딩에서 관찰값\n\n\n다음은 동일한 엑셀 화면에서 한 개의 열(column)을 보여주고 있는 Figure 3.6 입니다. 엑셀에 코딩된 화면에서 한 개의 열(column)은 한 개의 변수를 의미 합니다. 지금 화면에는 모든 변수를 다 보여주고 있지 못하지만 결론적으로 열(column)의 개수를 세어보면 우리는 데이터의 변수의 개수를 알 수 있다는 의미 입니다. 사실 이 엑셀화면은 나중에 우리가 실습에 사용할 데이터입니다. 이 데이터의 종속변수와 독립변수를 확인해 보도록 하겠습니다.\n\n\n\nFigure 3.6: 데이터 코딩에서 변수\n\n\n아래의 Figure 3.7 과 Figure 3.8 을 확인해보면 종속변수와 독립변수를 알 수 있습니다. 종속변수는 보다시피 연속변수이고 독립변수는 4가지 그룹의 범주형 변수입니다. 잘 안보일 수도 있으나 종속변수는 숫자라는 점 그리고 독립변수는 문자로된 4가지 그룹으로 되어 있다는 점입니다. 중요한 것은 독립변수의 4가지 그룹이 한 개의 열(column)에 있다는 점입니다. 경우에 따라 초보자들은 이 독립변수를 한 개의 열(column)이 아닌 4개의 열(column)에 입력하는 실수를 하기도 합니다. 이렇게 되면 아예 분석이 불가능합니다. 꼭 기억하기 바랍니다. 한 개의 변수는 한 개의 열(column)에 입력되어야 한다는 사실 말입니다.\n\n\n\nFigure 3.7: 실습 데이터의 종속변수\n\n\n\n\n\nFigure 3.8: 실습 데이터의 독립변수\n\n\n\n\n3.3.3 엑셀 코딩시 편리한 기능\n사실 이런 방법은 저도 원래는 제 학생들에게만 알려주는 것인데 공개하는 내용입니다. 알고 보면 정말 별 것 아니지만 아는 것과 모르는 것이 편리하기가 천지차이이기 때문입니다. 본래 엑셀에서 엔터키를 누르면 커서가 아래쪽 방향으로 이동합니다. 문제는 앞서 이야기 했듯이 우리가 코딩할 때, 한 명의 응답자의 응답을 입력하려면 한 개의 열(row)에 입력해야 합니다. 1번 질문에 대한 답을 3이라는 값으로 입력하고 난 후에 엔터를 치면 커서가 우측이 아닌 아래로 내려갑니다. 이렇게 되면 우리는 방향키를 이용해서 커서를 다음 입력위치로 옮겨 놓아야 합니다. 매우 번거로운 일입니다.\n이 문제를 해결하는 방법은 매우 쉽습니다. 엑셀에서 &lt;파일&gt; 메뉴를 클릭한 뒤에 &lt;옵션&gt;을 클릭하고, 그 후에 &lt;고급&gt;을 눌러보시기 바랍니다. 가장 상단에 엔터키를 누른 후 커서의 이동방향을 설정할 수 있는 부분이 있을 것입니다. 기본 값은 아래쪽으로 되어 있지만 이 방향을 우측으로 변경한 뒤에 저장 후 다 시 엑셀을 실행해 보면 엔터키를 치고 난 뒤에 커서가 우측으로 움직이는 것을 확인하실 수 있을 것입니다. 알고 보면 정말 별것 아니지만 수백 장의 설문지를 코딩하는 경우 상당한 시간을 아낄 수 있습니다.\n더불어 위의 경우와 같이 독립변수의 그룹을 문자열로 입력할 경우 일부 통계 프로그램은 이를 인식하지 못하는 문제가 발생합니다. 즉, Bank transfer, Credit card, Electronic check, Mailed check과 같은 문자열은 인식이 안 되어 이를 강제로 1, 2, 3, 4로 바꿔 코딩해야 하는 경우가 있습니다. 이 경우 기존의 변수를 지우지 말고 엑셀에서 추가로 열(column)을 생성해서 여기에 엑셀의 if 함수를 사용해 변경해 주는 것이 빠르고 편리합니다. 대부분의 통계 프로그램에서 이를 변경하려고 하면 오히려 시간과 노력이 더 많이 들어가는 경우가 많기 때문입니다. 다만, 우리는 이런 수고를 할 필요가 없습니다. 왜냐하면 우리가 사용할 Jamovi라는 프로그램은 위의 문자열을 알아서 범주형 변수로 인식하기 때문입니다. 매우 편리한 기능이 아닐 수 없습니다.\n그럼 이제 분산분석에 대해 본격적으로 배워봅시다!!\nYouTube 바로 가기"
  },
  {
    "objectID": "chapter3.html#anova의-기본을-이해하자",
    "href": "chapter3.html#anova의-기본을-이해하자",
    "title": "3  분산분석 (ANOVA)",
    "section": "3.4 ANOVA의 기본을 이해하자",
    "text": "3.4 ANOVA의 기본을 이해하자\n\n3.4.1 책에 등장하는 Equation\n다시 한 번 강조하자면 우리가 하는 것은 일원배치 분산분석 (One-way ANOVA)입니다. 이 분산분석의 목적은 세 개 이상의 그룹을 비교하고자 할 때 하는 것입니다. 이유는 두 개의 그룹을 비교할 때 사용 하던 t-test를 여러 번 해서 이 결과들을 종합하여 결론을 내릴 경우 우리는 문제가 된다는 것을 앞서 배웠기 때문입니다. 우리가 하려는 것은 바로 Figure 3.2 의 그림과 같은 상황입니다.\n이제 보통 통계를 공부하다가 통계책에서 이런 것을 발견하곤 합니다.\n\\[Y_{ij} = \\mu \\;+\\; \\tau_{j} \\;+\\; \\epsilon_{ij} \\] \\[Y_{ij} \\;-\\; \\mu = \\tau_{j} \\;+\\; \\epsilon_{ij} \\]\n이게 무엇일까요? 보통 굳은 결심으로 통계책을 펴고 공부를 시작해도 이런 것을 보게 되면 많은 경우 통계를 반쯤 포기하게 됩니다. 여러분들은 그럴 필요가 없습니다. 제가 도와드리겠습니다. 위의 것은 그냥 어려워 보이게 써 놓은 것일 뿐 사실 내용을 알고 보면 그다지 어려운 것은 아닙니다.\n첫 번째 식과 두 번째 식은 같은 식입니다. 다만 \\(\\mu\\) 를 우측에서 좌측으로 옮겨 놓은 것뿐입니다. 기본적으로 \\(=\\) 기호의 좌측을 좌항 우측을 우항이라고 합니다. 좌항부터 일단 보겠습니다. \\(Y_{ij}\\) 는 분산분석에서 종속변수를 의미합니다. 앞서 이야기 했듯이 종속변수는 연속변수(continuous variable)이어야 합니다. 기본적으로 대문자 \\(Y\\)가 종속변수를 의미합니다. 이런 식으로 표현하는 이유는 한 개의 문자를 이용해 데이터의 모든 종속변수에 해당하는 숫자를 표기하기 위함입니다. 마치 중학교 때 배운 미지수 \\(x\\)와 같은 것입니다. 그렇다면 \\(Y\\)의 아래에 있는 아래첨자 \\(_{ij}\\)는 무엇일까요? 기본적으로 \\(j\\)는 분산분석의 독립변수의 그룹을 의미합니다. 조금 헷갈릴 수 있는데요. 갑자기 종속변수에 독립변수의 그룹을 표기하는 것이 이상해 보일 수 있습니다. 이렇게 생각하면 됩니다. 종속변수에 해당하는 어떤 데이터가 있습니다. 이 데이터는 숫자 즉 연속형 변수인데, 이 숫자가 어느 독립변수의 그룹의 영향으로 만들어진 데이터인지 알기 위해 \\(j\\)라는 문자를 사용해서 표기하는 것입니다. \\(i\\)라는 문자는 해당 그룹 내에서 몇 번째 종속변수인지를 의미합니다. 조금 어려우시다고요? 그렇다면 앞에서 보았던 데이터의 엑셀 코딩 화면을 보면서 설명해 보겠습니다.\n\n\n\nFigure 3.9: 분산분석 코딩화면\n\n\n위의 Figure 3.9 를 보면 독립변수 한 열(column)과 종속변수 한 열(column)을 볼 수 있습니다. 이제 화면을 조금 확대해서 보겠습니다.\n\n\n\nFigure 3.10: 코딩화면의 종속변수\n\n\n우리가 사용할 종속변수는 Total Charges입니다. 이 변수의 변수명이 첫 번째 행(row)에 있고 그 아래로 종속변수의 값이 쭉 있습니다. 첫 번째 값은 29.85인데요. 그 앞에 앞의 열(column)인 Payment Method가 바로 우리가 사용할 독립변수입니다. 여기서 독립변수는 4 개의 그룹으로 이루어져 있습니다. 예를 들어 Electronic chek을 1번 그룹으로 Mailed check을 2번 그룹으로 Bank transfer (automatic)을 3번 그룹으로 Credit card (automatic)을 4번 그룹으로 지정했다면 이 번호가 바로 위의 공식에 등장 하는 \\(j\\)값이 됩니다. 그러므로 첫 번째의 29.85라는 값은 1번 Electronic check그룹의 첫 번째 값이므로 \\(i=1\\), \\(j=1\\)이 되어 이 값은 \\(Y_{11}=29.85\\)가 됩니다. 그 아래의 1889.5라는 종속변수의 값은 Mailed check 그룹에 속한 값이므로 \\(j=2\\)가 되고 이 두 번째 그룹의 첫 번째 값이므로 \\(i=1\\)이 되어 \\(Y_{12}=1889.5\\)가 됩니다. 다시 그 아래의 108.15라는 값은 두 번째 그룹인 Mailed check의 두 번째 값이므로 \\(i=2\\), \\(j=2\\)가 되어 \\(Y_{22}=108.15\\)가 됩니다. 이 방식을 계속 적용해보면 그 다음의 값은 \\(Y_{13}=1840.75\\)가 됩니다. 이는 세 번째 그룹인 Bank transfer (automatic)에 속한 첫 번째 값이라는 의미가 됩니다. 이런 방식으로 모든 종속변수의 값에 고유의 넘버링을 할 수 있습니다. 이게 바로 위에 등장하는 공식의 좌항인 \\(Y_{ij}\\)입니다.\n이제 \\(\\tau_{j}\\)에 대해 알아봅시다. Figure 3.11 에서 독립변수 Payment Method는 네 가지 그룹으로 되어 있습니다. 위에서 설명한 것처럼 Electronic chek을 1번 그룹으로 Mailed check을 2번 그룹으로 Bank transfer (automatic)을 3번 그룹으로 Credit card (automatic)을 4번 그룹으로 지정했습니다. 이 번호가 바로 \\(j\\) 입니다. 그래서 첫 번째의 Electronic check은 \\(\\tau_{1}\\)이 되고, 두 번째와 세 번째의 Mailed check은 \\(\\tau_{2}\\)가 되고 Bank transfer (automatic)은 \\(\\tau_{3}\\)가 됩니다.\n\n\n\nFigure 3.11: 코딩화면의 독립변수\n\n\n이제 마지막으로 남은 것은 \\(\\epsilon_{ij}\\)입니다. 여기서 \\(i\\), \\(j\\)는 종속변수의 경우와 동일합니다. 문제는 이 \\(\\epsilon\\)이 무엇이냐 인데 이것이 의미하는 것은 오차(error)입니다. 갑자기 웬 오차인가 싶을 수도 있겠지만 쉽게 설명하자면 우리가 가진 데이터를 우리의 통계적 모델인 분산분석이 완벽하게 100% 설명할 수는 없습니다. 아주 약간씩의 오차는 있을 수밖에 없는 것이지요. 이것을 의미합니다. 다만 여기서 말하는 오차는 random한 오차입니다. 즉 무작위성의 오차라는 의미입니다. 따라서 이 오차는 큰 의미가 없는 것입니다. 만약에 이 오차가 무작위가 아니라면 기본적으로 우리의 분석 모델이 잘못되었거나 이 오차 안에 뭔가 다른 의미가 있어서 그 의미를 찾아내야 하는 상황이 됩니다. 일단 이런 복잡하고 어려운 상황은 기초적인 단계에서는 다룰 수 없으니 분산분석의 오차는 일단 무조건 random한 오차라고 이해합시다. 이와 관련되어서는 사실 뒤에 나오는 회귀분석에서 보다 자세하게 다룰 일이 있을 것입니다.\n자, 그럼 이제 다시 이 두 개의 식을 들여다봅시다.\n\\[Y_{ij} = \\mu \\;+\\; \\tau_{j} \\;+\\; \\epsilon_{ij} \\]\n\\[Y_{ij} \\;-\\; \\mu = \\tau_{j} \\;+\\; \\epsilon_{ij} \\]\n어떤가요? 이해가 되나요? 사실 알고 보면 별것 아닙니다. 위의 식들은 우리의 분산분석을 그리고 우리의 데이터를 일반화해서 써 놓은 것입니다. 궁극적으로 위의 식이 의미하는 것은 그룹별(독립변수) 차이가 종속변수에 나타나는 것인지 아닌지 보겠다는 것입니다. 그러니 이제 통계책에서 이런 복잡해 보이는 식을 만나더라도 너무 긴장하지 말고 절대 통계를 포기하지 말기 바랍니다.\nYouTube 바로 가기"
  },
  {
    "objectID": "chapter3.html#anova는-f-valuef값이다",
    "href": "chapter3.html#anova는-f-valuef값이다",
    "title": "3  분산분석 (ANOVA)",
    "section": "3.5 ANOVA는 F-value(F값)이다",
    "text": "3.5 ANOVA는 F-value(F값)이다\n\n3.5.1 분산분석의 F-value\n이제 우리는 분산분석을 시작하려 합니다. 사실 앞에서 했던 z-test와 t-test처럼 분산분석도 이런 유의 이름이 있습니다. 바로 F-test입니다. 방금 알게 된 사실인데, 제가 지난 몇 년간 바빠서 유투브 댓글을 거의 보지 못하고 있었습니다. 우연히 조금 전에 들어가 봤더니 많은 분들이 이 F-value의 F는 Fisher의 F라는 것을 댓글로 알려주셨네요. 생각해 보니 너무 당연한 건데 저도 의외로 너무 바보같이 그냥 지나쳤습니다. 사실 유명한 Fisher의 정확검정 같은 것만 생각해봐도 이 ANOVA의 창안자가 Fisher라는 점은 너무 당연하네요. 하여간 그렇답니다. 댓글 달아주신 분들께 감사드립니다. 저도 한 수 배워갑니다.\nz-test에 z-value가 있었고 t-test에 t-value가 있었듯이 분산분석인 F-test에는 F-value가 있습니다. 그렇습니다. 분산분석 즉 ANOVA는 F-value가 핵심입니다. 중요한 것은 분산분석의 F-test 역시 앞에서 공부한 z-test나 t-test와 동일한 흐름으로 진행된다는 것입니다. 그럼 앞에서 했던 것들을 잠시 떠 올려 봅시다.\nz-test를 다음 위해서 우리는 먼저 z-value를 구하고 이 z-value를 표준 정규분포를 기본으로, z-table (표준 정규분포표)에서 이 값을 찾아서 우리가 원하는 p-value를 구하였습니다. t-test에서는 먼저 t-value를 구하고 역시 t-distribution을 기본으로, t-table에서 앞에서 구한 t-value를 찾아서 우리가 원하는 p-value의 critical value (c.v.)를 알아내었습니다. 그러므로 F-test에서는 먼저 F-value를 구할 것이고 이것을 F-distribution에 기반하여 F-table에서 우리가 원하는 p-value와 관련한 정보를 얻어낼 것입니다. 그러므로 전반적인 프로세스는 동일합니다.\n이제 분산분석을 시작해 봅시다.\n\n\n3.5.2 이름이 왜 분산분석인가?\n갑자기 이게 무슨 뚱딴지같은 질문일까 생각하시는 분도 있겠지만, 언제나 우리의 공부의 시작은 바로 질문입니다. 자 생각해 봅시다. 우리가 원하는 것은 정확하게 말하면 세 개 이상의 집단의 평균값이 같은지 다른지 알고 싶다는 것입니다. 에를 들면 Figure 3.2 처럼 말이죠. 앞에서 공부한 t-test는 분명히 두 그룹의 평균값을 비교하기 위해 그 차이를 구하고 그 차이에서 분석을 시작했습니다. 단지 그룹이 한 개 더 늘어서 세 개가 되었는데 우리의 목적은 동일합니다. 세 집단의 평균이 같은지 다른지 알고 싶은 것이지요. 그렇다면 분석의 이름이 평균분석이어야 하지 않을까요? 갑자기 분산분석이라니 이게 무슨 뜻일까요? 뭔가 이상하지 않나요? 분산분석이라는 이름을 듣고 이사하게 생각하지 않는다면 아마도 평생 왜 이것이 분산분석인지 모르고 넘어갈 것입니다. 아마도 제가 아는 한 모든 통계수업과 통계책은 이런 설명이 없이 그냥 공식을 외우고 문제를 풀고 답을 찾게만 합니다. 왜냐고 물으면 아무도 답해주지 않습니다. 우리는 질문해야 합니다. 왜? 분산분석인가요? 평균분석이 아니고?\n그럼 이제 왜 이 분석방법의 이름이 분산분석인지 알려드리겠습니다.\nANOVA 즉 분산분석의 핵심은 앞서 F-value라고 했습니다. F-value는 두 분산의 비율입니다. 그래서 우리는 이 분석을 분산분석이라고 부릅니다. 하지만 여전히 우리의 궁금증은 해결되지 않습니다. 왜냐하면 우리가 궁금한 것은 세 그룹의 평균값이 같은지 다른지 인데, 두 개의 분산으로 어떻게 세 그룹의 평균값이 같은지 다른지 알 수 있을까요? 일단 여기서 다시 분산의 공식을 떠 올려 봅시다.\n\\[Variance=s^2=\\frac{\\sum_{i=1}^{n}(x_i-\\bar{x})^2}{n-1}\\]\n앞에서 해 본 것 처럼 우리가 가진 자료가 {1, 2, 3, 4, 5}라면 평균은 3이고 분산은 다음과 같이 계산될 것입니다.\n\\[\\frac{(1-3)^2+(2-3)^2+(3-3)^2+(4-3)^2+(5-3)^2}{4}=2.5\\]\n앞에서 했던 분산의 계산이 기억이 나시나요? 아무것도 아닌 것 같지만 위의 계산을 잘 기억해 두시기 바랍니다. 앞으로 우리가 자주 보아야 할 것이기 때문입니다.\n\n\n3.5.3 두 개의 분산\n이제 예를 들어서 차근차근 알아가 봅시다.\n우리가 뒤에서 실습할 예제이긴 합니다만 자주 반복해서 보다보면 더 쉽게 이해될 것입니다. 어느 인터넷 서비스 기업 (ISP: Internet Service Provider)이 자신의 고객들의 총 지불금액이 고객별 이용대금 지불방법에 따라 차이가 있는지 알고 싶다면 종속변수와 독립변수는 다음과 같습니다.\n\n종속변수: 총 지불금액 (Total charges)\n독립변수: 대금 지불방법 (총 4가지 그룹)\n\n계좌이체 (Bank transfer)\n신용카드 (Credit card)\n전자수표 (Electronic check)\n종이수표 (Mailed check)\n\n\n아래는 종속변수와 독립변수에 대한 기본적인 정보들입니다. 일종의 기술통계 (Descriptive statistics)라고 할 수 있습니다. 약 7000개 정도의 관측치가 있음을 알 수 있고 총 지불금액의 평균은 2,283 달러입니다. 표준편차도 2,267 달러 정도 되네요. 독립변수의 4 개의 그룹에 따른 총 지불금액의 평균은 Bank transfer와 Credit card가 약 3,000 달러 정도이고 Electronic check와 Mailed check가 각각 약 2,000 달러 수준 그리고 1,000 달러 수준임을 알 수 있습니다.\n\n\n\nFigure 3.12: 종속변수-Total Charges\n\n\n\n\n\nFigure 3.13: 독립변수-Payment method\n\n\n그렇다면 이제 우리는 두 개의 분산을 찾아서 F-value를 구해야 합니다. 중요한 것은 위에서 우리가 다시 계산해 보았던 분산의 공식입니다. 두 개의 분산이 존재 하려면 먼저 무엇이 두 개 필요할까요? 잠시 생각해 보시길 바랍니다.\n너무 쉬운 질문이지만 의외로 답을 잘 못합니다. 두 개의 분산이 계산되려면 먼저 두 개의 평균값이 존재해야 합니다. 이제 우리는 그래프를 보면서 두 개의 평균값이 무엇인지 찾아보겠습니다. 아래의 Figure 3.14 를 확인해보기 바랍니다.\n\n\n\nFigure 3.14: 두 개의 평균\n\n\n두 가지 평균값이란 바로 전체평균(GM: Grand Mean)과 그룹평균 입니다. 물론 여기서 그룹평균은 그룹이 4 개 이므로 4개의 평균값이 있지만 개념적으로 모두 같은 것이므로 하나의 그룹평균이라고 볼 수 있습니다. 현재 우리의 데이터에서 전체평균은 \\(GM = 2283\\) 이고 첫 번째 그룹의 평균은 \\(M_1=3079\\), 두 번째 그룹의 평균은 \\(M_2=3071\\), 세 번째 그룹의 평균은 \\(M_3=2091\\), 마지막으로 네 번째 그룹의 평균은 \\(M_4=1054\\)입니다. 그렇다면 이제 우리는 이 두 개의 평균값, 정확히는 두 가지의 평균값에서 두 개의 분산을 찾아내야 합니다. 무엇일까요?\n\n\n\nFigure 3.15: Between Variance\n\n\n바로 그룹간 분산입니다. 이를 우리는 Between Variance라고 부릅니다. 이 Between Variance는 전체평균(GM=2283)으로부터 각 4 개의 그룹의 평균값들 사이의 거리를 의미하는 분산입니다. 위의 Figure 3.15 에서 볼 수 있듯이 말입니다. 그렇다면 이 Between Variance가 가지는 의미는 무엇일까요? 우리는 우선 이 Between Variance가 크다는 것이 어떤 의미인지를 먼저 이해해야 합니다. Between Variance가 크다는 것은 무슨 뜻일까요? 그것은 그룹의 평균값이 전체평균값에서 멀어져 있다는 것을 의미합니다. 다만, 그룹이 3 개 이상으로 여러 개이므로 우리는 정확하게 말하면, Between Variance가 크다는 것은 적어도 어떤 한 그룹의 평균값은 전체평균값으로부터 멀어져 있다고 이야기 할 수 있습니다. 이제 우리는 어떻게 분산을 이용해서 3 개 이상의 그룹의 평균값이 같은지 다른지 분석할 수 있는 단서를 알게 되었습니다. 앞의 t-test에서는 단지 두 개의 그룹이 있었기 때문에 쉽게 두 그룹의 평균값을 빼서 차이 값을 만들어 접근했다면, 그룹의 개수가 3 개 이상이 되면 이 방법이 통하지 않기 때문에 각 그룹의 평균값이 전체 평균값으로부터 얼마나 멀어져 있는지 분산을 구해서 적어도 한 그룹의 평균값은 전체평균과 다르다는 것을 찾아내는 방식이 분산분석인 것입니다. 그래서 평균분석이 아닌 분산분석이라는 이름이 되는 것이지요.\n문제는 지금부터 발생합니다.\nBetween Variance가 크다는 것은 적어도 한 그룹의 평균값이 전체평균값에서 멀어져 있다는 의미는 알겠는데, 도대체 이 Between Variance가 얼마나 커야 큰 거신지 혹은 얼마나 작아야 작은 것인지 우리가 알 수 있을까요? 통계적으로 이 Between Variance가 충분히 크려면 얼마나 커야 할까요? 혹은 이 Between Variance가 우연히 클 확률은 얼마나 될까요?\n맞습니다. 이 Between Variance 하나로는 이러한 질문에 아무런 답도 할 수 없습니다. 그런데 우리는 이런 상황을 앞에서 한 번 겪어 봤습니다. 어디에서 였을까요? 바로 t-value에서 였습니다. 다시 생각해보면 t-value의 분자부분인 두 그룹의 평균값의 차이가 우리의 관심사였습니다. 문제는 이 차이가 얼마나 커야 통계적으로 큰지 얼마나 작아야 작은지 알 수 없었다는 점입니다. 그래서 우리는 비교대상을 가져와서 나누었습니다. 즉 비율을 만든 것이지요. 지금 우리가 공부하는 F-value도 마찬가지입니다. 우리의 관심사는 Between Variance 입니다. 이 Between Variance가 커야 적어도 한 그룹의 평균값이 전체평균으로부터 멀어져 있다고 결론 내릴 수 있기 때문입니다. 문제는 이 Between Variance가 얼마나 커야 큰지 알 수 없으므로 우리는 역시 비교대상을 가져와야 합니다. 그 비교대상이 당연히 두 분산 중 나머지 한 개의 분산이 되겠죠. 그럼 비교대상이 될 나머지 한 개의 분산에 대해 알아봅시다.\n\n\n\nFigure 3.16: Within Variance\n\n\n위의 Figure 3.16 에서 보듯이 나머지 한 개의 분산은 그룹내 분산입니다. Within Variance라고 합니다. 이 Within Variance는 무엇이고 어떤 의미일까요? 간단하게 말하자면 앞에서 공부한 t-value의 분모의 표준편차와 동일한 의미이고 같은 역할을 합니다. 앞서 t-value에서 두 평균값의 차이가 얼마나 커야 큰지 혹은 얼마나 작아야 작은지 알 수 없기 때문에 비교대상으로 표준편차를 가져와서 비교한다는 이야기를 했습니다. 표준편차는 데이터가 평균값으로부터 멀어져 있는 평균적인 거리라고 이야기 했죠. 이 편차는 의미 없는 편차라고도 이야기 했습니다. 이 편차는 단순히 random한 편차로서 아무런 의미가 없는 편차라는 것입니다. 그래서 이런 의미 없는 편차보다도 평균값의 차이(이것도 일종의 편차이지요)가 작거나 비슷하다면 이 두 평균값의 차이는 의미 없는 차이라고 보고 유의하지 않다고 판단하고 만약 이 의미 없는 편차(표준편차)보다 확실히 크다면 두 평균값의 차이는 유의하고 뭔가 이러한 차이에는 이유가 있을 것이라는 설명을 했습니다. 이 논리는 분산분석에서도 동일합니다.\n앞에서 본 Between Variance는 우리의 관심사이지만 얼마나 커야 큰지 혹은 얼마나 작아야 작은지 알 수 없습니다. 그래서 비교대상이 필요하고 우리는 비교대상으로 Within Variance를 가져온 것입니다. 이 Within Variance는 그룹내 분산으로 각 그룹내에서 데이터가 그룹의 평균값을 중심으로 퍼져 있는 평균적인 거리입니다. 즉, 의미 없는 퍼짐인 것입니다. 이러한 퍼져 있는 정도는 단순히 random한 분산일 뿐 뭔가 의미가 있지 않습니다. 따라서 Between Variance가 Within Variance보다 충분히 크지 않다면 우리는 Between Variance가 충분히 크다고 판단할 수 없을 것이므로 어떤 그룹의 평균값도 전체평균에서 그다지 멀리 떨어져 있다고 판단하기 어려울 것입니다. 따라서 모든 그룹의 평균값은 비슷하다고 결론 내려야 할 것입니다.\n\n\n3.5.4 F-value\n\\[F-value = \\frac{Between \\; Variance}{Within \\; Variance} = \\frac{MS_{Between}}{MS_{Within}} = \\frac{MS_{Treatment}}{MS_{Error}}\\]\n책 마다 표기 방법이 다를 수 있어 여러 가지를 써 보았습니다. 위의 식에서 핵심은 결국 F-value는 Between Variance와 Within Variance의 비율이라는 것입니다. 뒤에 나오는 \\(MS_{Between}\\)에 대해서 설명하자면 여기서 \\(MS\\)는 Mean Squared의 약자로서 분산을 의미합니다. 왜 Mean Squared라고 하냐면 기본적으로 분산의 공식을 보면 분산의 분자부분은 제곱의 합입니다. 이를 영어로 Sum of Squared라고 하는데 그냥 SS라고 부릅니다. 이것을 \\(n-1\\)로 나누면 분산이 되는데 사실 \\(n\\)으로 나누냐 혹은 \\(n-1\\)로 나누냐는 모집단이냐 샘플이냐의 차이일 뿐 그 의미는 데이터의 개수로 나누는 것을 의미합니다. 이는 평균값을 구할 때 데이터의 합을 데이터의 개수로 나누는 것이 평균이기 때문에, 분산에서 데이터의 개수로 나누는 것은 평균의 의미를 가지게 됩니다. 그래서 분산이나 표준편차가 평균값을 중심으로 데이터가 평균적으로 퍼져있는 거리가 되는 것이지요. 그런 의미에서 SS를 데이터의 개수로 나누었으니 이게 일종의 평균의 개념이 된다는 의미로 MS라는 말을 사용합니다. 그냥 분산이라는 의미이죠. 되게 어렵게 써 놓았으나 결론은 분산이라는 의미입니다. 다만, 어떤 책은 Between 대신에 Treatment라는 말을 사용하는데, 이는 실험연구에서 각 그룹별로 다른 처방을 내리는 것을 Treatment라고 해서 그룹별로 다르다는 것을 이런 식으로 표현한 것입니다. 또한 Within 대신에 Error를 쓰기도 하는데 여기서 Error는 무슨 문제가 있다는 의미가 아닌 단순히 random한 편차/차이라는 의미 입니다. 따라서 너무 어렵게 생각하지 말기 바랍니다.\n핵심은 F-value란 두 분산인 Between Variance와 Within Variance의 비율이며 여기서 Between Variance가 크다는 것은 적어도 어느 한 그룹의 평균값이 전체평균으로부터 멀어져 있다는 의미이며, 이 크기가 얼마나 커야 큰지 혹은 얼마나 작아야 작은지 알 수 없으므로 우리는 비교대상인 Within Variance를 가져와서 비교한다는 것입니다. 여기서 Within Variance는 의미 없는 random한 분산이므로 이러한 의미 없는 분산보다 Between Variance가 충분히 커야 적어도 한 그룹의 평균값이 전체 평균값과는 다르다고 결론 내릴 수 있다는 것입니다.\n축하드립니다.\n이제 여러분은 분산분석의 가장 중요한 부분을 끝내셨습니다. 조금만 더 나아가 봅시다.\nYouTube 바로 가기"
  },
  {
    "objectID": "chapter3.html#f-value를-계산해-보자",
    "href": "chapter3.html#f-value를-계산해-보자",
    "title": "3  분산분석 (ANOVA)",
    "section": "3.6 F-value를 계산해 보자",
    "text": "3.6 F-value를 계산해 보자\n\n3.6.1 통계적 가설\n앞서 우리는 F-value란 Between Variance와 Within Variance의 비율이라는 것을 알았습니다. 특히 여기서 우리의 관심사는 Between Variance 였습니다. 왜냐하면 만약 Between Variance가 작다면 이것은 모든 그룹의 평균값이 전체평균과 비슷하다는 의미이고, Between Variance가 크다면 이것은 적어도 한 그룹의 평균값이 전체평균으로부터 멀어져 있으므로 다르다는 의미가 되기 때문입니다. 이제 이 말을 통계적 가설로 바꿔 보겠습니다.\n\\[ H_0: \\mu_1 = \\mu_2 = \\; ... \\; = \\mu_k \\; (k는 그룹의 갯수)\\] \\[ H_a: \\mu_i \\neq \\mu_j \\; for \\; some \\; i, j\\]\n위의 대립가설을 우리말로 바꾸면 적어도 한 그룹의 평균값은 다르다는 의미가 됩니다. 영어로는 대략 All means are NOT equal 정도가 되겠습니다. 왜 그런지는 사실 우리가 이미 여러 차례 이야기 했습니다. Between Variance가 통계적으로 유의하다는 것은 이 값이 Within Variance보다 충분히 크다는 것이고, 이것이 의미 하는 바는 누군지는 몰라도 적어도 한 개의 그룹의 평균값이 전체평균과 다르다는 것입니다. 물론, 한 개가 아닐 수도 있습니다. 두 개 일수도 있고 모든 그룹의 평균값이 다 다를 수도 있지만, 중요한 것은 이 정보만으로는 정확하고 자세한 내용을 알 수 없다는 점이지요. 따라서 F-value가 유의 하다는 것은 위의 통계적 가설에서 대립가설을 채택한다는 것이므로 의미상 적어도 한 그룹은 다르다 정도로만 해석이 가능한 것입니다.\n\n\n3.6.2 F-value의 계산\n우리가 이미 계속 반복하고 있지만 다시 한 번 분산의 계산 방법을 떠 올려 봅시다.\n\\[Variance=s^2=\\frac{\\sum_{i=1}^{n}(x_i-\\bar{x})^2}{n-1}\\]\n우리가 가진 자료가 {1, 2, 3, 4, 5}라면 평균은 3이고 분산은 다음과 같이 계산될 것입니다.\n\\[\\frac{(1-3)^2+(2-3)^2+(3-3)^2+(4-3)^2+(5-3)^2}{4}=2.5\\]\n이제 손으로 계산하기 쉬운 예를 하나 가지고 직접 F-value를 계산해 봅시다.\n감기약의 효과를 측정하기 위해 감기약 A와 B 그리고 플라시보를 준비했습니다. 총 10명의 대상자를 세 그룹으로 나누어 감기가 낫는데까지 걸리 날자를 세어 보았습니다. 다음은 그 결과를 정리한 데이터 입니다.\n\n\nTable 3.1: 예제 데이터\n\n\nid\ndays\ngroup\n\n\n\n\n1\n5.3\n1\n\n\n2\n6.0\n1\n\n\n3\n6.7\n1\n\n\n4\n5.5\n2\n\n\n5\n6.2\n2\n\n\n6\n6.4\n2\n\n\n7\n5.7\n2\n\n\n8\n7.5\n3\n\n\n9\n7.2\n3\n\n\n10\n7.9\n3\n\n\n\n\n이제 우리는 Table 3.1 를 이용해서 계산을 해 보겠습니다. 먼저 그룹 평균값과 전체평균값을 구해보겠습니다.\n\n\nTable 3.2: 평균값 추가\n\n\nid\ndays\ngroup\ngroup mean\ngrand mean\n\n\n\n\n1\n5.3\n1\n6.00\n6.44\n\n\n2\n6.0\n1\n6.00\n6.44\n\n\n3\n6.7\n1\n6.00\n6.44\n\n\n4\n5.5\n2\n5.95\n6.44\n\n\n5\n6.2\n2\n5.95\n6.44\n\n\n6\n6.4\n2\n5.95\n6.44\n\n\n7\n5.7\n2\n5.95\n6.44\n\n\n8\n7.5\n3\n7.53\n6.44\n\n\n9\n7.2\n3\n7.53\n6.44\n\n\n10\n7.9\n3\n7.53\n6.44\n\n\n\n\n\n\nTable 3.3: \\(SS_{Between}\\) 계산\n\n\n\n\n\n\n\n\n\n\nid\ndays\ngroup\ngroup mean\ngrand mean\n\\(SS_{Between}\\)\n\n\n\n\n1\n5.3\n1\n6.00\n6.44\n\\(=(6.00-6.44)^2 = 0.194\\)\n\n\n2\n6.0\n1\n6.00\n6.44\n\\(=(6.00-6.44)^2 = 0.194\\)\n\n\n3\n6.7\n1\n6.00\n6.44\n\\(=(6.00-6.44)^2 = 0.194\\)\n\n\n4\n5.5\n2\n5.95\n6.44\n\\(=(5.95-6.44)^2 = 0.240\\)\n\n\n5\n6.2\n2\n5.95\n6.44\n\\(=(5.95-6.44)^2 = 0.240\\)\n\n\n6\n6.4\n2\n5.95\n6.44\n\\(=(5.95-6.44)^2 = 0.240\\)\n\n\n7\n5.7\n2\n5.95\n6.44\n\\(=(5.95-6.44)^2 = 0.240\\)\n\n\n8\n7.5\n3\n7.53\n6.44\n\\(=(7.53-6.44)^2 = 1.195\\)\n\n\n9\n7.2\n3\n7.53\n6.44\n\\(=(7.53-6.44)^2 = 1.195\\)\n\n\n10\n7.9\n3\n7.53\n6.44\n\\(=(7.53-6.44)^2 = 1.195\\)\n\n\n\n\nTable 3.3 은 Between Variance의 분자부분 즉 Sum of Squared 부분을 먼저 계산하는 것을 보여줍니다. 위에서 보듯이 1 번 그룹(감기약 A)에 3 명, 2 번 그룹(감기약 B)에 4 명, 그리고 마지막으로 3 번 그룹(플라시보)에 3명이 있어 동일한 계산을 3 회, 4 회, 3 회 반복합니다. 가끔 왜 반복하느냐고 묻는 분들이 있는데요. 간단합니다. 우리가 가진 데이터의 개수대로 해야만 정확하기 때문입니다. 예를 들어 위의 {1, 2, 3, 4, 5}라는 데이터의 분산을 구할 때도, 모든 데이터에서 전부 한 번씩 평균을 빼서 제곱을 한 뒤에 합쳐야 하는 것과 마찬가지 입니다. 첫 번째 그룹에 세 명의 사람이 있고 이 세 명의 회복일 수 의 평균이 6.00일이므로 이 6.00일이라는 평균값은 한 개가 아닌 세 개로부터 나왔으므로 세 번 전체평균과의 차이를 구해 제곱해서 합해야 합니다. 그러므로 위의 세 그룹의 경우를 단순하게 계산해 본다면 \\(3 \\times (6.00-6.44)^2 + 4 \\times (5.95-6.44)^2 + 3 \\times (7.53-6.44)^2 = 5.127\\)이 됩니다. 가능하다면 엑셀에서 위의 데이터를 넣고 직접 계산해 보길 바랍니다. 직접 손으로 해보는 것과 그냥 눈으로 보는 것은 차이가 큽니다.\n여기서 계산된 \\(3 \\times (6.00-6.44)^2 + 4 \\times (5.95-6.44)^2 + 3 \\times (7.53-6.44)^2 = 5.127\\)은 Between Variance의 분자부분입니다. 이제 정확한 Between Variance를 계산하기 위해서는 분모부분이 필요합니다. 이 계산에서 분모부분이 바로 분산분석의 자유도 (degree of freedom)입니다. 두 개의 분산 중 이 Between Variance의 자유도가 첫 번째 자유도 입니다. \\(df_1\\)이라고 표기합니다. 이 자유도의 계산은 다음과 같습니다.\n\\[df_1 = k -1 \\; (\\text{k는 그룹의 갯수})\\]\n우리의 독립변수는 감기약 A, B 그리고 플라시보로 이루어져 있으므로 \\(k = 3\\)입니다. 따라서 \\(df_1 = k -1 = 2\\)가 됩니다. 그러므로 우리가 원하는 Between Variance는 \\(SS_{Between} \\div df_1 = 5.127 \\div 2\\)가 될 것입니다. 다음은 Within Variance를 계산해 봅시다.\n\n\nTable 3.4: \\(SS_{Within}\\) 계산\n\n\nid\ndays\ngroup\ngroup mean\n\\(SS_{Within}\\)\n\n\n\n\n1\n5.3\n1\n6.00\n\\(=(5.30-6.00)^2 = 0.49\\)\n\n\n2\n6.0\n1\n6.00\n\\(=(6.00-6.00)^2 = 0.00\\)\n\n\n3\n6.7\n1\n6.00\n\\(=(6.70-6.00)^2 = 0.49\\)\n\n\n4\n5.5\n2\n5.95\n\\(=(5.50-5.95)^2 = 0.20\\)\n\n\n5\n6.2\n2\n5.95\n\\(=(6.20-5.95)^2 = 0.06\\)\n\n\n6\n6.4\n2\n5.95\n\\(=(6.40-5.95)^2 = 0.20\\)\n\n\n7\n5.7\n2\n5.95\n\\(=(5.70-5.95)^2 = 0.06\\)\n\n\n8\n7.5\n3\n7.53\n\\(=(7.50-7.53)^2 = 0.001\\)\n\n\n9\n7.2\n3\n7.53\n\\(=(7.20-7.53)^2 = 0.11\\)\n\n\n10\n7.9\n3\n7.53\n\\(=(7.90-7.53)^2 = 0.14\\)\n\n\n\n\nTable 3.4 에서 보는 바와 같이, Within Variance는 각 값에서 그룹 평균값을 빼서 제곱하여 모두 합하면 됩니다. 소수점 둘째자리 이하는 절삭하였습니다. 전부 다 합쳐서 보면 약 1.757이 됩니다. 즉, \\(SS_{Within} = 1.757\\)이 됩니다. 이제 Within Variance의 분모부분을 알아야 합니다. 이것도 또한 자유도이며 이제 두 번째 자유도가 됩니다. \\(df_2 = n - k\\)입니다. 즉, 데이터의 개수에서 독립변수의 그룹의 개수를 빼주면 됩니다. 총 데이터의 개수는 10개이고 그룹은 3 개 이므로 \\(df_2 = 10 - 3 = 7\\)이 됩니다. 재미있는 것은 \\(df_1 + df_2 = 2 + 7 = 9 = n -1\\)라는 사실입니다. 두 개의 자유도를 합치니 t-test의 자유도와 동일해집니다. 자, 그런 이제 계산된 모든 값들을 정리해 봅시다.\n\\[F-value = \\frac{Between \\; Variance}{Within \\; Variance} = \\frac{MS_{Between}}{MS_{Within}} = \\frac{MS_{Treatment}}{MS_{Error}} = \\frac{\\frac{5.127}{2}}{\\frac{1.757}{7}} = 10.216\\]\n이렇게 됩니다. 결국 우리의 F-value는 약 10.216정도가 됩니다. 어떤가요? 이제 F-value가 보이시나요?\n\n\n3.6.3 통계 프로그램 결과표\n그런데, 보통 ANOVA를 통계 프로그램에서 돌리고 나면 아래와 같은 결과 표가 나타납니다.\n\n\nTable 3.5: 분산분석 결과표\n\n\nANOVA Result\n\n\n\n\n\n\n\n\n\nSource of variance\nSS\ndf\nMS\nF-value\np-value\n\n\nBetween\n5.127\n2\n2.564\n10.216\n0.008\n\n\nWithin\n1.757\n7\n0.251\n\n\n\n\nTotal\n6.884\n9\n\n\n\n\n\n\n\nTable 3.5 가 이해가 되시나요? 우리가 위에서 계산한 그대로 모든 숫자가 나타나 있습니다. 가장 첫 번째에 SS (Sum of Squared)가 있고 그 다음에 df 그리고 SS를 df로 나눈 MS(Mean Squared)가 나옵니다. 이 MS가 우리가 앞에서 설명했듯이 바로 분산입니다. 그리고 Between Variance를 Within Variance로 나눈 것이 바로 F-value입니다. 마지막에 p-value가 나오는데요. 5%보다 확실히 작으므로 유의합니다. 여기서 엑셀에서 저 p-value를 구할 수 있는 간단한 함수를 하나 알려드린다면 바로 fdist라는 엑셀 함수입니다. =fdist(F-value, df1, df2) 이런 순서로 넣으시면 우리가 원하는 p-value를 구할 수 있습니다.\n이제 우리는 분산분석을 거의 정복했습니다. 마무리만 남았네요. 조금만 힘냅시다. 파이팅!!\nYouTube 바로 가기"
  },
  {
    "objectID": "chapter3.html#anova의-f-table과-사후검정",
    "href": "chapter3.html#anova의-f-table과-사후검정",
    "title": "3  분산분석 (ANOVA)",
    "section": "3.7 ANOVA의 F-table과 사후검정",
    "text": "3.7 ANOVA의 F-table과 사후검정\n\n3.7.1 F-table\n앞서 보았던 분산분석의 결과표 Table 3.5 를 보면 p-value는 0.008로 우리가 생각하는 유의수준 \\(\\alpha\\) 5%보다 훨씬 작아 유의합니다. 그렇다면 이 F-vlaue가 유의하다는 것은 무슨 뜻인가요? 이미 설명 했듯이 적어도 어느 한 그룹은 다르다는 정도입니다. 즉, 우리는 뭔가 더 자세한 결과를 알고 싶지만 이 상태만으로는 알 수가 없습니다. 따라서 항상 분산분석이 유의한 결과를 나타내었다면 자동적으로 사후검정 (Post-hoc test)를 해야 합니다.\n사후검정을 하기 전에 먼저 F-table을 한번 보도록 하겠습니다.\n\n\n\nFigure 3.17: F-table\n\n\n앞에서 보았던 t-table과도 조금 다릅니다. 왜냐하면 자유도가 2 개이기 때문에 \\(df_1\\)을 가로축에 \\(df_2\\)를 세로축에 둔 모양이기 때문입니다. 그럼 이제 우리가 앞에서 계산한 F-value를 가지고 F-table을 이용해 p-value를 찾아보겠습니다. 우리의 F-value는 10.216이었고, \\(df_1 = 2, \\; df_2 = 7\\)이었습니다.\n\n\n\nFigure 3.18: F-table의 사용법\n\n\nFigure 3.18 에서 우리는 두 번째 열(파란색)이 \\(df_1 = 2\\)이므로 쭉 따라서 내려오다가 좌측에 \\(df_2 = 7\\)인 초록색과 만나는 부분이 우리가 찾아야 할 부분입니다. 좌측에 보면 7이라는 숫자 우측에 소수점들이 있는데 이 부분이 바로 p-value 입니다. 우리의 유의수준은 \\(\\alpha = 0.05\\)이므로 그 중에 두 번째 줄을 보면 4.74라는 숫자가 있습니다. 이 숫자가 바로 \\(df_1 = 2, \\; df_2 = 7\\)인 경우 유의수준 \\(\\alpha = 0.05\\)에 해당하는 c.v. (critical value)입니다. 앞의 t-table과 똑같이 우리의 F-value가 이 c.v. 보다 크면 유의수준 5%보다 p-value가 작아진다는 의미입니다. 우리의 F-value는 10.216이므로 c.v. 4.74보다 훨씬 큽니다. 따라서 우리의 F-value는 유의합니다. 앞에서 설명한 것처럼 보다 정확한 p-value를 알고 싶다면 엑셀의 fdist 함수를 이용하시기 바랍니다.\n\n\n3.7.2 사후검정\n이제 다시 유의한 분산분석의 결과로 돌아와 봅시다.\n이야기 했듯이 F-value가 유의하다는 것은 적어도 한 그룹이 다르다는 것이지 그 이상도 그 이하도 아닙니다. 그러므로 보다 자세한 결과를 알고 싶다면 사후검정을 해야 합니다. 사후검정을 통해 어떤 그룹이 어떻게 다른 그룹과 같은지 다른지 알 수 있기 때문입니다. 따라서 ANOVA가 유의했다면 자동으로 사후검정을 하는 것을 습관화해야 합니다.\n사후검정이란 일종의 여러 다발의 t-test입니다. 여기서 주의할 점은 사실 방법상으로는 multiple t-test와 유사하기 때문입니다. 사후검정은 multiple t-test에서 발생할 수 있는 1종오류를 제거하도록 설계된 특수한 t-test라고 볼 수 있습니다. 그러므로 사후검정을 통해 각 그룹을 1대 1로 비교 가능합니다. 이쯤 되면 누군가는 이런 생각을 할 수도 있습니다. 그렇다면 분산분석을 하지 않고 바로 사후검정을 하면 되지 않겠냐고 하는 분도 있을 수 있습니다. 그러나 이건 일종의 논리적인 프로세스입니다. 분산분석이 유의해야 사후검정이 의미가 있는 것이지 무턱대고 사후검정부터 하면 사실 좀 논리적인 문제가 발생한다고 볼 수 있습니다. 하지만, 제 개인적인 생각으로는 앞으로 어쩌면 분산분석 없이 사후검정을 하는 분석가들도 꽤 나타날 것이라는 생각이 듭니다. 왜냐하면 이게 뭔가 좀 더 직관적으로 보일 수도 있기 때문이죠. 하지만 우리는 그래도 좀 논리적인 순서대로 가봅시다. 더불어 사후검정에는 여러 가지 방법이 있습니다. 대부분 이 방법은 만든 사람 이름인데요. Fisher’s LSD / Bonferroni / Sheffe / Turkey / Duncan 등이 나름 가장 유명한 방법입니다. 이중 무엇을 써야 하느냐고 물으실 수도 있는데, 두세 가지 정도를 써보면 대부분의 경우 같은 결과가 나옵니다. 그러니 무엇이 더 좋으냐 혹은 맞느냐의 문제는 그다지 중요하지 않습니다.\n다음 시간에 Jamovi를 이용해 분산분석을 직접 실습해 볼 것인데요. 여기서는 위의 데이터를 Jamovi에 넣어서 사후검정한 결과를 보여드리겠습니다.\n\n\n\nFigure 3.19: 사후검정 결과\n\n\n먼저 좌측의 표를 보시면 그룹 대 그룹으로 비교하는 것이 있습니다. 그룹이 1/2/3으로 되어 있습니다. 첫 번째 줄은 그룹 1과 2를 비교 한 것으로 이는 감기약 A와 B를 비교한 것인데, Tukey/Scheffe/Bonferroni 모두 유의하지 않은 결과를 보입니다. 즉, 두 감기약은 효과의 차이가 없다는 의미가 됩니다. 그러나 두 번째 줄과 세 번째 줄은 감기약 A와 플라시보를 그리고 감기약 B와 플라시보를 비교한 것인데 모두 유의합니다. 즉, 감기약 A와 B는 플라시보(위약)과 효과가 유의하게 다르다는 것입니다. 문제는 여기까지 봐도 약간 헷갈립니다. 그래서 더 좋다는 것인가 나쁘다는 것인가? 그렇습니다. 이러한 유의성만으로는 보다 정밀한 설명이 어렵습니다. 그래서 분산분석에서는 유의하면 바로 사후검정을 하고 그 사후검정 결과를 그래프로 그리는 것이 좋습니다. 가끔 이런 그래프를 안 그리는 경우가 있는데 솔직히 매우 아마추어적인 실수라고 할 수 있습니다. 분산분석에서 유의하면 사후검정과 그래프를 필수입니다. 우측의 그래프를 보면 앞의 사후검정 결과가 충분히 이해가 됩니다. 동그라미는 평균 회복일수를 그리고 평균값을 중심으로 위 아래로 뻗은 직선은 95% 유의구간입니다. 이 구간이 겹친다는 것은 기본적으로 두 그룹이 차이가 없다는 것이고 이 구간이 겹치지 않는 것은 두 그룹이 차이가 있다는 의미가 됩니다. 그림에서 보듯이 플라시보 그룹만이 확실하게 위쪽에 위치하고 있는 것이 보입니다. 그러므로 두 감기약은 플라시보 보다는 효과가 빠르지만 둘 사이에는 아무런 차이가 없다고 결론 내릴 수 있습니다.\n이제 우리는 일원배치 분산분석 (One-way ANOVA)를 모두 마스터 했습니다.\n여러분 수고하셨습니다. 통알못의 기초통계 1권은 여기까지입니다. 이정도 공부하셨다면 이제 통계의 아주 기초적인 분석은 마스터 하신 겁니다. 이후부터는 보다 어려운 내용이 준비되어 있습니다. 하지만 제가 여태 그래왔듯 보다 쉽게 이해하실 수 있도록 설명하겠습니다.\n고생 많으셨습니다. 실습으로 넘어가 보겠습니다.\nYouTube 바로 가기"
  },
  {
    "objectID": "chapter3.html#anova를-실습해-보자",
    "href": "chapter3.html#anova를-실습해-보자",
    "title": "3  분산분석 (ANOVA)",
    "section": "3.8 ANOVA를 실습해 보자",
    "text": "3.8 ANOVA를 실습해 보자\n\n3.8.1 실습 데이터\n우리가 사용할 실습 데이터는 다음의 링크에 있습니다.\n실습 데이터\n이 데이터는 유투브 강의에서 설명했듯이 Kaggle.com에서 다운로드 한 것입니다. Kaggle.com에 직접 가서 다운로드 하시는 것도 방법입니다. Kaggle.com에 가시면 이 데이터의 변수들에 대한 보다 자세한 정보를 얻으실 수 있습니다.\nYouTube 바로 가기"
  }
]